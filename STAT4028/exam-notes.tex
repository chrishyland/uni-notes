\documentclass[twoside]{article}
\setlength{\oddsidemargin}{0.25 in}
\setlength{\evensidemargin}{-0.25 in}
\setlength{\topmargin}{-0.6 in}
\setlength{\textwidth}{6.5 in}
\setlength{\textheight}{8.5 in}
\setlength{\headsep}{0.75 in}
\setlength{\parindent}{0 in}
\setlength{\parskip}{0.1 in}

%
% ADD PACKAGES here:
%

\usepackage{amsmath,amsfonts,amssymb,graphicx,mathtools,flexisym, hyperref, graphicx}
\graphicspath{ {./Images/} }

\usepackage{tcolorbox}

%
% The following commands set up the lecnum (lecture number)
% counter and make various numbering schemes work relative
% to the lecture number.
%
\newcounter{lecnum}
\renewcommand{\thepage}{\thelecnum-\arabic{page}}
\renewcommand{\thesection}{\thelecnum.\arabic{section}}
\renewcommand{\theequation}{\thelecnum.\arabic{equation}}
\renewcommand{\thefigure}{\thelecnum.\arabic{figure}}
\renewcommand{\thetable}{\thelecnum.\arabic{table}}

%
% The following macro is used to generate the header.
%
\newcommand{\lecture}[4]{
   \pagestyle{myheadings}
   \thispagestyle{plain}
   \newpage
   \setcounter{lecnum}{#1}
   \setcounter{page}{1}
   \noindent
   \begin{center}
   \framebox{
      \vbox{\vspace{2mm}
    \hbox to 6.28in { {\bf STAT4028: Probability and Mathematical Statistics
    \hfill } }
       \vspace{4mm}
       \hbox to 6.28in { {\Large \hfill #1. #2 \hfill} }
       \vspace{4mm}
       }
   }
   \end{center}


}
%
% Convention for citations is authors' initials followed by the year.
% For example, to cite a paper by Leighton and Maggs you would type
% \cite{LM89}, and to cite a paper by Strassen you would type \cite{S69}.
% (To avoid bibliography problems, for now we redefine the \cite command.)
% Also commands that create a suitable format for the reference list.
\renewcommand{\cite}[1]{[#1]}
\def\beginrefs{\begin{list}%
        {[\arabic{equation}]}{\usecounter{equation}
         \setlength{\leftmargin}{2.0truecm}\setlength{\labelsep}{0.4truecm}%
         \setlength{\labelwidth}{1.6truecm}}}
\def\endrefs{\end{list}}
\def\bibentry#1{\item[\hbox{[#1]}]}

%Use this command for a figure; it puts a figure in wherever you want it.
%usage: \fig{NUMBER}{SPACE-IN-INCHES}{CAPTION}
\newcommand{\fig}[3]{
            \vspace{#2}
            \begin{center}
            Figure \thelecnum.#1:~#3
            \end{center}
    }
% Use these for theorems, lemmas, proofs, etc.
\newtheorem{theorem}{Theorem}[lecnum]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{claim}[theorem]{Claim}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{remark}[theorem]{Remark}
\newtheorem{observation}[theorem]{Observation}
\newtheorem{example}[theorem]{Example}
\newenvironment{proof}{{\bf Proof:}}{\hfill\rule{2mm}{2mm}}


\tcbuselibrary{theorems}
\newtcbtheorem
  []% init options
  {theorem_exam}% name
  {Theorem}% title
  {%
    colback=orange!5,
    colframe=orange!35!black,
    fonttitle=\bfseries,
  }% options
  {def}% prefix


\newtcbtheorem
  []% init options
  {definition_exam}% name
  {Definition}% title
  {%
    colback=blue!5,
    colframe=blue!35!black,
    fonttitle=\bfseries,
  }% options
  {def}% prefix  


\newtcbtheorem
  []% init options
  {proposition_exam}% name
  {Proposition}% title
  {%
    colback=red!5,
    colframe=red!35!black,
    fonttitle=\bfseries,
  }% options
  {def}% prefix  

\newcommand{\Lim}[1]{\raisebox{0.5ex}{\scalebox{0.8}{$\displaystyle \lim_{#1}\;$}}}
\newcommand{\Inf}[1]{\raisebox{0.5ex}{\scalebox{0.8}{$\displaystyle \inf_{#1}\;$}}}
\newcommand{\Sup}[1]{\raisebox{0.5ex}{\scalebox{0.8}{$\displaystyle \sup_{#1}\;$}}}
\newcommand{\norm}[1]{\left\lVert#1\right\rVert}
%
% To generate a clickable table of content.
%
\hypersetup{
    colorlinks,
    citecolor=black,
    filecolor=black,
    linkcolor=blue,
    urlcolor=black
}


% For disjoint unions
% -------------------------------------------------------------------------
\makeatletter
\def\moverlay{\mathpalette\mov@rlay}
\def\mov@rlay#1#2{\leavevmode\vtop{%
   \baselineskip\z@skip \lineskiplimit-\maxdimen
   \ialign{\hfil$\m@th#1##$\hfil\cr#2\crcr}}}
\newcommand{\charfusion}[3][\mathord]{
    #1{\ifx#1\mathop\vphantom{#2}\fi
        \mathpalette\mov@rlay{#2\cr#3}
      }
    \ifx#1\mathop\expandafter\displaylimits\fi}
\makeatother

\newcommand{\cupdot}{\charfusion[\mathbin]{\cup}{\cdot}}
\newcommand{\bigcupdot}{\charfusion[\mathop]{\bigcup}{\cdot}}
% -------------------------------------------------------------------------


% Shorthand to make notes easier
\newcommand\E{\mathbb{E}}
\newcommand{\algebra}{\mathcal{A}}
\newcommand{\semialgebra}{\mathcal{S}}
\newcommand{\sigmalgebra}{\mathcal{F}}
\newcommand{\borelsigmaalgebra}{\mathcal{B}}
\newcommand{\sa}{\sigma-algebra}
\newcommand{\powerset}{\mathcal{P}}
\newcommand{\real}{\mathbb{R}}
\newcommand{\extendedreal}{\overline{\mathbb{R}}}
\newcommand{\negativereal}{\mathbb{R}^-}
\newcommand{\positivereal}{\mathbb{R}^+}
\newcommand{\positiveextendedreal}{\overline{\mathbb{R}}^+}
\newcommand{\positivenegativereal}{\overline{\mathbb{R}}^-}
\newcommand{\prob}{\mathbb{P}}
\newcommand{\utilde}{\underset{\sim}}


\usepackage{tocloft}

\addtolength{\cftsecnumwidth}{10pt}
\setlength{\cftsubsecnumwidth}{3.5em}

\title{STAT4028: Probability and Mathematical Statistics}
\author{Charles Christopher Hyland}
\date{Semester 1 2020}


\begin{document}

\pagenumbering{gobble}
\maketitle
\begin{abstract}
Thank you for stopping by to read this. These are notes collated from lectures and tutorials as I took this course.
\end{abstract}
\newpage
\tableofcontents
\newpage
\pagenumbering{arabic}


\lecture{1}{Non-measurable sets, Sigma algebra, Measure Spaces}
\section{Sigma Algebras and Measures}
\section{Sigma Algebras and Measures}
\subsection{Motivation}

We give a motivation on why we are interested in probability theory. 

Let $\Omega$ be a finite or countable set. Let $\prob$ be a function $\prob: \Omega \rightarrow [0,1]$. In the set up of random experiments with finite or countably many possible outcomes, we can easily deal with it with our discrete probability space $(\Omega, \prob).$

However, the issue comes when $\Omega$ is an uncountable space. Suppose we are interested in assigning probabilities to the interval [0,1], which contains an uncountable number of points. The probability of us picking any point $\omega \in [0,1]$ will be zero (we can always be more and more precise). However, summing over all points in [0,1] will give us 0 which does not make sense. This brings us to our first realisation that we are unable to assign a measure to all sets in $\Omega$ and hence we must be careful.

\subsection{Vitali Sets}

Let us take $\Omega = I = [0,1].$ For now, we say a measure on I generalises the notion of length. The Lebesgue measure on I, which we denote by $\lambda$ assigns to every interval its length $\lambda (a,b) = b - a.$ We will require that $\lambda$ is countably additive and translation invariant.

We will show that there exists sets which are not measurable.

\begin{definition}(Rationals). A point is in the rationals if $q \in \mathbb{Q}$ can be expressed as $q = \frac{x}{y}$ where $x,y \in \mathbb{Z}$ are integers.
\end{definition}

\begin{definition}(Coset). The coset of rationals $\mathbb{Q}$ in the reals $\mathbb{R}$ is 
$$
x + \mathbb{Q} = \{x + q: q \in \mathbb{Q}\}
$$
for each $x \in \mathbb{R}.$
\end{definition}

\begin{lemma}Let $x, y \in \mathbb{R}$. We can group real numbers into categories of cosets
\begin{enumerate}
\item If $y - x \in \mathbb{Q}$, then $x + \mathbb{Q} = y + \mathbb{Q}$
\item If $y - x \not \in \mathbb{Q}$, then the cosets $x + \mathbb{Q}$ and $ y + \mathbb{Q}$ are \textbf{disjoint}.
\end{enumerate}
\end{lemma}

\begin{definition}(Vitali set). A subset $V \subseteq [0,1]$ is called a Vitali set if V contains a single point from each coset of $\mathbb{Q}$ in $\mathbb{R}$.
\end{definition}

\begin{remark}In order to pick points as described, we require the axiom of choice.
\end{remark}

\begin{definition}(Axiom of choice). The choice function is defined on a set of sets whereby it takes an element from each set. The axiom of choice states that a choice function always exists on a set of sets.
\end{definition}


\begin{theorem_exam}{Non-measurable sets always exist}{}Let $(\mathbb{R}, \borelsigmaalgebra, \mu)$ be a measure space on $\mathbb{R}$. Then, for any measurable set $A \in \borelsigmaalgebra$ where $\mu(A) > 0$, there exists a non-measurable subset $B \subset A$.
\end{theorem_exam}

\begin{remark}To show the existence, we can look at $A \subset (0,1)$ and by the density of rationals and translation invariant property of the Lebesgue measure, shift the set to our desired set.
\end{remark}


\begin{theorem_exam}{Vitali sets are not Lebesgue-measurable}{}If $V \subseteq [0,1]$ is a Vitali set, then V is not Lebesgue-measurable.
\end{theorem_exam}

We proceed to construct an example of a Vitali set.
\begin{claim}There exists a set $B \subset [0,1)$ where we set $\{q_n\} = \mathbb{Q} \cap [0,1)$ and $B_n = q_n \bigoplus B$. 

\begin{enumerate}
\item $B_n$ are disjoint sets;
\item $\cup_n B_n = [0,1).$
\end{enumerate}
\end{claim}

\begin{corollary}We cannot assign a Lebesgue measure to the set B 
$$
1 = \sum_{i=1}^{\infty}\lambda (B_i) = \sum_{i=1}^{\infty}\lambda (B) = \infty.
$$
\end{corollary}

Hence, due to Vitali sets, we need to be more selective to which sets we can assign a measure if we want to generalise the notion of length.

\subsection{Sigma Algebras}

\begin{definition}(Sample space and points).
The set of all possible outcomes is called the \textbf{sample space} $\Omega.$ 
A point $\omega \in \Omega$ is called a \textbf{sample point}.
\end{definition}

\begin{definition}(Events).
\textbf{Events} are subsets of $\Omega$ to which we can assign a probability. An event A has \textbf{occurred} if the sample point $\omega \in \Omega$ satisfies $\omega \in A.$
\end{definition}

We can now define the class of sets to which we can assign a measure to.

\begin{definition_exam}{$\sigma$-algebra}{}A class of sets $\sigmalgebra$ is a $\sigma$-algebra ($\sigma$-field) if 
\begin{enumerate}
\item $\Omega \in \sigmalgebra$
\item If $A \in \sigmalgebra$ then $A^c \in \sigmalgebra$
\item If $A_1,A_2,... \in \sigmalgebra$ then $\bigcup_{i=1}^{\infty}A_n \in \sigmalgebra$ (Closed under \textbf{countable} union)
\end{enumerate}
\end{definition_exam}


We have the following useful properties from set theory.

\begin{definition_exam}{De Morgan's Laws}{}
$$
(A \cup B)^c = A^c \cap B^c
$$
$$
(A \cap B)^c = A^c \cup B^c
$$
\end{definition_exam}

\begin{lemma}Let A and B be sets. Then
$$
\bigcup(A_i) \cap B = \bigcup (A_i \cap B)
$$
$$
\bigcap(A_i) \cap B = \bigcap (A_i \cap B)
$$
Furthermore, we have that $A \cap B \subseteq A$ and 
$
A = A \cup (A \cap B).
$
\end{lemma}

We can now describe properties of $\sa$ that will be useful for us.

\begin{proposition_exam}{Properties of $\sigma$-algebra}{} Let $\sigmalgebra$ be a $\sa$. We have the following properties for $\sa$
\begin{enumerate}
\item If $A_n \in \sigmalgebra$ for $n \in \mathbb{N}$ then $ \cap_{i=1}^{\infty}A_n \in \sigmalgebra$ (Closed under countable intersection)
\item $\emptyset \in \sigmalgebra$
\item If $A_1,...,A_N \in \sigmalgebra$ then $ \cup_{i=1}^{N}A_n \in \sigmalgebra$ (Closed under \textbf{finite} union)
\item If $A_1,...,A_N \in \sigmalgebra$ then $\cap_{i=1}^{N}A_n \in \sigmalgebra$ (Closed under \textbf{finite} intersection)
\end{enumerate}
\end{proposition_exam}

\begin{definition}(Measurable Space). The pair $(\Omega, F)$ is called a measurable space.
\end{definition}

\begin{definition}(Power set). Let $\Omega$ be a set. Then, the power set is $\powerset(\Omega) = 2^{\Omega}$ is the largest $\sa$ of $\Omega$.
\end{definition}

We now want to be able to generate the smallest $\sa$ $\sigmalgebra$ that contains all open and closed sets in $\Omega = \mathbb{R}$. We now introduce the tools we will need in order to do so.


\begin{proposition}(Intersection of $\sa$ is a $\sa$). Let I be an arbitrary index set and suppose that for every $i \in I$, $\mathcal{A}_i$ is a $\sigma-$algebra of subsets of $\Omega.$ Then,
$$
\mathcal{A} \coloneqq \bigcap_{i \in I}\mathcal{A}_i \subseteq \mathcal{P}(\Omega)
$$
is a $\sigma-$algebra of subsets of $\Omega$.
\end{proposition}

\begin{definition_exam}{$\sigma$-algebra generated by $\mathcal{A}$}{} Let $\mathcal{A} \subset 2^{\Omega}$. There exists a minimal $\sigma-$algebra that contains $\mathcal{A}$ which we denote by $\sigma (\mathcal{A}).$ This $\sigma$-algebra is generated by the \textbf{intersection of all $\sigma$-algebras} which contains $\mathcal{A}.$
\end{definition_exam}


We describe a special type of $\sigma$-algebra which we will need later onwards.

\begin{definition_exam}{Borel $\sigma-$algebra}{} Let $\Omega = \mathbb{R}.$ Define $\borelsigmaalgebra = \sigma(\{G \subset \mathbb{R}: \text{G is open}\})$. $\borelsigmaalgebra$ is called the \textbf{Borel} $\sigma-$algebra. A set $A \in \mathcal{B}$ is called a \textbf{Borel set.}
\end{definition_exam}

We can also construct the Borel $\sa$ by looking at the $\sa$ generated by intervals in $\mathbb{R}$.

\begin{claim}Let $\mathcal{B}$ be the Borel $\sa$. Then, $$\sigmalgebra_1 = \sigma(\{(-\infty,x]: x \in \mathbb{R}\})$$
and 
$$\sigmalgebra_2 = \sigma(\{[a,b]: a,b \in \mathbb{R}\}).$$
We have that 
$$
\borelsigmaalgebra = \sigmalgebra_1 = \sigmalgebra_2.
$$
\end{claim}


\begin{example}(Cylinder $\sa$). Let $\Omega = \{0,1\}^{\mathbb{N}}$ where $\omega = (\omega_1,\omega_2,...)$ where $\omega_i \in \{0,1\}.$ The \textbf{cylinder sets} are defined by $A_i \{\omega: \omega_j = 0\ \quad ,1 \leq j \leq i \}$ and $A_i^c = \{\omega: \omega_j = 1 \quad ,1 \leq j \leq i\}$. $A_i$ is known as \textbf{cylinder sets}. Then, 
$$
\sigmalgebra = \sigma\{A_i: i \in \mathbb{N}\}
$$
is the $\textbf{cylinder}$ $\sa$.
\end{example}

\begin{lemma}The cyliner $\sa$ is isomorphic to the Borel $\sa$ $\borelsigmaalgebra$ on the interval (0,1).
\end{lemma}

\subsection{Measures}
We can now assign a measure to sets of interest.
\begin{definition_exam}{Measure}{}A set function $\mu: \sigmalgebra \rightarrow [0,\infty]$ is a measure on $(\Omega, \sigmalgebra)$ if 
\begin{enumerate}
\item $\mu(\emptyset) = 0,$
\item If $\{A_i\}_{i \in \mathbb{N}} \in \sigmalgebra$ are disjoint sets, then $\mu(\cup_{i=1}^{\infty}A_i) = \sum_{i=1}^{\infty}\mu(A_i)$ (countable additivity).
\end{enumerate}
\end{definition_exam}

\begin{definition}(Measure Space). The triple $(\Omega, \sigmalgebra, \mu)$ is called a measure space.
\end{definition}

\begin{remark}If $\mu(\Omega) = 1$ then $\mu$ is called a \textbf{probability measure} and denoted by $\prob.$ We then call $(\Omega, \sigmalgebra, \prob)$ a \textbf{probability space.}
\end{remark}


\begin{definition}(Finite and $\sigma-$finite measures). Let $(\Omega, \sigmalgebra, \mu)$ be a measure space. The measure $\mu$ is \textbf{finite} if $\mu(\Omega) < \infty$. The measure $\mu$ is \textbf{$\sigma-$finite} if for sets $A_n \in \sigmalgebra$ such that $\cup_{n \in \mathbb{N}}A_n = \Omega$, then $\mu(A_n) < \infty$ for all $n \in \mathbb{N}.$
\end{definition}

\begin{lemma}The Lebesgue measure $\lambda$ on $\mathbb{R}$ is a $\sigma-$finite measure.
\end{lemma}
\begin{remark}However, the Lebesgue measure $\lambda$ is \textbf{not} finite on $\mathbb{R}.$
\end{remark}

\begin{definition}(Counting Measure). Define the measurable space $(\Omega, \powerset(\Omega))$ where $\powerset(\Omega)$ is the power set of $\Omega$. Then, the counting measure $\mu$ is defined as 
$$
\mu(A) = |A|
$$
for all $A \in \powerset(\Omega)$ and $|A|$ is the cardinality of the set A.
\end{definition}

\begin{proposition_exam}{Properties of a measure}{}Let $(\Omega, \sigmalgebra, \mu)$ be a measure space. Then 
\begin{enumerate}
\item (Finite additivity) If $A_i \in \sigmalgebra$ for $1 \leq i \leq N$ are disjoint sets, then $$
\mu(\bigcup_{1}^{N}A_i) = \sum_{1}^{N}\mu(A_i)
$$
\item (Monotonicity) If $A \subset B$ then $\mu(A) \leq \mu(B)$ 
\item (Sub-additivity) If $A \subset \bigcup_nA_n$ then $$\mu(A) \leq \sum_n \mu(A_n)$$
\item If $\mu(\Omega) < \infty$, then the inclusion exclusion formula holds for $A_1,...,A_n \in \sigmalgebra$ 
$$
\mu(\bigcup_{i=1}^nA_i) = \sum_{i=1}^n\mu(A_i) - \sum_{i < j}\mu (A_i \cap A_j) + \sum_{i < j < k}\mu(A_i \cap A_j \cap A_j) + ... + (-1)^{n-1}\mu(A_1 \cap ... \cap A_n)
$$
\end{enumerate}
\end{proposition_exam}

\begin{definition}(Increasing and decreasing sequence of sets). Let $\{A_n\}_{n \in \mathbb{N}}$ be a sequence of sets such that $A_n \subset A_{n + 1}$ and $\cup_{n \in \mathbb{N}} A_n = A$. We then write that $A_n \uparrow A = \lim_{n \rightarrow \infty}\cup_{n} A_n$. Likewise, if $A_n \supset A_{n+1}$ and $\cap_{n \in \mathbb{N}}A_n = A$, we write that $\lim_{n \rightarrow \infty}\cap_{n}A_n = A_n \downarrow A.$
\end{definition}

\begin{proposition_exam}{Continuity of the measure}{}
\begin{enumerate}
\item (Continuity from below) Let $A_n \in \sigmalgebra$ for $n \in \mathbb{N}$. If $A_n \uparrow A$ then $$\lim_{n \rightarrow \infty}\mu(A_n) = \mu(\bigcup_{n=0}^{\infty}A_n).$$
\item (Continuity from above) Let $A_n \in \sigmalgebra$ for $n \in \mathbb{N}$. If $A_n \downarrow A$ and $\mu(A_0) < \infty$ then $$\lim_{n \rightarrow \infty}\mu(A_n) = \mu(\bigcup_{n=0}^{\infty}A_n).$$
\end{enumerate}
\end{proposition_exam}

\begin{definition}(Discrete probability space). Let $\Omega$ be a countable set. Let $\mathcal{F} = 2^{\Omega}.$ Then, 
$$
P(A) = \sum_{\omega \in \Omega}p(\omega) 
$$
where $p(\omega) \geq 0$ and $\sum_{\omega \in \Omega}p(\omega) = 1.$ If $\Omega$ is a finite set, we then let $p(\omega) = \frac{1}{|\Omega|}$.
\end{definition}

\lecture{2}{Construction of Measures}
\section{Sigma Algebras and Measures}
We are interested in constructing measures on the measurable space $(\Omega, \sigmalgebra).$ The intuition on how to do so is that we want to take a smaller collection of sets $\algebra \subset \sigmalgebra$ and build up from there. In particular, we will come to see that $\algebra$ is an \textbf{algebra}.
\subsection{Algebras}
We will denote $\sigmalgebra$ as the $\sa$ for the rest of this section and an algebra as $\algebra$.
\begin{definition_exam}{Algebra}{} The class $\mathcal{A} \subseteq \mathcal{P}(\Omega)$ is an \textbf{algebra} if 
\begin{enumerate}
\item $\Omega \in \mathcal{A}$
\item If $A \in \mathcal{A}$ then $A^c \in \mathcal{A}$
\item If $A_i \in \mathcal{A}$ then $\bigcup_{i =1}^{N} \in \mathcal{A}.$
\end{enumerate}
\end{definition_exam}

\begin{remark}In some text, an algebra is also known as a \textbf{field}.
\end{remark}

\begin{example} Define the sample space $\Omega = (0,1].$ Define the algebra 
$$
\borelsigmaalgebra_0 = \{\cup_{i=1}^{n}(a_i,b_i]: 0 \leq a_i < b_i \leq 1; n \in \mathbb{N}\}
$$
The class $\borelsigmaalgebra_0$ is an algebra but not a $\sa.$
\end{example}



\begin{claim}If $\sigmalgebra$ is a $\sa$, then $\sigmalgebra$ is an algebra.
\end{claim}


\subsection{Caratheodory Extension Theorem}
\begin{definition}(Pre-measure). Let $\algebra$ be an algebra. Let $\mu_0: \algebra \rightarrow \positiveextendedreal$. The function $\mu_0$ is called a \textbf{pre-measure} if 
\begin{enumerate}
\item $\mu_0(\emptyset) = 0$
\item For every countable sequence $\{E_i\}_{i \in \mathbb{N}}$ of pairwise disjoint sets whose union lies in $\algebra$, then 
$$
\mu_0\bigg(\bigcup_{i=1}^{\infty}E_i \bigg) = \sum_{i=1}^{\infty}\mu_0(E_i).
$$
\end{enumerate}
\end{definition}

\begin{remark}The pre-measure is just a measure defined on the domain of an algebra.
\end{remark}

Pre-measures will be extremely useful in helping us define outer-measures.


\begin{example}Let $\borelsigmaalgebra_0 = \{\cup_{i=1}^{n} (a_i, b_i]: 0 \leq a_i < b_i \leq 1, n \in \mathbb{N}\}$. For a set $A \in \borelsigmaalgebra_0$, we define the Lebesgue pre-measure 
$$
\lambda(A) = \sum_{i=1}^{n}(b_i - a_i).
$$
Then, $\lambda$ is a pre-measure on $\borelsigmaalgebra_0.$
\end{example}

The $\lambda$ pre-measure we defined on the algebra $\borelsigmaalgebra_0$ is what we will want to extend to the Borel $\sa$ and hence create the Lebesgue measure.


\begin{theorem_exam}{Caratheodory's Extension Theorem}{}Let $\algebra$ be an algebra. Then, if $\mu$ is a $\sigma-$finite measure on the algebra $\algebra,$ then $\mu$ has an $\textbf{unique}$ extension to a measure on $\sigma(\algebra).$
\end{theorem_exam}

\begin{corollary} The Lebesgue measure on $([0,1], \borelsigmaalgebra)$ is well defined.
\end{corollary}

We will now show the steps on how to prove Caratheodory's extension theorem. First, we give the extension of the pre-measure we defined earlier.


\begin{proposition_exam}{Outer Measure}{}Let $\Omega$ be the sample space and let $\algebra$ be an algebra of the space $\Omega$. Let $\mu$ be the pre-measure we defined on $\algebra$. Then, we define that for any set $E \subseteq \Omega$, the set function
$$
\mu^*(E) = \inf_{ \{A_i\}_{i \geq 1} } \bigg\{\sum_{i \geq 1}\mu(A_i): A \subseteq \bigcup_{i \geq 1}A_i \text{ and } A_i \in \algebra \bigg\}.
$$
Here, $\mu^*$ is known as the outer-measure.
\end{proposition_exam}

\begin{remark}Here, we take the infimum over all coverings $\{A_i\}_{i \geq 1}$ of the set E. Furthermore, note that this is defined for all sets $E \in \Omega,$ not sets that are measurable.
\end{remark}

The outer measure provided an upper bound on the pre-measure $\mu(E) \leq \mu^*(E)$.

\begin{claim}Let $\mu^*$ be the outer measure and $\mu$ be the pre-measure. If a set E is in the algebra $\algebra$ then 
$$
\mu(A) = \mu^*(A).
$$
\end{claim}

We can state a series of properties of the outer-measure, which are similar to the properties of the pre-measure.

\begin{lemma}(Null set is zero). Let $\mu^*$ be the outer measure. Then 
$$
\mu^*(\emptyset) = 0.
$$
\end{lemma}

\begin{lemma}(Monotonicity of outer measure) Let $\mu^*$ be an outer-measure. For any two sets $E, F \in \Omega$, if $E \subseteq F$ then $\mu(E) \leq \mu(F).$
\end{lemma}

\begin{lemma}(Subadditivity of outer measure). Let $\mu^*$ be the outer measure. Then for a set $A \subset \cup_{k \geq 1}A_k$, we have that 
$$
\mu^*(A) \leq \sum_{k \geq 1}\mu^*(A_k)
$$
\end{lemma}


\subsection{Construction of Measures}

Now, we will define the collection of sets to which we will call measurable. Intuitively, the measurable sets will be the sets for which the upper bound $\mu^*(E)$ is tight, that is $\mu^*(E) + \mu^*(E^c) = 1.$


\begin{definition_exam}{$\mu^*$-measurable set}{} Let $\mu^*: \powerset(\Omega) \rightarrow \positiveextendedreal$ be an outer measure. We call a set $A \subseteq \Omega$ a $\mu^*-$measurable set if 
$$
\mu^*(S) = \mu^*(S \cap A) + \mu^*(S \cap A^c)
$$
for all sets $S \subseteq \Omega.$ We define the family of measurable sets $\mathcal{M}$ where $A \in \mathcal{M}$ if it is $\mu^*-$measurable.
\end{definition_exam}

\begin{lemma}Let $\algebra$ be the algebra on the set $\Omega$ and $\mu^*$ the outer-measure. Then, if $E \in \algebra$ then E is $\mu^*$-measurable.
\end{lemma}


\begin{proposition_exam}{The family of measurable sets if a $\sa$}{}Let $\Omega$ be our set of interest and $\algebra$ be the algebra on $\Omega$. Let $\mu^*$ be the outer-measure. Let $\mathcal{M}$ be the family of $\mu^*$-measurable sets. Then, we have that 
\begin{enumerate}
\item $\mathcal{M} \supseteq \mathcal{A}$
\item $\mathcal{M}$ is a $\sa$
\item From (1) and (2), we have that 
$$
\mathcal{M} \supseteq \sigmalgebra (\algebra).
$$
where $\sigmalgebra (\algebra)$ is the $\sa$ generated by the algebra $\algebra.$
\end{enumerate}

\end{proposition_exam}

\begin{proposition_exam}{The Outer Measure restricted to $\mathcal{M}$ is a measure}{}Let $\mu^*$ be the outer-measure we have defined and $\mathcal{M}$ the family of $\mu^*-$measurable sets. Additionally, let $\nu$ be the pre-measure defined on the algebra $\algebra.$ Then 
$$
\mu^*|_{\mathcal{M}}: \mathcal{M} \rightarrow \positiveextendedreal
$$
is a \textbf{measure} $\mu$. Furthermore, $\mu$ is an \textbf{extension} to the pre-measure $\nu$ as $\mu(A) = \nu(A)$ for all sets $A \in \algebra.$
\end{proposition_exam}

From all this, we can now concisely state Caratheodory's extension theorem.

\begin{theorem_exam}{Caratheory's Extension Theorem}{}Let $\algebra$ be an algebra on $\Omega$ and let $\nu: \algebra \rightarrow \positiveextendedreal$ be a pre-measure on $\algebra.$ Let $\sigmalgebra(\algebra)$ be the $\sa$ generated by $\algebra.$ Then, there exists a measure $\mu: \sigmalgebra(\algebra) \rightarrow \positiveextendedreal$ such that $\mu|_{\algebra} = \nu.$ Moreover, if $\nu$ is $\sigma-$finite, then the extension $\mu$ is \textbf{unique} and also $\sigma-$finite.
\end{theorem_exam}

\begin{corollary}Let $\borelsigmaalgebra_0$ be the Borel algebra defined before and let $\lambda_0$ be the Lebesgue outer-measure defined on it. Then, the Lebesgue measure $\lambda$ on $([0,1], \borelsigmaalgebra)$ is well-defined!
\end{corollary}

\lecture{3}{Uniqueness of measures}
\section{Sigma Algebras and Measures}
\subsection{Uniqueness of measures}

This lecture, we work on proving uniqueness of the extension of the pre-measure in Caratheodory's theorem. In particular, we want to assert the claim.


\begin{claim}Assume that $\mu$ is the extension of the pre-measure $\nu$ on the algebra $\algebra.$ If $\nu$ is $\sigma-$finite, then it is the \textbf{unique extension} of $\nu$ onto $\sigmalgebra(\algebra).$
\end{claim}

One particular issue is that we may have two probability measures that agree on a collection of sets E but they do not agree on the $\sa$ generated $\sigma(E).$ Therefore, we need to be careful when we have that $\mu = \nu$ on the algebra $\algebra$ and make sure that they still agree on $\sigma(\algebra).$ To do so, we require new structures.

\begin{definition_exam}{$\pi$-system}{}A collection of sets P is a $\pi$-system if it is closed under intersection, that is, for all $A, B \in P$
$$
A \cap B \in P.
$$
\end{definition_exam}

\begin{definition_exam}{$\lambda$-system}{}A collection of sets L is a $\lambda-$system (d-system) if 
\begin{enumerate}
\item $\Omega \in L$
\item $A, B \in L$ where $A \subset B$ implies that $B$\textbackslash $A \in L$
\item $A_n \in L$ with $A_n \uparrow A$ implies that $A \in L.$
\end{enumerate}
\end{definition_exam}

We now state a theorem which we will need in showing the uniqueness of the extension in Caratheodory's theorem.

\begin{theorem_exam}{Dynkin's $\pi-\lambda$ Theorem}{}If $\mathcal{P}$ is a $\pi-$system and $L \supset \mathcal{P}$ is a $\lambda-$system, then $\sigma(\mathcal{P}) \subset L.$
\end{theorem_exam}

\begin{proposition_exam}{$\sa$ and $\pi-\lambda$ System}{}The collection of sets $F \subset 2^{\Omega}$ is a $\sigma$-algebra if and only if F is both a $\pi$-system and a $\lambda$-system.
\end{proposition_exam}

\begin{lemma}For $e \subset 2^{\Omega}$, define $\lambda(e)$ to be the intersection of all $\lambda-$systems that contains e. Then $\lambda(e)$ is a $\lambda-$system and is the smallest $\lambda-$system that contains e.
\end{lemma}

\begin{theorem_exam}{$\sa$-generated by a $\pi-$system}{}Let $\mathcal{P} \subset 2^{\Omega}$ be a $\pi-$system. Then, the $\lambda-$system generated by P is agrees with the $\sa$ generated by P $$\lambda(\mathcal{P}) = \sigma(\mathcal{P}).$$
\end{theorem_exam}

We can now finally show the uniqueness property for Caratheodory's theorem.
\begin{theorem_exam}{Measures agree on $\sa$ generated by a $\pi-$system}{}If the measures $\mu$ and $\nu$ agree on a $\pi$-system P, then they agree on the $\sigma$-algebra $\sigma(P).$
\end{theorem_exam}

\begin{proof} First, define the collection of sets 
$$
\mathcal{L} = \{B \in \sigma(P): \mu(B) = \nu(B)\}.
$$

Now, we show that $\mathcal{L}$ is a $\lambda-$system.

\begin{enumerate}
\item $\mu(\Omega) = 1 = \nu(\Omega)$
\item Suppose that $A, B \in \mathcal{L}$ and $A \subset B.$ Then 
$$
\mu(B \setminus A) = \mu(B) - \mu(A) = \nu(B) - \nu(A) = \nu(B \setminus A)
$$
and therefore $B \setminus A \in \mathcal{L}$
\item If $A_n \in \mathcal{L}$ and $A_n \uparrow A$ then 
$$
\mu(A) = \lim_{n \rightarrow \infty}\mu(A_n) = \lim_{n \rightarrow \infty}\nu(A_n) = \nu(A)
$$
and therefore $A \in \mathcal{L}.$
\end{enumerate}

Then, by Dynkin's $\pi-\lambda$ theorem, we have that 
$$
\sigma(P) \subset \mathcal{L}
$$
Now recall, that by construction of $\mathcal{L},$ for every set $B \in \mathcal{L},$ we have that $\mu(B) = \nu(B).$ Therefore, as $\sigma(P) \subset \mathcal{L}$, we have that $\mu(B) = \nu(B)$ for every set $B \in \sigma(P)$ and hence $\mu$ agrees with $\nu$ on $\sigma(P).$
\end{proof}


We have started with an algebra $\algebra$ with a pre-measure $\nu.$ We then extend the measure to the $\sigma$-algebra $\sigma(\algebra)$. Hence, from the theorem above, $\algebra$ is also a $\pi$-system, so any measures that agree on $\algebra$, will also agree on $\sigma(\algebra).$


\subsection{Lebesgue-Stieltjes Integral}
We can now generalise the Lebesgue measure.

\begin{definition_exam}{Borel measure}{} Let $\mu$ be a measure on the $\sa$ $\sigmalgebra$. The measure $\mu$ is a Borel measure if the Borel $\sa$ $\borelsigmaalgebra \subseteq \sigmalgebra$. That is, any Borel set B is $\mu-$measurable.
\end{definition_exam}

There is a relationship between right continuous increasing functions $F$ on $\mathbb{R}$ and a Borel measure $\mu_F$.

\begin{proposition_exam}{Relationship between increasing right continuous functions and Borel Measures}{}Let F be a right continuous and increasing function F on $\mathbb{R}$. Let $\mu_F$ be a Borel measure on $\mathbb{R}.$
\begin{enumerate}
\item Given the function F, we can construct a Borel measure $\mu_F$;
\item Given the Borel measure $\mu_F$, we can construct a F.
\end{enumerate}
\end{proposition_exam}

\begin{remark}If $F(-\infty) = 0$ and $F(\infty) = 1$, then F is the cumulative distribution function.
\end{remark}


\begin{definition_exam}{Regular Measure}{} Let $\Omega$ be a topological space. Let $\mathcal{B}$ be the Borel $\sa$, which is the smallest $\sa$ that contains all open sets. Let $\mu: \sigmalgebra \rightarrow \positiveextendedreal$ and $\sigmalgebra \supseteq \mathcal{B}$. 

$\mu$ is \textbf{regular} if for all sets $A \in \sigmalgebra$ and $\epsilon > 0$, there exist sets $F \subseteq A \subseteq G$ where F is closed, G is open such that 
$$
\mu(G \text{\textbackslash} F) \leq \epsilon.
$$
\end{definition_exam}

\begin{remark}We can approximate any set $A \in \sigmalgebra$ from below by a closed set and from above by an open set.
\end{remark}


We now describe how we construct one from another.

\begin{proposition_exam}{Constructing increasing right continuous functions}{}Let $\mu$ be a regular Borel measure on $\mathbb{R}.$ Then, we define the function
$$
F_0(t) = \begin{cases}
\mu((0,t]) \quad t > 0\\
-\mu((t,0]) \quad t < 0
\end{cases}.
$$
Finally, we define the function $F(t) = F_0(t) + \mu((-\infty]).$ F is an increasing right continuous function.
\end{proposition_exam}


We now show how to derive a Borel measure from a increasing right continuous function.
\begin{definition_exam}{Lebesgue-Stieltjes Outer Measure}{}Let F be a right continuous increasing function. We define the \textbf{Lebesgue-Stieltjes outer measure} $\mu_{F}^{*}:\powerset(\Omega) \rightarrow \positiveextendedreal$ as 
$$
\mu_{F}^{*}(A) = inf \bigg\{\sum_{k=0}^{\infty}(F(b_k) - F(a_k)): A \subseteq \bigcup_{k=0}^{\infty}(a_k,b_k] \bigg\}
$$
for every set $A \in \powerset(\Omega).$
\end{definition_exam}

\begin{definition_exam}{Lebesgue-Stieltjes $\sa$}{}Let $\mu_{F}^*$ be the Lebesgue-Stieltjes outer measure. Define the set $\mathcal{L}$ as all the sets $A \in \Omega$ such that 
$$
\mu_{F}^{*}(E) = \mu_{F}^{*}(E \cap A) + \mu_{F}^{*}(E \cap A^c)
$$
for all sets $E \in \Omega$. Then, the collection of sets $\mathcal{L}$ is a $\sa$.
\end{definition_exam}

\begin{proposition_exam}{Lebesgue-Stieltjes Measure}{}Let F be an increasing right continuous function. Let $\mu_F^*$ be the Lebesgue-Stieltjes outer measure induced by F. Let $\mathcal{L}$ be the Lebesgue-Stieltjes $\sa$ associated with $\mu_F^*$. Then, the \textbf{Lebesgue-Stieltjes measure induced by F} $\mu_F$ is the outer-measure $\mu_F^{*}$ restricted to $\mathcal{L}.$
\end{proposition_exam}

\begin{theorem_exam}{Lebesgue-Stieltjes measure function}{}Let $F: \mathbb{R} \rightarrow \mathbb{R}$ such that F is non-decreasing and right continuous. Then, there exists a unique Borel measure $\mu$ on $(\mathbb{R}, \borelsigmaalgebra)$ such that 
$$
\mu((a,b]) = F(b) - F(a).
$$
$\mu$ is the \textbf{Lebesgue-Stieltjes measure function}.
\end{theorem_exam}

\begin{remark}If we set $F(x) = x$, then $\mu((a,b]) = b - a$ is the \textbf{Lebesgue measure}.
\end{remark}

\begin{definition}(Lebesgue-Stieltjes Integral). Let $f$ be $\mu_F$-measurable function. Then, the Lebesgue-Stieltjes integral is defined as 
$$
\int_{\mathbb{R}}fd\mu_F.
$$
\end{definition}

\begin{remark}This is a generalisation of the Lebesgue integral which we will see later!
\end{remark}


\subsection{Completion of Measure Spaces}
We are now interested in including \textbf{null sets} into our $\sa$. Why do we care about having complete measure spaces? Suppose if two functions f,g satisfy $f(x) = g(x)$ for all $x \in X$\textbackslash $N$ where N has measure zero. We would like to treat f and g as essentially the same thing. However, without completeness, it could be the case that f is measurable but g is not. Furthermore, many theorems in measure theory, for instance Fubini or Radon-Nikodym, needs completeness to make full sense.


\begin{definition_exam}{Complete measure space}{} Let $\sigmalgebra \subseteq \powerset$ be a $\sa$ and let $\mu: \sigmalgebra \rightarrow \positiveextendedreal$ be a measure. Then, $(\Omega, \sigmalgebra, \mu)$ is \textbf{complete} if for every set $A \in \sigmalgebra$ such that $\mu(A) = 0$, then for all sets $E \subseteq A$, we have that $E \in \sigmalgebra.$ The sets E are known as \textbf{negligible sets}.
\end{definition_exam}


\begin{observation}By monotonicity of the measure, we have that the negligible set $\mu(E) = 0.$
\end{observation}

We now state how to actually complete a measure space and that this completion is unique.

\begin{proposition_exam}{Completion of a $\sa$}{}Let $\sigmalgebra \subseteq \powerset$ be a $\sa.$ Define $\mu: \sigmalgebra \rightarrow \positiveextendedreal$ be a measure. Then 
$$
\overline{\sigmalgebra} = \{A \cup N: A \in \sigmalgebra \text{ and } N \subseteq E \in \sigmalgebra \text{ such that } \mu(E) = 0\}.
$$
Then, $\overline{\sigmalgebra}$ is a $\sa.$
\end{proposition_exam}


\begin{proposition_exam}{Completion of a measure}{}Let $\sigmalgebra \subseteq \powerset$ be a $\sa.$ Define $\mu: \sigmalgebra \rightarrow \positiveextendedreal$ be a measure. Then, we define the measure $\overline{\mu}: \overline{\sigmalgebra} \rightarrow \positiveextendedreal$ to be 
$$
\overline{\mu}(A \cup N) = \mu(A)
$$
for all sets $A \in \overline{\sigmalgebra}.$ Clearly, $\overline{\mu}|_{\sigmalgebra} = \mu.$
\end{proposition_exam}


\begin{theorem_exam}{Completion of a measure space}{}Define the measure and $\sa$ pair $(\mu, \sigmalgebra)$. Furthermore, assume that $\Omega$ is $\sigma-$finite with respect to $\mu.$ Then, the completion $(\Omega, \overline{\mu}, \overline{\sigmalgebra})$ is unique.
\end{theorem_exam}

\begin{remark}It is always possible to complete a measure and a $\sa.$
\end{remark}

\begin{proposition_exam}{Lebesgue $\sa$ and Borel $\sa$}{} The Lebesgue $\sigma-$algebra $\borelsigmaalgebra_c$ is the completion of the Borel $\sa$ $\borelsigmaalgebra$ with respect to the Lebesgue measure $\lambda.$ 

That is, we can extend $\lambda$ to $\borelsigmaalgebra_c$ where $E \subset \borelsigmaalgebra_c$ whereby there exists $A \in B$ and $B \subset N \in B$ such that $E = A \cup B$ with $\lambda (N) = 0.$ 
\end{proposition_exam}

\begin{remark}The Lebesgue $\sa$ is just the completion of the $\borelsigmaalgebra$!
\end{remark}

\begin{corollary}The Lebesgue measure is a Borel measure.
\end{corollary}

\begin{remark}There are sets which are Lebesgue measurable but not Borel measurable. The Borel $\sa$ is generated by open sets whereas the Lebesgue $\sa$ is generated by open sets and null sets.
\end{remark}

\subsection{First Borel-Cantelli Lemma}

There is a very important duality between sets and functions. That is, with a set, we can construct a function known as an indicator function.

\begin{definition_exam}{Indicator Function}{} Let $\Omega$ be a sample space. Then, the indicator function of a set $A \subset \Omega$ is defined as 
$$
1_{A}(\omega) = 
\begin{cases}
1 \quad \omega \in A\\
0 \quad \omega \not \in A.
\end{cases}
$$
\end{definition_exam}

\begin{remark} In this course, we will generally be working with measurable sets $A \in \sigmalgebra$ when constructing indicator functions.
\end{remark}

This definition gives us some nice properties.
\begin{lemma} Suppose that $A, B \subset \Omega$. Then 
\begin{enumerate}
\item $1_A \leq 1_B$ if and only if $A \subseteq B$
\item $1_{A^{c}} = 1 - 1_A$
\end{enumerate}
\end{lemma}

We are now interested in analysing sequence of events. However, first recall some probabilistic terminology.
\begin{enumerate}
\item The set of all possible outcomes $\Omega$ is the \textbf{sample space}
\item A point $\omega \in \Omega$ is a \textbf{sample point}
\item \textbf{Events} are subsets of $\Omega$ to which we can assign a probability measure to. That is, they are in the $\sa$ $\sigmalgebra$
\item We say that an \textbf{event has occurred} $A \in \sigmalgebra$ if the \textbf{outcome (sample point)} $\omega \in A$
\end{enumerate}

\begin{definition_exam}{Almost everywhere}{}For a general measure space $(\Omega, \sigmalgebra, \mu)$, we say that any statement S holds \textbf{almost everywhere} (a.e.) if 
$$
\mu(\{\omega \in \Omega: S(\omega) \text{ is false}\}) = 0.
$$
\end{definition_exam}

\begin{remark} In a probability space, we say that the statement S holds \textbf{almost surely} (a.s.).
\end{remark}

We now revise the idea of limit inferiors and limit superiors from analysis.

\begin{definition}(Limit inferior/superior). The limit inferior of a sequence $\{x_n\}_{n \geq 1}$ is 
$$
\lim_{n \rightarrow \infty}\inf\;x_n = \lim_{n \rightarrow \infty}(\inf_{k \geq n}x_k).
$$
The limit superior of a sequence $\{x_n\}_{n \geq 1}$ is 
$$
\lim_{n \rightarrow \infty}\sup\;x_n = \lim_{n \rightarrow \infty}(\sup_{k \geq n}x_k).
$$
\end{definition}

We can apply this idea to sequences of events. We will see later that the definition of convergence for random variables depends on manipulating sequences of events, which require limits of sets. 
\begin{definition}(Infimum and supremum of sets). Suppose that $\{A_n\}_n \subset \Omega$ is a sequence of events. 
\begin{enumerate}
\item The \textbf{infimum} of the sequence of events is 
$$
\inf_{k \geq n}A_k \coloneqq \bigcap_{k=n}^{\infty}A_k
$$
\item The \textbf{supremum} of the sequence of events is 
$$
\sup_{k \geq n}A_k \coloneqq \bigcup_{k=n}^{\infty}A_k
$$
\end{enumerate}
\end{definition}




\begin{definition_exam}{Infinitely often/Limit superior for sets}{}Let $\{A_n\}_n$ be a sequence of events. We define the subset of events
$$
lim\;sup\;A_n = \bigcap_{m=1}^{\infty}\bigcup_{n = m}^{\infty}A_n = \{\omega: \forall m \; \text{there exists }n=n(\omega) \geq m \text{ with } \omega \in A_n\} = (A_n \text{ i.o.})
$$
\end{definition_exam}
\begin{remark}Note that if we let $B_m = \bigcup_{n \geq m}A_n$, we have that $B_m$ is a \textbf{decreasing sequence of sets.} 
\end{remark}

Intuitively, we say that we are interested in collection of sample points $\omega$ for which that for all values of m, there exists a rank $n(\omega)$ such that the sample point $\omega$ appears in every event $A_n.$. 

\begin{proposition_exam}{The limit superior of measurable sets is measurable}{}Let $\{A_n\}_n$ be a sequence of events on the measure space $(\Omega, \sigmalgebra, \mu).$ Then, the set $$(A_n \text{ i.o}) \in \sigmalgebra$$ 
\end{proposition_exam}

\begin{proof} First, recall that 
$$
(A_n \text{ i.o.}) = \bigcap_{m=1}^{\infty}\bigcup_{n = m}^{\infty}A_n
$$
First, recall that countable union of measurable sets is measurable
$$
\bigcup_{n = m}^{\infty}A_n \in \sigmalgebra
$$
Next, the countable intersection of measurable sets is measurable
$$
\bigcap_{m=1}^{\infty}\bigcup_{n = m}^{\infty}A_n \in \sigmalgebra
$$
Therefore, we have shown that $$(A_n \text{ i.o}) \in \sigmalgebra.$$ 
\end{proof}




\begin{proposition}Let $1_{A}$ be the indicator function of a measurable set $A_n$. Then 
$$
\overline{lim}1_{A_{n}}(\omega) = 1_{\overline{lim}A_n}(\omega)
$$
for all $\omega \in \Omega.$
\end{proposition}

\begin{proof}(Sketch). It can be claimed that
$$
\inf 1_{A_n}(\omega) = 1_{\inf A_n}(\omega) \quad \sup 1_{A_n}(\omega) = 1_{\sup A_n}(\omega)
$$
Now, write out 
$$
\overline{lim}1_{A_{n}}(\omega) = \inf \sup 1_{A_{n}}(\omega)
$$
and apply the claim twice to get 
$$
1_{\inf \sup A_{n}}(\omega) = 1_{\overline{lim}A_n}(\omega)
$$
\end{proof}

We now state one of the most important lemmas of the course. The Borel-Cantelli lemma is a useful tool for proving almost sure convergence.

\begin{theorem_exam}{First Borel-Cantelli lemma}{}Let $\{A_n\}$ be a sequence of events such that $\sum_n\prob(A_n) < \infty.$ Then,
$$
\prob((A_n \; \text{i.o})) = \prob(\lim_{n \rightarrow \infty} \sup\;A_n) = 0.
$$
\end{theorem_exam}

\begin{proof} Let $B_m = \cup_{n \geq m}A_n$. Then, we have that $$B_m \downarrow B = \cap_{m=1}^{\infty}B_m = \overline{\lim}A_n.$$ Therefore, we have that 
$$
\prob(B_m) \rightarrow \prob(\overline{\lim}A_n)
$$
However, due to the subaddivity of the probability measure 
$$
\prob(B_m) \leq \sum_{n \geq m}\prob(A_n) \rightarrow 0
$$
as $n \rightarrow \infty$ since $\sum_n\prob(A_n) < \infty$ implies that $\prob(A_n) \rightarrow 0$. We can therefore conclude that 
$$
\prob(B_m) \rightarrow \infty
$$
which in turn implies that the set $(A_n \; i.o.)$ will have measure zero.
\end{proof}

We now define something that is the opposite of infinitely often.
 
\begin{definition_exam}{Eventually/Limit infimum for sets}{}Define the probability space $(\Omega, \sigmalgebra).$ Let $\{A_n\}_n$ be a sequence of events. We define the subset 
$$
\lim\;inf\;A_n = \bigcup_m\bigcap_{n \geq m}A_n = \{\omega: \omega \in A_n \text{ for all sufficiently large n}\} = (A_n \text{ eventually})
$$
\end{definition_exam}

\begin{remark} A way to interpret $(A_n \text{ eventually})$ is that the point $\omega$ appears in all but finitely many sets.
\end{remark}

We give some properties of the limit infimum for sets.

\begin{proposition_exam}{The limit inferior of measurable sets is measurable}{}Define the probability space $(\Omega, \sigmalgebra).$ Let $\{A_n\}_n$ be a sequence of events on the measure space $(\Omega, \sigmalgebra, \mu).$ The set $$(A_n \text{ eventually}) \in \sigmalgebra.$$
\end{proposition_exam}

\begin{proof} We have that $\bigcap_{n \geq m}A_n \in \sigmalgebra$ if $A_n \in \sigmalgebra$. Then, we can conclude that $\bigcup_m\bigcap_{n \geq m}A_n \in \sigmalgebra.$
\end{proof}

\begin{proposition_exam}{Relationship between limit superior and limit inferior of sets}{}Let $\{A_n\}_n$ be a sequence of measurable sets. Then 
$$
\underline{\lim} \;A_n  \subset \overline{\lim} \;A_n
$$
\end{proposition_exam}

\begin{proof}(Sketch). First, suppose that 
$$
\omega \in \bigcup_{m = 1}^{\infty}\bigcap_{n \geq m}A_n
$$
This equivalent to saying that there exists $N_0 \in \mathbb{N}$ such that $\omega \in A_n$ for all $n \geq N_0.$ That is,
$$
\omega \in \bigcap_{n \geq N_0}A_n
$$
Now, the key insight is that this implies that 
$$
\omega \in \bigcup_{n \geq N_0}A_n
$$
Then, we use the fact that 
$$
\omega \in \bigcup_{n \geq N_0}A_n \subseteq \bigcup_{n = 1}^{\infty}A_n
$$
Then, this means that $
\omega \in \bigcup_{n = m}^{\infty}A_n
$
 for all $m \geq 1.$ Hence, we can conclude that 
$$
\omega \in \bigcap_{m = 1}^{\infty}\bigcup_{n \geq m}A_n = \overline{lim}\;A_n
$$
\end{proof}

\begin{proposition_exam}{Complements between limit inferior and limit superior of sets}{}Define the probability space $(\Omega, \sigmalgebra).$ Let $(A_n \text{ eventually})$ and $(A_n \text{ i.o})$ be the limit inferior and limit superior of a sequence of sets $\{A_n\}_n$. Then 
$$
(A_n^c \text{ eventually}) = (A_n \text{ i.o.})^c
$$
\end{proposition_exam}
\begin{proof}
$$
(A_n^c \text{ eventually}) = \bigcup_{m = 1}^{\infty}\bigcap_{n \geq m}A_n^c = \bigcup_{m = 1}^{\infty}\bigg(\bigcup_{n \geq m}A_n\bigg)^c = \bigg(\bigcap_{m = 1}^{\infty}\bigcup_{n \geq m}A_n\bigg)^c = (A_n \text{ i.o.})^c
$$
\end{proof}


\begin{theorem_exam}{Fatou's Lemma for sets}{}Define the probability space $(\Omega, \sigmalgebra, \prob).$ For the sets $A_n \in F$, we have that
$$
\prob(\overline{lim}\;A_n) \geq \overline{lim}\;\prob(A_n)
$$
$$
\prob(\underline{lim}\;A_n) \leq \underline{lim}\;\prob(A_n) 
$$
\end{theorem_exam}

\begin{proof}(Sketch). First, define the decreasing sequence 
$$
B_m = \bigcup_{n \geq m}A_n
$$
whereby we have that $B_m \downarrow \overline{lim}\;A_n.$ Therefore, we have that 
$$
\prob(B_m) \downarrow \prob( \overline{lim}\;A_n)
$$
Now, note that for a fixed n, $B_n \supset A_n.$ Therefore, by monotonicity
$$
\prob(B_m) \geq \prob(A_m)
$$
From this, we take limit superior of both sides 
$$
\overline{lim}\;\prob(B_m) \geq \overline{lim}\;\prob(A_m)
$$
Hence, we can conclude that 
$$
\prob(\overline{lim}\;A_n) \geq \overline{lim}\;\prob(A_n)
$$
To prove the other result, repeat the same process except let $B_m = \bigcap_{n \geq m}A_n.$
\end{proof}

\begin{proposition}Let $1_{A}$ be the indicator function of a measurable set $A_n$. Then 
$$
\underline{lim}1_{A_{n}}(\omega) = 1_{\underline{lim}A_n}(\omega)
$$
for all $\omega \in \Omega.$
\end{proposition}

\begin{proof}Recall that
$$
\inf 1_{A_n}(\omega) = 1_{\inf A_n}(\omega) \quad \sup 1_{A_n}(\omega) = 1_{\sup A_n}(\omega)
$$
Then, apply this result twice to the expression 
$$
\underline{lim}1_{A_{n}}(\omega) = \sup_{k \geq 1}\inf_{n \geq k}1_{A_{n}}(\omega).
$$
\end{proof}

\lecture{4}{Random Variables and Distributions}
\section{Random Variables}
\section{Random Variables}
\subsection{Random Variables}
Today, we look at random variables and the distribution function of random variables.

\begin{definition}(Preimage of a function). Define a function $f: (\Omega_1,\sigmalgebra_1) \rightarrow (\Omega_2,\sigmalgebra_2)$. Then, the preimage of a set $B \in \sigmalgebra_2$ is given by 
$$
f^{-1}(B) = \{\omega \in \Omega_1: f(\omega) \in B\}
$$
\end{definition}

\begin{remark} Note that we use the phrase preimage as the function may not necessarily have an inverse but it will have a preimage.
\end{remark}

Now, we can define what we mean by a measurable function.

\begin{definition_exam}{Measurable function}{} A function $f: (\Omega_1,\sigmalgebra_1) \rightarrow (\Omega_2,\sigmalgebra_2)$ is measurable with respect to $\sigmalgebra_1$ if for all measurable sets $A \in \sigmalgebra_2$, we have $$f^{-1}(A) \in \sigmalgebra_1.$$
\end{definition_exam}

\begin{example}The constant function f = c is a measurable function as defined by 
$$
f^{-1}(A) = 
\begin{cases}
\emptyset \quad c \not \in A\\
\Omega \quad c \in A
\end{cases}
$$
for all $A \in \sigmalgebra_2$ as $\emptyset, \Omega \in \sigmalgebra_1.$
\end{example}


\begin{definition_exam}{Random Variable}{}Define the function $X: (\Omega, \sigmalgebra) \rightarrow (\mathbb{R}, \mathbb{B})$ where $\mathbb{B}$ is the Borel $\sigma-$algebra. Then X is a random variable (RV) if it is measurable with respect to $\sigmalgebra$.
\end{definition_exam}

\begin{lemma}Let $\Omega$ be a discrete probability space. Then, any function $X: \Omega \rightarrow \mathbb{R}$ is a random variable.
\end{lemma}

We state important properties of preimages of functions that we will need.
\begin{claim} Let $f:(\Omega_1, \sigmalgebra_1) \rightarrow \Omega_2$. Then, we have that 
\begin{enumerate}
\item $f^{-1}(A^c) = \bigg(f^{-1}(A) \bigg)^c$
\item $f^{-1}\big(\cup_nA_n \big) = \cup_n f^{-1}(A_n)$
\end{enumerate}
\end{claim}

We can now show an important result whereby if a collection of sets is has a measurable preimage, then the $\sa$ generated by the collection of sets also has a measurable preimage.

\begin{proposition_exam}{Measurability of $\sa$ generated by sets}{}Define the function $f: (\Omega_1, \sigmalgebra_1) \rightarrow \Omega_2$. Suppose that for any set in the collection of sets $A \in \algebra \subset 2^{\Omega_2}$, we have that $$f^{-1}(A) \in \sigmalgebra_1.$$ Then, for any set in the $\sa$ generated $A \in \sigma(\algebra)$, we have that $$f^{-1}(A) \in \sigmalgebra_1$$
\end{proposition_exam}

\begin{proof} 
We have a collection of sets $\mathcal{A}$ such that for any set $A \in \mathcal{A},$ we have that $f^{-1}(A) \in \sigmalgebra_1.$ We want to show that any set $A \in \sigma(\mathcal{A})$, we have that $f^{-1}(A) \in \sigmalgebra_1.$

First, define the set 
$$
\beta = \{A \in \Omega_1: f^{-1}(A) \in \sigmalgebra_1\}
$$

Clearly, by construction, we have that 
$$
\mathcal{A} \subseteq \beta
$$

Now, the goal is to show two things
\begin{enumerate}
    \item $\beta$ is a $\sigma-$algebra
    \item $\sigma(\mathcal{A}) \subseteq \beta$
\end{enumerate}
These two things will imply that every set $A \in \sigma(\mathcal{A})$, we have that $f^{-1}(A) \in \sigmalgebra_1,$ the result we want to show.

First, we show that $\beta$ is a $\sigma-$algebra
\begin{enumerate}
    \item $\emptyset \in \beta$ as $f^{-1}[\emptyset] = \emptyset \in \sigmalgebra_1$
    \item Let $A \in \beta.$ Then, as $\sigmalgebra_1$ is a $\sigma-$algebra, $f^{-1}(A) \in \sigmalgebra_1$ implies that $f^{-1}(A)^c = f^{-1}(A^c) \in \sigmalgebra_1$. Hence, $A^c \in \beta.$
    \item Suppose $A_k \in \beta$ for $k \in \mathbb{N}.$ Then as $\sigmalgebra_1$ is a $\sigma-$algebra, $f^{-1}[A_k] \in \sigmalgebra_1$ we have that $\cup_{k \in \mathbb{N}}f^{-1}[A_k] = f^{-1}[\cup_{k \in \mathbb{N}}A_k] \in \sigmalgebra_1$. Therefore, $\cup_{k \in \mathbb{N}} \in \beta.$
\end{enumerate}
Hence, $\beta$ is a $\sigma-$algebra.

Now, we argue that  $\sigma(\mathcal{A}) \subseteq \beta$. First, by definition of $\mathcal{A}$, we have that $f^{-1}[A] \in \sigmalgebra_1$ for all sets $A \in \mathcal{A}.$ Hence, $\mathcal{A} \subset \beta.$ Now, $\sigma(\mathcal{A})$ is the smallest $\sigma-$algebra that contains $\mathcal{A}.$ As a result, $\sigma(\mathcal{A}) \subset \beta.$

Hence, we can conclude that $f^{-1}(A) \in \sigmalgebra_1$ for every set $A \in \sigma(\mathcal{A}).$
\end{proof}

With this proposition, we can specify an easier way to verify whether is a function a random variable.

\begin{theorem_exam}{Test for a random variable}{}Let $(\Omega, \sigmalgebra)$ be a measurable space. Let $X: \Omega \rightarrow \mathbb{R}$ be a function. Then, the following are equivalent 
\begin{enumerate}
\item X is a random variable;
\item $X^{-1}[(\alpha, \infty]] \in \sigmalgebra$ is measurable for all $\alpha \in \mathbb{Q}$;
\item $X^{-1}[[\alpha, \infty]] \in \sigmalgebra$ is measurable for all $\alpha \in \mathbb{Q}$;
\item $X^{-1}[[-\infty, \alpha)] \in \sigmalgebra$ is measurable for all $\alpha \in \mathbb{Q}$;
\item $X^{-1}[[-\infty, \alpha]] \in \sigmalgebra$ is measurable for all $\alpha \in \mathbb{Q}$.
\end{enumerate}
We can replace $\mathbb{Q}$ by $\mathbb{R}$ in the above statement.
\end{theorem_exam}

\begin{proof} First, define the collection of sets $\algebra = \{[(\alpha, \infty]]: \alpha \in \mathbb{Q}\}.$ Then, if $X^{-1}(A) \in \sigmalgebra$ for all $A \in \algebra$, this means that 
$$
X^{-1}(B) \in \sigmalgebra
$$
for all sets B in the $\sa$ generated $\sigma(\algebra).$ However, recall that by definition, the Borel $\sa$ $\borelsigmaalgebra$ is generated by
$$
\borelsigmaalgebra = \sigma(\algebra)
$$
Therefore, we have shown that every Borel set has a measurable preimage and therefore by definition, X is a random variable.
\end{proof}

\begin{definition_exam}{$\sigma$-algebra generated by random variable}{}Let $X: \Omega \rightarrow \mathbb{R}$ be a random variable. The set $$\sigma(X) = \mathcal{G} = \{X^{-1}(B): B \in \borelsigmaalgebra\}$$ is called the $\sigma-$algebra generated by the random variable X where $\borelsigmaalgebra$ is the Borel $\sa$ and it is denoted by $\sigma(X).$
\end{definition_exam}
We investigate the above definition.

\begin{proposition_exam}{Smallest $\sa$ generated by random variable}{}Let $X: \Omega \rightarrow \mathbb{R}$ and let $$\sigma(X) = \mathcal{G} = \{X^{-1}(B): B \in \borelsigmaalgebra\}$$ where $\borelsigmaalgebra$ is the Borel $\sa.$ Then $\sigma(X) = \mathcal{G}$ is a $\sigma-$algebra and is the smallest one for which X is a random variable.
\end{proposition_exam}

\begin{proof}(Sketch). It is straightforward to show that $\mathcal{G}$ is a $\sa.$ However, to show that $\mathcal{G}$ is the smallest one is not as easy. First, recall that the Borel $\sa$ is generated by $\borelsigmaalgebra = \sigma(\algebra)$ where $\algebra$ is the semi-algebra of all open intervals. To show that $\mathcal{G}$ is the smallest $\sa$ for which $X$ is a random variable, we need to show that 
$$
\mathcal{G} = X^{-1}(\sigma(\algebra)) = \sigma(X^{-1}(\algebra))
$$
where the right hand term indicates that $\mathcal{G}$ is the smallest $\sa.$ 

$\rightarrow$ First, as $\algebra \subseteq \sigma(\algebra)$ this means that 
$$
X^{-1}(\algebra) \subseteq X^{-1}(\sigma(\algebra))
$$
Now, recall that $X^{-1}(\sigma(\algebra))$ is a $\sa.$ By minimality, this means that 
$$
\sigma(X^{-1}(\algebra)) \subseteq X^{-1}(\sigma(\algebra))
$$
$\leftarrow$ Define the collection of sets 
$$
\sigmalgebra_2 = \{B \subset \mathbb{R}: X^{-1}(B) \in \sigma(X^{-1}(\algebra)) \}
$$
It is easy to show that $\sigmalgebra_2$ is a $\sa.$ By definition,
\begin{equation}
X^{-1}(\sigmalgebra_2) \subset \sigma(X^{-1}(\algebra))
\tag{*}
\end{equation}
Also, since $X^{-1}(\algebra) \subset \sigma(X^{-1}(\algebra))$, this means that $\algebra \subset \sigmalgebra_2$ and therefore
\begin{equation}
\sigma(\algebra) \subseteq \sigmalgebra_2
\tag{**}
\end{equation}
as $\sigmalgebra_2$ is a $\sa.$ Combining both (*) and (**), we therefore have 
$$
X^{-1}(\sigma(\algebra)) \subseteq X^{-1}(\sigmalgebra_2) \subset \sigma(X^{-1}(\algebra))
$$
and hence we can conclude that $X^{-1}(\sigma(\algebra)) \subseteq \sigma(X^{-1}(\algebra)).$

From this, we can therefore conclude that 
$$
\mathcal{G} = X^{-1}(\sigma(\algebra)) = \sigma(X^{-1}(\algebra))
$$
and hence, $\mathcal{G}$ is the smallest $\sa$ for which X is a random variable.
\end{proof}



\begin{lemma}Let $A \subset \Omega$ and let $\mathcal{F}$ be a $\sigma$-algebra. Then, the indicator function $1_A$ is a random variable if and only if $A \in \mathcal{F}.$
\end{lemma}


\begin{definition_exam}{$\sa$ generated by collection of random variables}{}If $X_1,X_2,...$ are maps where $X_i: \Omega \rightarrow \mathbb{R}$, then the $\sigma-$algebra generated by $X_1,...,X_n$ for all $n \in \mathbb{N}$ is the smallest $\sigma-$algebra with respect to which $X_1,...,X_n$ are random variables. We denote this by $$\sigma(X_1,...,X_n) = \bigcup_{i=1}^{n}\sigma(X_i)$$
\end{definition_exam}

\begin{claim}For all $n \in \mathbb{N} \cup \{\infty\}$, we have that 
$$
\sigma(X_1,...,X_n) = \sigma(\sigma(X_1),...,\sigma(X_n)).
$$
\end{claim}


\begin{definition_exam}{Borel function}{} Let $f: (\mathbb{R},\mathbb{B}) \rightarrow (\mathbb{R},\mathbb{B})$ be a measurable function with respect to the Borel $\sa$ $\borelsigmaalgebra$. Then, f is known as a \textbf{Borel function}.
\end{definition_exam}

\begin{proposition_exam}{Continuous and Borel Functions}{}Define the function $f: (\mathbb{R},\mathbb{B}) \rightarrow (\mathbb{R},\mathbb{B}).$

\begin{enumerate}
\item If f is a continuous function, then f is a Borel-measurable function.
\item If f is a monotone function, then f is a Borel-measurable function.
\end{enumerate}
\end{proposition_exam}
\begin{proof} Suppose that f is a continuous function. Then, construct the set 
$$
\mathcal{L} = \{f^{-1}[O]: O \in \borelsigmaalgebra\}
$$
where due to the fact that f is continuous, all elements of $\mathcal{L}$ will be an open set. In fact, $\mathcal{L}$ is a $\sa$ which contains all open sets in $\borelsigmaalgebra.$ But, by definition, this is the Borel $\sa$ and hence f is measurable with respect to the Borel $\sa.$
\newline 

Recall that a function is measurable if $f^{-1}[(-\infty,a]] \in \sigmalgebra$ for all $a \in \mathbb{Q}.$ Now, WLOG, assume that f is monotone increasing. Then, notice that 
$$
\{f^{-1}[(-\infty,a]]\} = \{t: f(t) \leq a\}
$$
The set $\{t: f(t) \leq a\}$ will be either 
\begin{enumerate}
\item $\emptyset$
\item $\mathbb{R}$
\item $(-\infty, z]$
\end{enumerate}
Clearly, $\emptyset, \mathbb{R} \in \borelsigmaalgebra.$ Now, for (3), let $a \in \mathbb{R}$ and therefore we are interested in the set $\{t: f(t) \leq a\}.$ Then, if 
$$
x \in \{t: f(t) \leq a\}
$$
we have that for all $y < x$, by monotonicity of f, $f(y) < f(x) \leq a$ and hence 
$$
y \in \{t: f(t) \leq a\}
$$
With this in mind, define $b = \sup\{t: f(t) \leq a\}$ and therefore 
$$
\{t: f(t) \leq a\} = (-\infty, b]
$$
which is a Borel set. Hence, the preimage of all Borel sets $(-\infty, a]$ is a Borel set $(-\infty, b].$ Hence, f is Borel measurable.
\end{proof}


\begin{remark}All continuous functions are Borel functions, but not all Borel functions are continuous. Likewise, not all measurable functions are Borel measurable.
\end{remark}


\begin{proposition}Let $(\Omega, \mathcal{F}, P)$ be a probability space and Y, Z be metric spaces. If $f: X \rightarrow Y$ is measurable and $\phi: Y \rightarrow Z$ is continuous, then 
$$
\phi \circ f: X \rightarrow Z
$$
is \textbf{measurable}.
\end{proposition}

\begin{proof} Let U be an open set in Z. Then $\phi^{-1}[U]$ is an open set in Y. Furthermore, $f^{-1}[\phi^{-1}[U]] \in \mathcal{A}.$ 
\end{proof}

\begin{remark}If we are working on the real line $\mathbb{R}$, we in fact only require $\phi$ is a Borel function (measurable). Recall that every continuous function is a Borel function.
\end{remark}

\begin{proposition}Let $(\Omega, \mathcal{F}, P)$ be a probability space. Let $f = (f_1,...,f_k): \Omega \rightarrow \mathbb{R}^k$ be a function. Then f is measurable if and only if every component function $f_k: \Omega \rightarrow \mathbb{R}$ is measurable.
\end{proposition}

So now, with the last 2 propositions, we can construct new random variables by viewing them as compositions of measurable and continuous functions.
\begin{theorem_exam}{Operations on Random Variables}{}Let X and Y be random variables and $f:(\mathbb{R},\mathbb{B}) \rightarrow (\mathbb{R},\mathbb{B})$ be a Borel function. Then the following operations yields random variables
\begin{enumerate}
\item X+Y
\item X $\cdot$ Y
\item $\frac{X}{Y}$ \text{ if Y} $\neq$ 0
\item f(X)
\item $|X|$, max(X,Y), min(X,Y).
\end{enumerate}
\end{theorem_exam}

\begin{proof}(Sketch). Define the function $F(\omega) = (X(\omega), Y(\omega)),$ which is a measurable function as $X, Y$ are measurable functions respectively. Then, $\psi(x,y) = x+ y$ is a continuous function. Hence, 
$$
\psi \circ F
$$
is a Borel measurable function.
\end{proof}

\begin{remark}Note that for max, we can express that as 
$$
\max(X,Y) = \frac{1}{2}\bigg(X + Y + |X - Y|\bigg)
$$
\end{remark}


In the context of limits, it is convenient to allow random variables to attain the value of $\pm \infty$. In particular, we define the extended Borel $\sa$ as $\overline{\borelsigmaalgebra} = \sigma([-\infty,x): x \in \mathbb{R}).$ Hence a function $X: (\Omega, \sigmalgebra) \rightarrow (\overline{\mathbb{R}}, \overline{\borelsigmaalgebra})$ is a random variable if it is measurable.

\begin{theorem_exam}{Sequence of random variables}{}Let $(\Omega, \mathcal{F}, P)$ be a probability space. If $X_n \coloneqq \{X_n\}_{n \geq 1}$ are a sequence of random variables, then so is 
\begin{enumerate}
\item $\inf X_n$
\item $\sup X_n$
\item $\lim \inf\;X_n$
\item $\lim \sup\;X_n$
\end{enumerate}
Moreover, if $X_n \rightarrow X$ pointwise, then X is a random variable.
\end{theorem_exam}

\begin{proof}(Sketch). Recall that if $X^{-1}[[\alpha, \infty]]$ is measurable for all $\alpha \in \mathbb{R}$, then X is measurable. Suppose that $inf\;X_n \geq \alpha$ for $\alpha \in \mathbb{R}$. This implies that $X_n(\omega) \geq \alpha$ for all $n \in \mathbb{N}.$ Then 
$$
inf\;X_n^{-1}\bigg[[\alpha, \infty] \bigg] = \bigcap_{n \in \mathbb{N}}X_{n}^{-1}\bigg[[\alpha, \infty] \bigg]
$$
is measurable since $X_n$ is measurable (random variable) for all $n \in \mathbb{N}$. Now, $\sup X_n = -\inf (-X_n)$ to show that $\sup X_n$ is measurable.\\ Recall that $\lim \inf\;X_n = \sup_{n \in \mathbb{N}}\bigg(\inf_{k \geq n}\{X_k, X_{k+1}, ....\bigg)$. Then applying the fact that the supremum and infimum of random variables is random variable, we get our result.\\
Finally, if $X_n \rightarrow X$ pointwise, then the $\lim \inf\;X_n = \lim \sup\;X_n = X$ and hence X is a random variable.
\end{proof}

\begin{remark}One of the useful things is that limits preserves measurability of functions unlike continuity.
\end{remark}

\subsection{Distributions of random variables}
Random variables $X$ induces a probability measures on $(\real, \borelsigmaalgebra)$ called its \textbf{distribution}.

\begin{definition_exam}{Distribution function}{}Let $X:(\Omega, \mathcal{F}, \prob) \rightarrow (\mathbb{R}, \mathbb{B})$ be a random variable, where $\prob$ is a probability measure on $(\Omega, \mathcal{F}).$ Then, the random variable X induces a probability measure on $(\mathbb{R}, \mathbb{B})$ called its \textbf{distribution} 
$$
\mu(A) = \prob(\{\omega: X(\omega) \in A\}) = \prob(X \in A)
$$
for all Borel sets $A \in \mathbb{B}.$
\end{definition_exam}

\begin{remark}Note that the distribution pulls the Borel set $A \subset \mathbb{R}$ back to $(\Omega, \mathcal{F}, \prob)$ and we apply the probability measure $\prob$ to it.
\end{remark}

\begin{claim}The triple $(\mathbb{R}, \mathbb{B}, \mu)$ is a probability space.
\end{claim}

\begin{proof} First, recall that for a Borel set $A \subset \mathbb{B}$, we have that $\mu(A) = \prob(\{\omega: X(\omega) \in A\}).$ Now, let $\{A_i\}_{i \in I}$ be disjoint Borel sets. Now, since $A_i$ are disjoint, this means that if $X \in \cup_iA_i$, then it is only in 1 $A_j$. Furthermore, as $\omega$ cannot be mapped to multiple $A_i$, then $\{\omega: X(\omega) \in A_i\} \subset \mathcal{F}$ are disjoint. So, we have 
$$
\mu(\cup_iA_i) = \prob(\{\omega: X(\omega) \in \cup_iA_i\}) = \prob(\cup_i\{\omega: X(\omega) \in A_i\})= \sum_i\prob(\{\omega: X(\omega) \in A_i\}) = \sum_i\mu(A_i).
$$
\end{proof}


However, we normally describe the distribution of a random variable through its distribution function, also known as the cumulative distribution function.


\begin{definition_exam}{Distribution Function}{}Let $X: (\Omega, \mathcal{F}, \prob) \rightarrow (\mathbb{R}, \mathbb{B}, \mu)$ be a random variable. The distribution \textbf{distribution function} $F_X$ of the random variable X is
$$
F_X(x) = \mu((-\infty, x]) = \prob(X \leq x) = \prob(\{\omega: X(\omega) \leq x\})
$$
for $x \in \mathbb{R}.$
\end{definition_exam}

We now state properties associated to the CDF.

\begin{theorem_exam}{Properties of CDF}{}Let F be the Cumulative Distribution Function for a random variable X. Then, F satisfies the following properties: 
\begin{enumerate}
\item $F$ is non-decreasing;
\item $\lim_{x \rightarrow \infty}F(x) = 1$ and $\lim_{x \rightarrow -\infty}F(x) = 0$
\item F(x) is right continuous
\item $F(X_-) = \lim_{t \rightarrow x^-}F(x) = P(X \leq x)$
\item $P(X = x) = F(x) - F(x_-).$
\end{enumerate}
\end{theorem_exam}

\begin{proof} (1). Let $x \leq y$, then $\{X \leq x\} \subseteq \{X \leq y\}.$ Then, by monotonicty of the probability measure
$$
F(x) = \prob(X \leq x) \leq \prob(X \leq y) = F(y)
$$
(2). As $x \rightarrow \infty$, then $\{\omega: X(\omega) \leq x\} \rightarrow \Omega.$ Therefore $\prob(\Omega) = 1.$ Likewise, $\{\omega: X(\omega) \leq x\} \rightarrow \emptyset$ as $x \rightarrow -\infty.$
\newline
(3). We want to show that 
$$
\lim_{y \rightarrow x^+}F(y) = F(x).
$$
So then, define the sequence $(x, y_n] \downarrow \emptyset$, which means that 
$$
(x, y_1] \supseteq (x, y_2] \supseteq ...
$$
Then, we have that 
$$
\bigcap_n(x, y_n] = (x,x] = \emptyset.
$$
Now, applying the CDF to this 
$$
F(y_n) - F(x) = \prob((x, y_n]) \rightarrow 0
$$
and therefore we have that 
$$
F(y_n) \downarrow F(x).
$$
\end{proof}

\begin{theorem_exam}{Every CDF is associated to a random variable}{}If a function F satisfies
\begin{enumerate}
\item $F$ is non-decreasing;
\item $\lim_{x \rightarrow \infty}F(x) = 1$ and $\lim_{x \rightarrow -\infty}F(x) = 0$
\item F(x) is right continuous
\end{enumerate}
then it is the CDF of some random variable.
\end{theorem_exam}


\begin{remark}Recall that if a function F satisfies (1) and (3), then there exists a unique measure on $(\mathbb{R}, \mathbb{B})$ with $\mu[a,b] = F(b) - F(a)$ which we called the Lebesgue-Stieltjes measure. Let $(\Omega, \mathcal{F}, P) = (\mathbb{R}, \mathbb{B}, \mu)$ and define $X(\omega) = \omega.$ Then, P is a probability measure and $F_X = F$
\end{remark}


\begin{definition_exam}{Equal in distribution}{} Let X and Y be random variables defined on the same measurable spaces $(\Omega, \mathcal{F}).$ We say that X and Y are equal in distribution if they induce the same distribution $\mu$ on $(\mathbb{R}, \mathbb{B})$. That is
$$
P(X \leq x) = F_X(x) = \mu((-\infty, x]) = F_Y(x) = P(Y \leq x)
$$
for all $x \in \mathbb{R}$.
\end{definition_exam}


\lecture{5}{Independence}
\section{Independence}
\section{Independence}
\subsection{Independence of sets of events}

We first recall definitions from elementary probability theory. Remember, that we can interpret $\sigma-$algebras as description of information. What we will do is to generalise the notions of independence of events to the notion of independence of information.
\begin{definition_exam}{Independence of a finite number of events}{} Suppose $(\Omega, \sigmalgebra, \prob)$ is a probability space. The events $A_1,A_2,...,A_n$ are independent if 

$$
\prob(\bigcap_{i \in I}A_i) = \prod_{i \in I}\prob(A_i)
$$
for all finite $I \subset \{1,...,n\}.$
\end{definition_exam}

\begin{remark}Note that for the criterion of independence of a finite number of events, we require 
$$
\sum_{k=2}^n{n \choose k} = 2^n - n - 1
$$
equations to hold in order for the collection of events to be independent.
\end{remark}

These notions of independence of sets hold for their complements too.
\begin{claim}If $A_1,...,A_n$ are independent events, then so are $A_1^c,A_2,...,A_n$.
\end{claim}

\begin{proof} We have that 
$$
\prob(\bigcap_{i=1}^{n}A_i) = \prod_{i=1}^{n}\prob(A_i)
$$
So now, let $A_1^c$ be our first event. Then, we have that 
$$
\prob(A_1^c \cap \bigg( \bigcap_{i=2}^{n} A_i \bigg) ) = \prob(\bigcap_{i=2}^{n}A_i \setminus (\cap_{i=2}^{n}A_i \cap A_1)) = \prob(\cap_{i=2}^{n}A_i) - \prob(\cap_{i=2}^{n}A_i \cap A_1)
$$
$$
= \prod_{i=2}^{n}\prob(A_i) - \prod_{i=1}^{n}\prob(A_i) = \prod_{i=2}^{n}\prob(A_i)\bigg[1 - \prob(A_1) \bigg] = \prod_{i=2}^{n}\prob(A_i)\prob(A_1^c)
$$
\end{proof}

\begin{claim}If $A_1,...,A_n$ are independent if and only if $B_1,...,B_n$ are independent, where for each i, $B_i = A_i$ or $B_i = A_i^c.$
\end{claim}

\begin{proof} Use induction to repeatedly apply the previous claim.
\end{proof}

\begin{proposition_exam}{Equivalent formulation of independence of events}{} Suppose $(\Omega, \sigmalgebra, \prob)$ is a probability space. The events $A_1,A_2,...,A_n$ are independent if 
$$
P(\bigcap_{i=1}^n B_i) = \prod_{i=1}^nP(B_i)
$$
where for each i = 1,...,n, $B_i$ equals either $A_i$ or $\Omega.$
\end{proposition_exam}



We can extend the notion of independence of events to independence for \textbf{sets of events}. However, recall that on our probability space $(\Omega, \sigmalgebra, \prob),$ we have 1 main $\sigmalgebra$ and we can construct sub-$\sa$ from it.


\begin{definition_exam}{Sub-$\sigma$-algebra}{} Let $(\Omega, \mathcal{F}, P)$ be a probability space. A set $g \subset 2^{\Omega}$ is a sub$-\sigma-$algebra of $\mathcal{F}$ if $g$ is a $\sigma$-algebra and $g \subset \mathcal{F}.$
\end{definition_exam}


\begin{definition_exam}{Independence of sub-$\sigma-$algebra}{} Let $(\Omega, \mathcal{F}, P)$ be a probability space. The sub-$\sigma-$algebras $g_1,...,g_n$ are independent if whenever $A_i \in g_i$ for i=1,...,n, we have that 
$$
P(\bigcap_{1}^nA_i) = \prod_{1}^nP(A_i).
$$
\end{definition_exam}

Recall earlier definitions of random variables.


\begin{definition}(Independence of random variables). Random variables $X_1,...,X_n$ are independent if for any Borel set $B_i \in \mathcal{B}$
$$
P(X_1 \in B_1, ..., X_n \in B_n) = \prod_{i=1}^{n}P(X_i \in B_i)  = \prod_{1}^kP(\{\omega: X_i(\omega) \in B_i\}).
$$
\end{definition}



\begin{proposition}(Sub-$\sa$-generated by indicator function). Suppose $(\Omega, \sigmalgebra, \prob)$ is a probability space. Let $1_{A}$ be the indicator function for the measurable set $A \in \sigmalgebra$. Then, the sub-$\sa$ generated by the indicator function is
$$
\sigma(1_{A}) = \{\emptyset, \Omega, A, A^c\}.
$$
\end{proposition}


If we had a collection $\{\mathcal{F}_i\}_{i \in I}$ of sub-$\sigma-$algebras, we can think that each $\mathcal{F}_i$ represents some information. We now make teh connection between independent events and random variables.

\begin{proposition_exam}{Relating independent events to independent random variables}{}For $A_1,...,A_n \in \mathcal{F}$, the following are equivalent:
\begin{enumerate}
\item $A_i$ are independent events;
\item The indicator functions $1_{A_{i}}$ are independent random variables;
\item The sub-$\sigma$-algebras generated by the indicator function $1_{A_{i}}$, given by $g_i = \sigma(A_{i}) = \{\emptyset, \Omega, A_i, A_i^c\}$ are independent for $i \in I$.
\end{enumerate}
\end{proposition_exam}

\begin{proof} (1 $\rightarrow 2$). First, recall that 
$$
\{1_A = a\} = \{\omega: 1_A(\omega) = a\} = 
\begin{cases}
A \quad \text{if }a = 1\\
A^c \quad \text{if }a = 0\\
\emptyset \quad \text{if }a \neq 0, 1
\end{cases}
$$
Therefore, we can say that 
$$
\prob(1_A = 1) = \prob(A) \quad \prob(1_A = 0) = \prob(A^c)
$$
WLOG, let us look at n = 2. Then,
$$
\prob(1_{A_{1}} = 1, 1_{A_{2}} = 1) = \prob(A_1 \cap A_2) = \prob(A_1)\cdot \prob(A_2) = \prob(1_{A_{1}} = 1)\cdot \prob(1_{A_{2}} = 1)
$$
since $A_1, A_2$ are independent by assumption. Likewise, we can do something similar for 
$$
\prob(1_{A_{1}} = 0, 1_{A_{2}} = 1) = \prob(A_1^c \cap A_2) = \prob(A_1^c)\cdot \prob(A_2) = \prob(1_{A_{1}} = 0)\cdot \prob(1_{A_{2}} = 1)
$$
We can repeat this for all other cases to show that $1_{A_{1}}$ and $1_{A_{2}}$ are independent random variables. Furthermore, we can show by induction that this holds for $n \geq 2$ independent events.
\newline 

$(2 \rightarrow 3).$ We have that the sub-$\sa$ generated by the indicator function $1_{A_{i}}$ is 
$$
\sigma(1_{A_i}) = \{\emptyset, \Omega, A_i, A_i^c\}.
$$

Define $B_i = \{\emptyset, \Omega, A_i, A_i^c\}$ where $B_i \in g_i.$ Then, as $1_{A_{i}}$ are independent, then $A_i$ are independent. From earlier results, we then have that $B_i$ are independent. Therefore, we have that 
$$
\prob(\bigcap_{i=1}^{n}B_i) = \prod_{i=1}^{n}\prob(B_i)
$$
for $B_i \in g_i$ and therefore the sub-$\sa$ $g_i$ are independent.
\newline 

$(3 \rightarrow 1).$ For each $g_i$, define $B_i = A_i.$ Then, as $g_i$ is independent, then 
$$
\prob(\bigcap_{i=1}^{n}A_i) = \prob(\bigcap_{i=1}^{n}B_i) = \prod_{i=1}^{n}\prob(B_i) = \prod_{i=1}^{n}\prob(A_i)
$$
and therefore $A_i$ are independent events.
\end{proof}

We can come up with a new notion of independence for random variables.
\begin{theorem_exam}{Independence of random variables}{}The collection of random variables $\{X_i\}_{1 \leq i \leq n}$ are independent if and only if the collection of sub-$\sigma-$algebras generated by random variables $$\{\sigma(X_i)\}_{1 \leq i \leq n}$$ are independent.
\end{theorem_exam}
\begin{proof}(Sketch). As $X_1,...,X_n$ are independent, then for any Borel set $B_i \in \mathcal{B}$, we have that
$$
P(X_1 \in B_1, ..., X_n \in B_n) = \prod_{i=1}^{n}P(X_i \in B_i)  = \prod_{1}^kP(\{\omega: X_i(\omega) \in B_i\}).
$$
As $\{X \in B_j\} = \sigma(X)$ for all Borel sets $B_j \in \borelsigmaalgebra,$ it then follows that $\{\sigma(X_i)\}_{1 \leq i \leq n}$ are independent.
\end{proof}

\begin{theorem_exam}{Indepedent random variables and $\sa$}{}If $\mathcal{G}_1,...,\mathcal{G}_n$ are independent $\sigma-$algebras and if $X_i \in \mathcal{G}_i$ (i.e. $\sigma(X_i) \subset \mathcal{G}_i$) then $X_1,...,X_n$ are \textbf{independent} random variables.
\end{theorem_exam}

\begin{proof} As $\sigma(X_i) \subset \mathcal{G}_i$ and $\mathcal{G}_i$ are independent, then $\sigma(X_i)$ are independent. Therefore, from the previous result, $X_i$ are also independent.
\end{proof}


We can now extend the notion of independence to sets of events $\algebra_1, ..., \algebra_n$.

\begin{definition_exam}{Independence for sets of events}{}Define the probabiliy space $(\Omega, \sigmalgebra, \prob).$ Define sets of events $\algebra_1,...,\algebra_n$, where for each i, we have that 
$
\algebra_i \subset \sigmalgebra
$
 and $\Omega \in \sigmalgebra_i.$ Then, $\algebra_i$ are independent if for any choice of $A_i \in \algebra_i$ for i = 1,...,n, we have that 
 $$
\prob(\cap_{i=1}^{n}A_i) = \prod_{i=1}^{n}\prob(A_i).
 $$
\end{definition_exam}

\begin{proposition} The sets of events $\algebra_1,...,\algebra_n$ are independent if and only if whenever $A_i \in \algebra$ for i = 1,...,n are independent events.
\end{proposition}

\begin{proof} This follows by definition. 
\end{proof}

We can now describe a result which allows for us to test for independence in an efficient manner.

\begin{theorem}(Test for independence). Suppose $(\Omega, \sigmalgebra, \prob)$ is a probability space. Suppose that for i = 1,...,n we have that the collection of sets, $\mathcal{A}_i \subset \mathcal{F}$ which satisfies 
\begin{enumerate}
\item $\Omega \in \mathcal{A}_i$
\item $\mathcal{A}_i$ is a $\pi-$system
\item $\mathcal{A}_1,...,\mathcal{A}_n$ are independent.
\end{enumerate}
Then, $\sigma(\mathcal{A}_1), \mathcal{A}_2,...,\mathcal{A}_n$ are independent.
\end{theorem}

\begin{proof}(Sketch). First, for n = 2, fix an event $A_2 \in \algebra_2.$ Then, define the set of all independent events 
$$
\mathcal{L} = \{A \in \sigmalgebra: \prob(A A_2) = \prob(A)\prob(A_2) \}
$$
Then, we can show that $\mathcal{L}$ is a $\lambda-$system. Furthermore, it is clear that $\algebra_1 \subset \mathcal{L}$. Then, by Dynkin's $\pi-\lambda$ theorem, we have that 
$$
\sigma(\algebra_1) \subset \mathcal{L}
$$
using the fact that $\algebra_1$ is a $\pi-$system. Therefore, $\sigma(\algebra_1), \algebra_2$ are independent. We can then extend this argument by induction to show that $\sigma(\algebra_1), \algebra_2,...,\algebra_n$ are independent. 
\end{proof}

The following corollary is what we really care about.

\begin{theorem_exam}{Criterion for independence}{}Suppose $(\Omega, \sigmalgebra, \prob)$ is a probability space. Let $\mathcal{A}_i$ be a collection of classes of events satisfying:
\begin{enumerate}
\item $\Omega \in \mathcal{A}_i$
\item $\mathcal{A}_i$ is a $\pi-$system
\item $\mathcal{A}_1,...,\mathcal{A}_n$ are independent.
\end{enumerate}
Then, we have that
$$
\sigma(\mathcal{A}_1),\sigma(\mathcal{A}_2),...,\sigma(\mathcal{A}_n)
$$
are independent classes of events.
\end{theorem_exam}


A typical example of the application of our independence critera is the independence of random variables using their cumulative distribution functions.

\begin{theorem_exam}{Independence of random variables through CDF}{} The random variables $X_1,...,X_n$ are independent if and only if their CDFs
$$
P(\bigcap_{1}^n\{X_i \leq x_i\}) = \prod_1^nP(X_i \leq x_i)
$$
for all $x_i \in \overline{\mathbb{R}}.$
\end{theorem_exam}

\begin{proof} (Sketch). First, recall the fact that $\{(-\infty,x]: x \in \mathbb{R}\}$ is a $\pi-$system on $\mathbb{R}.$ Then, $\algebra_i \subset \sigmalgebra$ and $\sigma(\algebra_i) = \sigma(X_i).$ It then follows by the criterion for independence that $X_1,...,X_n$ are independent.
\end{proof}



\subsection{Second Borel-Cantelli Lemma and Kolmogorov's 0-1 Law}
Recall that the first Borel-Cantelli lemma states that whenever the probabilities of the events $A_n$ decay fast enough, then it is (almost surely) impossible for the events to occur infinitely often.

The second Borel-Cantelli lemma states that if the probabilities of the events $A_n$ do not decay fast, and additionally if the events are independent, then the events must (almost surely) occur infinitely often.

\begin{theorem_exam}{The second Borel-Cantelli Lemma}{}Suppose $(\Omega, \sigmalgebra, \prob)$ is a probability space. Let $A_n \in \sigmalgebra$ be a sequence of \textbf{independent} events such that $\sum_{k=1}^{\infty}P(A_k) = \infty.$ Then, $$\prob(A_n \text{ i.o.}) = 1.$$
\end{theorem_exam}

\begin{proof} Define $p_n = \prob(A_n).$ Then, we have that 
$$
\prob(\bigcap_{n=m}^NA_n^c) = \prod_{n = m}^N\bigg(1 - \prob(A_n) \bigg) \leq \prod_{n=m}^{N}e^{-\prob(A_n)} = e^{-\sum_{n=m}^N\prob(A_n)} \rightarrow 0
$$
as $n \rightarrow \infty.$ Therefore, we have that 
$$
\prob(\bigcap_{n=m}^{\infty}A_n^c) = 0.
$$
Then, recall that $(A_n \text{ i.o.})^c = (A_n^c \text{ eventually})$ and therefore 
$$
\prob((A_n \text{ i.o.})^c) = \prob(\bigcup_{m = 1}^{\infty}\bigcap_{n = m}^{\infty}A_n^c) = 0
$$
and therefore, we can conclude that 
$$
\prob((A_n \text{ i.o.})) = 1.
$$
\end{proof}

\begin{remark} This is known as Borel zero-one law in some places.
\end{remark}

\subsection{Kolmogorovs 0-1 law}

We now work towards Kolmogorovs 0-1 law which states that under the independence assumption, any event which is not sensitive to finitely many individual values, has probability either zero or one.

Let $\{X_i\}_{i \geq 1}$ be a sequence of random variables. We can define 
$$
\sigma(X_1,X_2,...) = \sigma(\{X_i\}_{i \in \mathbb{N}})
$$
and interpret this as the information contained in the entire sequence.

We note that 
$$
\mathcal{T}_n = \sigma(X_{n+1}, X_{n+2},...)
$$
can be interpreted as the information contained in the sequence without its first n members. That is, $\mathcal{T}_n$ can be interpreted as the information in the sequence which is not affected by the first n values.

\begin{definition_exam}{Tail $\sigma-$algebra}{}Let $X_1,X_2,...$ be random variables and define 
$$
\mathcal{T}_n = \sigma(X_{n+1},X_{n+2},...)
$$
for $n \in \mathbb{N}.$ Then, define
$$
\mathcal{T} = \bigcap_{n=0}^{\infty}\mathcal{T}_n.
$$
We have that $\mathcal{T}$ is called the \textbf{tail $\sigma-$algebra} of the sequence $\{X_n\}$. The events $A \in \mathcal{T}$ are called \textbf{tail events}.
\end{definition_exam}

Recall that the intersection of $\sigma-$algebras is a $\sigma-$algebra. As $\mathcal{T}$ contains less information than any $\mathcal{T}_k$ for $k \in \mathbb{N}$, it describes the information which is not affected by any finite number of changes in the sequence. 

\begin{lemma}Let $\mathcal{T}$ be the tail $\sigma-$algebra. We have that 
$$
\mathcal{T} \subset ... \subset \mathcal{T}_{k+1} \subset \mathcal{T}_{k} \subset ... \subset \mathcal{T}_2 \subset \mathcal{T}_1.
$$
\end{lemma}

That is, we have that the tail $\sigma-$algebra $\mathcal{T} \subset \sigma\bigg(\{X_i\}_{i \in I}\bigg).$

\begin{lemma}We have that 
$$
\mathcal{T} = \bigcap_{n=m}^{\infty}\mathcal{T}_n
$$
for any $m \in \mathbb{N}.$
\end{lemma}

We give some examples of tail events and random variables.
\begin{claim} Show that the following are tail events in $\mathcal{T}$
\begin{enumerate}
\item $\{\omega: \lim_{n}X_n(\omega) \text{ exists}\}$
\item $\{\omega: \sum_{i=1}^{\infty}X_n(\omega) \text{ converges}\}$
\item $\{\omega: \lim_{n}\frac{S_n(\omega)}{n} \text{ exists}\}$
\item $\{\omega: \overline{\lim}\frac{S_n(\omega)}{n} > 0\}$
\end{enumerate}
where $S_n = \sum_{i=1}^{n}X_i$.
\end{claim}

\begin{proof} (1)
\newline
(2) First, recall that $\sum_{n=1}^{\infty}X_n(\omega)$ converges if and only if $\sum_{n=m}^{\infty}X_n(\omega)$ converges. Therefore 
$$
(\sum_{n}^{\infty}X_n \text{ converges}) = (\sum_{n = m+1}^{\infty}X_n \text{ converges}) \in \mathcal{T}_m
$$
whereby this holds for all m and after intersecting over m.
\end{proof}


We now have an important result regarding the probabilities of tail events.

\begin{theorem_exam}{Kolmogorov's 0-1 Law}{}Suppose that $X_1,X_2,...$ is a sequence of independent random variables. Then for any tail event $A \in \mathcal{T}$, we have that either 
$$
P(A) = 0 \quad \text{or} \quad P(A) = 1.
$$
\end{theorem_exam}

We now look at some of the implications of Kolmogorovs 0-1 Law.

\begin{theorem}Suppose that $X_1,X_2,...$ is a sequence of independent random variables. Then, any $\mathbb{R}-$valued random variable Y that is measurable with respect to the tail $\sigma$-algebra $\mathcal{T}$ is \textbf{almost surely constant}, that is, there exists some $c \in \mathbb{R}$, such that
$$
P(Y = c) = 1.
$$
\end{theorem}

\begin{proof}(Sketch). Use Kolmogorovs 0-1 law where Y is a $\mathcal{T}-$measurable function. Then, define $c \coloneqq inf\{x \in \mathbb{R}: P(Y \leq y) = 1\}.$ Then, by the right-continuity of CDFs, we can get the desire result where $P(Y = c) = P(Y \leq c) - P(Y < c).$
\end{proof}

\begin{corollary}We have the following 3 corollaries.
\begin{enumerate}
\item If $A_1,A_2,...$ are independent events, then $P(A_n \text{ i.o.}) \in \{0,1\}.$
\item Define $S_n = \sum_{1}^{n}X_k$. Then $P(lim  S_n\;\text{exists}) \in \{0,1\}.$
\item $P(lim \frac{S_n}{n} = \mu) \in \{0,1\}.$
\end{enumerate}
\end{corollary}



\lecture{6}{Lebesgue Integration}
\section{Integration}
\section{Integration}
\subsection{Integration of Simple Functions}
We are now interested in constructing integrals over probability spaces.

\begin{definition_exam}{Simple functions}{} Let $(\Omega, \mathcal{F}, \mu)$ be a measure space. The function f is a \textbf{simple non-negative function} $f:\Omega \rightarrow \extendedreal$ if $$f(\omega) = \sum_{i=1}^{n}\alpha_i1_{A_{i}}(\omega)$$ where $A_i$ are \textbf{disjoint sets} with $A_i \in \mathcal{F}$ and $\alpha_i \in \mathbb{R}^+.$
\end{definition_exam}

\begin{remark}The representation of $f$ is not unique since we do not assume that $\alpha_i$ is unique.
\end{remark}

\begin{remark}If $A_i$ are not disjoint, we can set $B_k = A_k \cap (A_1 \cup A_2 \cup ... \cup A_{k-1})^c$. Then, $A_k = \bigcup_{j=0}^{n}A_k \cap B_j$ is a disjoint union. Hence, $1_{A_{k}} = \sum_{j=0}^n1_{A_k \cap B_j}.$ Therefore, our simple function can be expressed as 
$$
\sum_{k=0}^{n}\alpha_k1_{A_{k}} = \sum_{k=0}^n\sum_{j=0}^n\alpha_k 1_{A_{k} \cap B_{j}}. 
$$
\end{remark}

\begin{lemma}A simple function $f:(\Omega, \sigmalgebra) \rightarrow (\positivereal, \overline{\borelsigmaalgebra})$ is a \textbf{measurable} function.
\end{lemma}

\begin{proof} Recall that f is measurable if and only if $f^{-1}((-\infty,a]) \in \sigmalgebra$ for all $a \in \mathbb{R}.$ Then 
$$
f^{-1}((-\infty,a]) = \bigcup \{A_i: i \in \{1,2,...,n\} \text{ such that } \alpha_i \leq a\}
$$
As each $A_i$ is measurable, then the union is measurable and hence f is measurable.
\end{proof}

\begin{definition_exam}{Space of simple non-negative functions}{} We denote $\mathcal{S}^+$ as the set of \textbf{simple non-negative functions}.
\end{definition_exam}

\begin{remark}The space of simple functions form a \textbf{vector space}.
\end{remark}

\begin{proposition_exam}{Properties of Simple Functions}{}Let $(\Omega, \mathcal{F}, \mu)$ be a measure space. Let $f, g \in \mathcal{S}^+$. Then, the following are also in $\mathcal{S}^+$:
\begin{enumerate}
\item $\alpha f + \beta g$ for all $\alpha, \beta > 0$;
\item $f \cdot g$;
\item $\frac{f}{g}$ if $g(x) \neq 0$ for all $x \in X;$
\item $min(f,g)$ and $max(f,g)$.
\end{enumerate}

\end{proposition_exam}

\begin{proof}(Sketch). 
Recall that 
$$
max(f,g) = \frac{f + g + |f - g|}{2} \quad min(f,g) = \frac{f + g - |f - g|}{2}
$$
Then show that the sum of simple functions is a simple function, the scalar multiple of a simple function is a simple function, and the modulus of a simple function is a simple function.
\end{proof}



\begin{definition_exam}{Lebesgue Integral of Simple Functions}{}Let $(\Omega, \sigmalgebra, \mu)$ be a measure space and let $f = \sum_{i=1}^{n}\alpha_i 1_{A_{i}}$ be a simple function. The Lebesgue integral of f with respect to $\mu$ is defined as 
$$
\int_{\Omega} f(\omega)d\mu(d \omega) = \int_{\Omega}fd\mu = \sum_{i=1}^n\alpha_i\mu(A_i).
$$
where we define $0 \cdot \infty = \infty \cdot 0 = 0.$
\end{definition_exam}


\begin{example}(Lebesgue and Riemann integral agree on indicator function). Let $(\Omega, \sigmalgebra, \mu) = (\mathbb{R}, \mathbb{B}, \lambda)$ where $\lambda$ is the Lebesgue measure. Then, define $f = \alpha 1_{(a,b)}$ where $\alpha > 0$ and $-\infty < a < b < \infty.$ Then the Lebesgue integral is the same as the Riemann integral.
$$
\text{(Lebesgue)} \int fd\mu = \alpha \lambda((a,b)) = \alpha(b - a) = \int_{\mathbb{R}}f(x)dx \text(Riemann)
$$
\end{example}

\newpage
We have a potential issue as if a simple function has 2 different representation, the integrals may not be the same.
\begin{proposition_exam}{Integral of simple functions is well-defined}{}Let $(\Omega, \sigmalgebra, \mu)$ be a measure space. Let $f: \Omega \rightarrow \positiveextendedreal$ be a positive simple function. Then, for any two standard representations for f, that is 
$$
f = \sum_{i=0}^{n}a_i1_{A_{i}} = \sum_{j=0}^{m}b_j1_{B_{j}}
$$
for $E_i,F_j \in \sigmalgebra$. It holds that 
$$
\sum_{i=0}^{n}a_i\mu(A_{i}) = \sum_{j=0}^{m}b_j\mu(B_{j}).
$$
That is, the integral $\int_{\Omega}fd\mu$ is well-defined.
\end{proposition_exam}

\begin{proof}(Sketch). A simple function f may have two different representations 
$$
f = \sum_{i=0}^{n}a_i1_{A_{i}} = \sum_{j=0}^{m}b_j1_{B_{j}}
$$
However, the integral may give different results, which is undesirable
$$
\sum_{i=0}^{n}a_i\mu(A_{i}) \neq \sum_{j=0}^{m}b_j\mu(B_{j}).
$$
However, first recall we can partition the sample space $\Omega$ up
$$
\Omega = \cup_i\cup_j E_{ij} = \cup_i\cup_j (A_i \cap B_j)
$$
and that 
$$
A_i = \bigcup_{j=0}^{m}(A_i \cap B_j) \quad B_j = \bigcup_{i=0}^{n}(B_j \cap A_i)
$$
Therefore, we have that 
$$
\int fd\mu = \sum_{i=0}^{n}a_i\mu(A_i) = \sum_{i=0}^{n}a_i\mu(\bigcup_{j=0}^{m}(A_i \cap B_j)) = \sum_{i=0}^{n}\sum_{j=0}^{m}a_i\mu(A_i \cap B_j)
$$
$$
= \sum_{j=0}^{m}b_j1_{B_{j}} = \int fd\mu
$$
\end{proof}

\begin{proposition_exam}{Elementary Properties of Integrals}{}Let $(\Omega, \sigmalgebra, \mu)$ be a measure space. Let $f, g \in \mathcal{S}^+$. Then, we have that 
\begin{enumerate}
\item $\int(\alpha f + \beta g)d\mu = \alpha \int fd\mu + \beta \int g d\mu$;
\item If $f \leq g$, then $\int f d\mu \leq \int g d\mu$;
\end{enumerate}
\end{proposition_exam}

\begin{proof}(Sketch). Let $f = \sum_{i=1}^{n}\alpha_i1_{A_{i}}$ and $g = \sum_{j=1}^{m}\beta_j1_{B_{j}}.$ We then let $A_0 = \bigg(\cup_{1}^{n}A_i\bigg)^c$ and $B_0 = \bigg(\cup_{1}^{n}B_j\bigg)^c$. We also set $\alpha_0 = \beta_0 = 0.$ Then, we have 
$$
\begin{cases}
f = \sum_{i=0}^{n}\alpha_i1_{A_{i}}\\
g = \sum_{j=0}^{m}\beta_j1_{B_{j}}
\end{cases}
$$

Now, $\{A_i\}_{i=0}^{n}$ and $\{B_j\}_{j=0}^{m}$ are disjoint partitions of $\Omega$. Then $(A_i \cap B_j) \in \mathcal{F}$ and is also a partition of $\Omega$.

Hence
$$
f + g = \sum_{i=0}^{n}\sum_{j=0}^{m}(\alpha_i \beta_j)1_{A_i \cap B_j}.
$$

Then recalling that $A_i = \cup_{j=0}^{m}(A_i \cap B_j)$, we can get the result that 
$$
\int(f+g)d\mu = \sum_{i=0}^{n}\alpha_i\mu(A_i) + \sum_{j=0}^{m}\beta_j\mu(B_j) = \int fd\mu + \int g d\mu
$$
Additionally
$$
\int \alpha fd\mu = \sum_{i=0}^{n}\alpha \alpha_i \mu(A_i) = \alpha \sum_{i=0}^{n} \alpha_i \mu(A_i)
$$
Finally, as $f \leq g,$ this means that $g - f \geq 0.$ Then 
$$
\int gd\mu = \int fd\mu + \int (g - f)d\mu \geq \int f d\mu.
$$
\end{proof}

We now define what it means for integrals to not see sets of measure zero.

\begin{proposition_exam}{Integrals do not see sets of measure zero}{} Let $(\Omega, \mathcal{F}, \mu)$ be a measure space. Let $f \in \mathcal{S}^+$ Let N be a set of measure zero such that $f(\omega) = 0$ for all $\omega \in N$. Then 
$$
\int_{\Omega}fd\mu = \int_{X \text{\textbackslash} N}fd\mu.
$$
\end{proposition_exam}

\begin{proof} First, note that $f = 1_{\Omega \setminus N}f  + 1_{N}f$
$$
\int_{\Omega}fd\mu = \int_{\Omega}1_{\Omega \setminus N}f  + 1_{N}f d\mu = \int_{\Omega}1_{\Omega \setminus N}f d\mu + \int_{\Omega} 1_{N}f d\mu
$$
Now, we note that 
$$
\int_{\Omega} 1_{N}f d\mu = \sum_{i=0}^{n}1_N \alpha_i \mu(A_i \cap N) = \sum_{i=0}^{n} \alpha_i \mu(A_i \cap N) = 0
$$
because $\mu(A_i \cap N) \leq \mu(N) = 0.$
\end{proof}

\subsection{Integration of non-negative measurable functions}

\begin{definition_exam}{Set of all non-negative measurable functions}{}
We define $\mathcal{F}^+$ as the set of all $f: \Omega \rightarrow (\overline{\mathbb{R}}, \overline{\mathcal{B}})$ that are measurable and non-negative.
\end{definition_exam}

\begin{claim}The set of all non-negative measurable functions $\mathcal{F}^+$ is a vector space.
\end{claim}

We now state that every measurable function can be approximated by simple measurable functions. 
This will be very important for us when we want to take Lebesgue integrals of non-negative functions.
\begin{proposition_exam}{Simple Approximation Theorem}{} Let $(\Omega, \mathcal{F}, P)$ be a probability space and let $f: \Omega \rightarrow [0,\infty]$ be a measurable function. Then, there exists a sequence of simple measurable functions $\phi: \Omega \rightarrow [0, \infty)$ such that 
$$
0 \leq \phi_n(\omega) \leq \phi_{n+1}(\omega) \leq f(\omega)
$$
for all $n \in \mathbb{N}$ and all $\omega \in \Omega.$\\ Moreover, $\phi_n(\omega) \rightarrow f(\omega)$ as $n \rightarrow \infty$ for all $\omega \in \Omega.$ That is, $\phi_n \rightarrow f$ pointwise.
\end{proposition_exam}

With the Simple approximation theorem, we can now define Lebesgue integrals of non-negative functions.

\begin{definition_exam}{Lebesgue Integral of non-negative functions}{}Let $(\Omega, \mathcal{F}, \mu)$ be a measure space. The \textbf{Lebesgue integral} of $f \in \mathcal{F}^+$ with respect to $\mu$ is defined as 
$$
\int_{\Omega} f d\mu = \sup \bigg\{\int_{\Omega}hd\mu: h \leq f \text{ and }h \in \mathcal{S}^+  \bigg\}
$$
where $\sigmalgebra^+$ is the space of non-negative measurable functions and $\mathcal{S}^+$ is the space of simple measurable functions.
\end{definition_exam}

\begin{claim}If $f \in \mathcal{S}^+$, then the definition of the Lebesgue integral of simple functions agrees with the Lebesgue integral of non-negative functions.
\end{claim}


\begin{proposition_exam}{Properties of the Lebesgue integral of $\mathcal{F}^+$ functions}{}Let $f,g \in \mathcal{F}^+$ be measurable non-negative functions and $\alpha, \beta \in \geq 0.$ Then 
\begin{enumerate}
\item $f \leq g$ implies that $\int fd\mu \leq \int gd\mu$
\item $\int (\alpha f + \beta g)d\mu = \alpha \int fd\mu + \beta \int gd\mu.$
\end{enumerate}
\end{proposition_exam}

\begin{proof}(Sketch). First, using simple measurable functions such that $0 \leq \phi \leq f$ and $0 \leq \psi \leq g$, then by definition of supremum 
$$
\int fd\mu \leq \int gd\mu
$$
For the second result, again express the functions in terms of their simple functions and use previously shown properties of Lebesgue integral of simple functions.
\end{proof}



\begin{proposition}(Integral of functions equal almost everywhere). Let $(\Omega, \mathcal{F}, \mu)$ be a measure space. Let $f,g \in \mathcal{F}^+$. Let N be a set of measure zero where $f(\omega) = g(\omega)$ for all $\Omega \text{\textbackslash N}$. Then f = g \textbf{almost everywhere}. Furthermore, 
$$
\int_{\Omega}fd\mu = \int_{\Omega}gd\mu.
$$
\end{proposition}

\begin{proof}
Using the fact that the Lebesgue integrals does not see sets of measure zero, we have that 
$$
\int_{\Omega}fd\mu = \int_{\Omega}1_{\Omega \text{\textbackslash} N}fd\mu = \int_{\Omega}1_{\Omega \text{\textbackslash} N}gd\mu = \int_{\Omega}gd\mu.
$$
\end{proof}

\begin{proposition_exam}{A function is zero almost everywhere}{}Let $f \in \mathcal{F}^+$ be a non-negative measurable function. Then, $\int_{\Omega}fd\mu = 0$ if and only if $f = 0$ almost everywhere.
\end{proposition_exam}
\begin{remark}
As a result, if the integral of a non-negative function f is zero, we \textbf{cannot} conclude that the function f is the zero function.
\end{remark}

\begin{proposition_exam}{Functions are equal almost everywhere}{} Let $f, g \in \sigmalgebra^+$ be non-negative measurable functions. Assume that $f = g$ almost everywhere. Then 
$$
\int fd\mu = \int gd\mu.
$$
\end{proposition_exam}


We are now interested in figuring out how to actually compute the integral $\int fd\mu.$ We show an example of when we cannot switch the order of limits and integration.

\begin{example} Let $(\Omega, \sigmalgebra, \mu) = ([0,1], \borelsigmaalgebra, \lambda).$ Let $f_n = n1_{0, 1/n}$. Then 
$$
\int f_nd\mu = n[\frac{1}{n} - 0] = 1 
$$
but this does not converge to
$$
\int fd\mu = 0
$$
\end{example}





As a result of this example, we need to be careful to find a sequence of functions $f_n \uparrow f$ and therefore $\int f_nd\mu = \int fd\mu$. We state the condition for when we are allowed to interchange the limit and integral.

\begin{theorem_exam}{Weak Monotone Convergence Theorem}{}Let $(\Omega, \sigmalgebra, \mu)$ be a measure space. Suppose that $\{f_n\}$ is a sequence of simple non-negative functions $f_n \in \mathcal{S}^+$. Furthermore, assume that $f_n \uparrow f$ pointwise. Then $f \in \mathcal{F}^+$ is a non-negative measurable function. Furthermore, we have that 
$$
\lim_{n \rightarrow \infty}\int_{\Omega} f_nd\mu  = \int_{\Omega}\lim_{n \rightarrow \infty}f_nd\mu = \int_{\Omega} f d\mu.
$$
\end{theorem_exam}

\begin{remark} The "weak" part comes from the fact that $f_n \in \mathcal{S}^+.$ We can later make this $f_n \in \sigmalgebra^+.$
\end{remark}

\begin{claim}The lemma for the weak monotone convergence theorem holds for $f = 1_{A_{i}}$ where $A_i \in \mathcal{F}.$
\end{claim}

\begin{claim}The lemma for the weak monotone convergence theorem holds for $f \in \mathcal{S}^+.$
\end{claim}


\lecture{7}{Convergence Theorems and Integrability}
\section{Integration}
\subsection{Convergence Theorems}

First, we recall the definition of pointwise convergence.
\begin{definition}(Pointwise Convergent). Let $\{f_n\}_{n \geq 1}$ be a sequence of functions on the domain X. Then, $\{f_n\}_{n \geq 1}$ is said to be \textbf{Pointwise Convergent} to the function f if $\lim_{n \rightarrow \infty}f_n(x) = f(x)$ if for all $x \in X$. That is, for all $\epsilon > 0$, there exists a $N = N(\epsilon, x) \in \mathbb{N}$ such that if $n \geq N$, then 
$$
|f_n(x) - f(x)| < \epsilon.
$$
\end{definition}

Also, recall the following sufficient condition for convergence of a sequence.
\begin{claim}(Sufficient conditions for convergence of a sequence). If the sequence $\{a_n\}_{n \geq 1}$ is bounded and monotonic, then the sequence $\{a_n\}_{n \geq 1}$ is convergent.
\end{claim}

We state some important theorems. The MCT is one of the key results of Lebesgue integrals.

\begin{theorem_exam}{Monotone Convergence Theorem}{}Let $(X, \mathcal{A}, \mu)$ be a measure space. For every $n \in \mathbb{N}$, let $f_n \in \mathcal{F}^+$ and $0 \leq f_n(x) \leq f_{n+1}(x)$ for almost every $x \in X.$
Then, there exists a measurable function $f \in \mathcal{F}^+$ such that $f_n(x) \rightarrow f(x)$ as $n \rightarrow \infty$ for almost every $x \in X$ and 
$$
\lim_{n \rightarrow \infty}\int_X f_nd\mu = \int_X \lim_{n \rightarrow \infty}f_nd\mu = \int_X fd\mu.
$$
\end{theorem_exam}

\begin{remark}In lectures, we did not extend the MCT to holding almost everywhere when also considering null sets, but we do did this in the tutorials.
\end{remark}

We can also state a theorem that applies to \textbf{arbitrary} sequences of non-negative functions by using the limit inferior.

\begin{theorem_exam}{Fatou's Lemma}{}Let $(\Omega, \mathcal{A}, \mu)$ be a measure space. Let $f_n \in \mathcal{F}^+$ be non-negative measurable functions. Then 
$$
\int_{\Omega} \lim_{n \rightarrow \infty} \inf f_nd\mu \leq \lim_{n \rightarrow \infty} \inf \int_{\Omega}fd\mu.
$$
\end{theorem_exam}

We can state something similar using the limit superior.

\begin{theorem_exam}{Reverse Fatou's Lemma}{}
Let $(\Omega, \mathcal{A}, \mu)$ be a measure space. Let $f_n \in \mathcal{F}^+$ be non-negative measurable functions. Furthermore, assume that $f_n \leq g$ where $g \in \mathcal{F}^+$ and $\int gd\mu < \infty.$ Then 
$$
\int_{\Omega} \overline{\lim}f_nd\mu \geq \overline{\lim}\int_{\Omega}fd\mu.
$$
\end{theorem_exam}

\begin{remark}Note that we require a dominating function in the reverse-Fatou lemma.
\end{remark}



\subsection{Relationship between Riemann and Lebesgue Integrals}

First, we recall the Riemann integral. A Riemann integral is defined on a bounded real-valued function $f: [a,b] \rightarrow \mathbb{R}$ and the domain of f is a \textbf{compact} interval.

\begin{definition}(Finite partition). A finite partition of [a,b] is defined as $\mathcal{P} = \{a = x_0 < x_1 < ... < x_n = b\}$. 
Let $m_k = \inf_{x_{k-1} \leq x \leq x_{k}}f(x)$ and $M_k = \sup_{x_{k-1} \leq x \leq x_{k}}f(x)$ for $1 \leq k \leq n.$
\end{definition}

\begin{definition}(Lower and upper Riemann sums). We define the upper and lower Riemann sums as 
$$
\underline{I}(f, \mathcal{P}) = \sum_{k=1}^{n}m_k\Delta_k
$$
$$
\overline{I}(f, \mathcal{P}) = \sum_{k=1}^{n}M_k\Delta_k
$$
where $\Delta_k = x_k - x_{k-1}$ for $1 \leq k \leq n.$
\end{definition}

\begin{definition}(Lower and upper Riemann Integrals). Finally, we define the lower and upper Riemann integrals as 
$$
\underline{I} = \sup_{\mathcal{P}}\underline{I}(f, \mathcal{P})
$$
$$
\overline{I} = \inf_{\mathcal{P}}\overline{I}(f, \mathcal{P}).
$$
\end{definition}

\begin{definition}(Riemann Integrable). A function f is said to be Riemann integrable if 
$$
I(f) = \underline{I}(f) = \overline{I}(f).
$$
\end{definition}

We recall some things from calculus.
\begin{proposition}Every continuous function $f \in C[a,b]$ is Riemann integrable.
\end{proposition}


We will now show that we can evaluate Lebesgue integrals using Riemann integrals. We will set the domain as $[0,1]$ but the following argument holds for any domain where $[a,b]$ for $a, b \geq 0.$

\begin{proposition_exam}{Simple functions approximating Riemann integral}{}Suppose that $f: [0,1] \rightarrow \mathbb{R}^+$ is a properly Riemann integrable function with $\int_0^1f(x)dx.$ Then define the measure space $([0,1], \borelsigmaalgebra, \lambda)$ where $\borelsigmaalgebra$ is the Borel $\sa$ and $\lambda$ is the Lebesgue measure.

Then, there exists sequences $L_n, U_n \in \mathcal{S}^+$ of simple non-negative functions such that 
\begin{enumerate}
\item $L_n \uparrow L \leq f$ and $U_n \downarrow U \geq f$;
\item $\int_{[0,1]}L_nd\lambda \uparrow \int_0^1f(x)dx$ and $\int_{[0,1]}U_nd\lambda \downarrow \int_0^1f(x)dx$.
\end{enumerate}
\end{proposition_exam}

\begin{proof}(Sketch). We take 
$$
L_n = \sum_{k=0}^{2^{n}-1}\inf_{x \in I_k}f(x)1_{I_{k}}
$$
$$
U_n = \sum_{k=0}^{2^{n}-1}\sup_{x \in I_k}f(x)1_{I_{k}}
$$
where the interval is $I_k = (\frac{k}{2^n}, \frac{k+1}{2^n}).$ Both $L_n, U_n \in \mathcal{S}^+.$ Furthermore, 
$$
\int_{[0,1]}L_nd\lambda = \sum_{k=0}^{2^{n}-1}\inf_{x \in I_k}f(x)\mu(1_{I_{k}}) = \sum_{k=0}^{2^{n}-1}\inf_{x \in I_k}f(x)\frac{1}{2^n} \rightarrow \int_{[0,1]}f(x)dx
$$
by the definition of the Riemann integral. Likewise, a similar argument holds for $U_n.$
\end{proof}


\begin{claim}The functions $U,L \in \borelsigmaalgebra^+$. That is, they are positive functions measurable with respect to the Borel $\sa$.
\end{claim}
\begin{proof} The simple functions $U_n, L_n$ are non-negative Borel-measurable functions and hence their pointwise limits are non-negative Borel-measurable functions.
\end{proof}


We have that $L \leq U$ and by monotonicty of integrals 
$$
\int L_n d\lambda \leq \int L d\lambda \leq \int U d\lambda \leq \int U_n d\lambda.
$$

Furthermore, we have shown that $\int_{[0,1]}L_nd\lambda \uparrow \int_0^1f(x)dx$ and $\int_{[0,1]}U_nd\lambda \downarrow \int_0^1f(x)dx$. 

\begin{lemma}
By the squeeze law, we have that 
$$
\int_{[0,1]}Ld\lambda = \int_{[0,1]}Ud\lambda.
$$
\end{lemma}

\begin{corollary}The functions 
$$
L = U
$$
almost everywhere.
\end{corollary}

\begin{proof} We have that
$$
\int_{[0,1]}Ld\lambda = \int_{[0,1]}Ud\lambda.
$$
$$
\int_{[0,1]}Ld\lambda - \int_{[0,1]}(U - L)d\lambda = \int_{[0,1]}Ud\lambda.
$$
$$
\int_{[0,1]}(U - L)d\lambda  = 0
$$
which means that $U - L = 0$ almost everywhere. Hence, this implies that $L = U$ almost everywhere.
\end{proof}

So, as we defined $L \leq f \leq U$, from the previous lemma, we have shown that on $\{\omega: L(\omega) = U(\omega)\}$, we have that $L = f = U$. Furthermore, the set $\{\omega: L(\omega) \neq U(\omega)\}$ has measure zero.

\textbf{However, we are unable to simply take the Lebesgue integral of f as we do not know if it is measurable with respect to the Lebesgue $\sa$. We only know it is Riemann integrable.} Therefore, we need to show that it is.

First, define the function 
$$
\tilde{f} = f\circ 1_{L = U} = L \circ 1_{L = U}
$$
since $L \leq f \leq U$ means that $f = L$ when $L = U.$ 

\begin{claim}The function $\tilde{f} = L \circ 1_{L = U} \in \borelsigmaalgebra^+$ is a non-negative function that is measurable with respect to the Borel $\sa.$ Furthermore, $\tilde{f} = L$ almost everywhere.
\end{claim}

\begin{proof} We had that $L \in \borelsigmaalgebra^+$ and the set $\{L = U\}$ was defined to be in the Borel $\sa.$
\end{proof}

From the previous claim, we have that
$$
\int_{[0,1]}f(x)dx = \int_{[0,1]}Ld\lambda = \int_{[0,1]}\tilde{f}d\lambda.
$$
We are now really close to showing that 
$$
\int_{[0,1]}f(x)dx =  \int_{[0,1]}fd\lambda.
$$

\begin{proposition_exam}{Expressing Riemann integrable function as Borel integrable function}{}Let f be the Riemann integrable function and $\tilde{f} = f\circ 1_{L = U}\in \borelsigmaalgebra^+$. Then 
$
f = \tilde{f}
$
almost everywhere. Furthermore, $$f = \tilde{f} + f\circ 1_{L \neq U}.$$
\end{proposition_exam}

Recall that the Lebesgue $\sa$ $\mathcal{L}$ is the completion of the Borel $\sa$ $\borelsigmaalgebra$ with respect to the Lebesgue measure $\lambda.$
\begin{lemma}Let $([0,1], \borelsigmaalgebra, \lambda)$ be a measure space. We can complete the measure space with respect to the Lebesgue measure to be $([0,1], \mathcal{L}, \lambda)$ where $\mathcal{L}$ is the Lebesgue $\sa$.
\end{lemma}

\begin{theorem_exam}{Riemann integrable function is Lebesgue measurable}{}Let f be a Riemann integrable function on [0,1]. Then, the function $f: ([0,1], \mathcal{L}, \lambda) \rightarrow (\positiveextendedreal, \overline{\borelsigmaalgebra})$ is measurable. That is, f is Lebesgue-measurable.
\end{theorem_exam}

\begin{proof} Take a Borel set $B \in \overline{\borelsigmaalgebra}.$ Then 
$$
f^{-1}(B) = f^{-1}(B) \cap \{\{L = U\} \cup \{L \neq U\}\}
$$
$$
= (f^{-1}(B) \cap \{L = U\}) \cup (f^{-1}(B) \cap \{L \neq U\})
$$
Recall that $f = \tilde{f} + f\circ 1_{L \neq U}$ where $\tilde{f}$ is only defined on $\{L = U\}$
$$
= (\tilde{f}^{-1}(B) \cap \{L = U\}) \cup (f^{-1}(B) \cap \{L \neq U\})
$$
Now, we know that for $(\tilde{f}^{-1}(B) \cap \{L = U\})$, $\tilde{f}$ was shown to be measurable with respect to $\borelsigmaalgebra^+ \subset \mathcal{L}.$

For the second term, we have that $f^{-1}(B) \cap \{L \neq U\} \subseteq \{L \neq U\}$. However, this was shown to be a set of measure zero in $\borelsigmaalgebra^+.$ Therefore, $f^{-1}(B) \cap \{L \neq U\} \subseteq \{L \neq U\} \in \borelsigmaalgebra^+ \subseteq \mathcal{L}.$

Therefore, f is measurable with respect to the Borel $\sa$. However, as $\borelsigmaalgebra \subseteq \mathcal{L}$, this means that f is measurable with respect to the Lebesgue $\sa.$
\end{proof}

\begin{theorem_exam}{Riemann and Lebesgue integrals}{}Let f be a Riemann integrable function over [0,1]. Then f is Lebesgue integrable with respect to $([0,1], \mathcal{L}, \lambda)$. Furthermore 
$$
\int_{[0,1]}fd\lambda = \int_{0}^{1}f(x)dx.
$$
\end{theorem_exam}

\begin{remark}This is extremely useful as we can now evaluate Lebesgue integrals using Riemann integrals and using the fundamental theorem of calculus.
\end{remark}

Now, we can generalise what we have just shown.

\begin{proposition}Every function f that is Borel-measurable and finite is Lebesgue integrable.
\end{proposition}

\begin{theorem_exam}{Lebesgue's Characterisation of Riemann integrable function}{}Let f be a bounded real-valued function defined on a compact interval [a,b]. Then f is Riemann integrable if and only if the set of all discontinuity points of f is a set of Lebesgue measure zero.
\end{theorem_exam}

\begin{theorem_exam}{Every Riemann integrable function is Lebesgue integrable}{}Every function $f \in C[a,b]$ has their Riemann integral and Lebesgue integral agreeing.
\end{theorem_exam}

Hence, every function that is Riemann integrable is Lebesgue integrable. Therefore, we can use tools from calculus when we wish to compute Lebesgue integrals of continuous functions.
 

\begin{proposition_exam}{Riemann integral and Lebesgue integral for non-negative functions}{}Let $f(x)$ be a non-negative Riemann integrable function on an interval $(a,b].$ Then, f is also Lebesgue integrable (with the Lebesgue measure $\lambda$) on $(a,b]$ with their integrals agreeing 
$$
\int_{a}^{b}f(x)dx = \int_{(a,b]}fd\lambda
$$
\end{proposition_exam}

\subsection{Abstract Lebesgue Integral and Integrable Functions}

Thus far, we have only looked at integrals of non-negative integrable functions. In this section, we are now interested in the integrals of functions $f:\Omega \rightarrow \mathbb{R}.$ Recall that the integral of a function f is the area of the function that is above 0 less the area of the function below 0. Hence, we require $|f|$ to be a finite integral in order for us to take the integral of f. This motivates our definitions of integrable functions. 

\begin{definition_exam}{Decomposition of extended real-valued function}{}If $f: \Omega \rightarrow \overline{\mathbb{R}}$ is a extended real-valued function, we define the positive and negative parts $f^+, f^-: \Omega \rightarrow [0, \infty]$ of the function f by 
$$
\quad f^+=\max \{f, 0\}, \quad f^-=\max \{-f, 0\} = -(\min \{f, 0\})
$$
Therefore, we can write the function f as 
$$
f = f^+ - f^-
$$
\end{definition_exam}


\begin{lemma}Let $f:(\Omega, \sigmalgebra) \rightarrow (\overline{\mathbb{R}}, \overline{\borelsigmaalgebra})$ be a measurable function. Then, the functions $f^-, f^+ \in \mathcal{F}^+$ are non-negative measurable functions.
\end{lemma}

\begin{proof} We can write 
$$
f^+ = \frac{|f| + f}{2} \quad f^- = \frac{|f| - f}{2}
$$
where we have shown that each component was a non-negative measurable function.
\end{proof}

\begin{lemma}f is measurable if and only if $f^+$ \textbf{and} $f^-$ are measurable.
\end{lemma}


Before the next few definitions, we explain there is a difference between the \textbf{existence} of integral and \textbf{integrability} in Lebesgue integration. Integrability refers to the integral being finite. However, we can still define an integral $\int fd\mu$ but it \textbf{needs not} be integrable. Indeed, we have said from before that $\int gd\mu$ for a nonnegative measurable g, we allowed it to take the value $\infty.$ 

With that in mind, we now define how to take the integral of a measurable function.

\begin{definition_exam}{Abstract Lebesgue Integral}{}Let $f: (\Omega, \mathcal{F}) \rightarrow (\overline{\mathbb{R}}, \overline{\borelsigmaalgebra})$ be a measurable function. We define 
$$
\int_{\Omega}fd\mu \coloneqq \int_{\Omega}f^+d\mu - \int_{\Omega}f^-d\mu
$$
provided that \textbf{at least one} of the integrals $\int_{\Omega}f^+d\mu, \int_{\Omega}f^-d\mu$ is finite.
\end{definition_exam}

\begin{remark}Alternatively, we can say that a function f is well-defined if $$min\{\int_{\Omega}f^+d\mu, \int_{\Omega}f^-d\mu\} < \infty.$$ The integral $\int fd\mu$ \textbf{does not exist} if and only if $\int f^+d\mu = \infty$ and $\int f^-d\mu = \infty$ since $\infty - \infty$ is not defined.
\end{remark}

\begin{remark}We use the convention that $\infty - c = \infty$ and $c - \infty = \infty.$
\end{remark}


We now draw out the distinction for when a function is integrable.

\begin{definition_exam}{Integrable function}{}Define the measure space $(\Omega, \sigmalgebra, \mu)$. A measurable function f is \textbf{integrable} if 
$$
\max \bigg(\int f^+d\mu, \int f^-d\mu \bigg) < \infty. 
$$
\end{definition_exam}


\begin{proposition_exam}{Equivalent formulation of integrability}{}
Define the measure space $(\Omega, \sigmalgebra, \mu)$. Let f be a measurable function. As $f = f^+ - f^-$, this implies that $|f| = f^+ + f^-.$ Then, we can say that f is a $\mu-$integrable function if 
$$
\int_{\Omega}|f|d\mu < \infty.
$$
\end{proposition_exam}

\begin{proof} As $|f| = f^+ + f^-$, we have that 
$$
\int |f|d\mu = \int f^+d\mu + \int f^-d\mu.
$$
The above equation is finite if and only if $\max \{\int f^+d\mu, \int f^-d\mu\} < \infty$. Hence, f is integrable.
\end{proof}

\begin{definition_exam}{$\mathcal{L}^{1}-Space$}{}Define the measure space $(\Omega, \sigmalgebra, \mu)$. We define the $\mathcal{L}^{1}$-space as the space of functions that are integrable with respect to the measure $\mu$. That is 
$$
\mathcal{L}^{1}(\Omega, \sigmalgebra, \mu) = \{f: \int_{\Omega}|f|d\mu < \infty.\}
$$
We can write $\mathcal{L}^{1}(\Omega, \sigmalgebra, \mu) = \mathcal{L}^{1}(d\mu).$
\end{definition_exam}

\begin{proposition_exam}{Condition for integrability of a function}{}Define the measure space $(\Omega, \sigmalgebra, \mu)$. Let f be a measurable function. Then $f \in \mathcal{L}^{1}(d\mu)$ if and only if $|f| \in \mathcal{L}^{1}(d\mu).$
\end{proposition_exam}

We now state some properties of integrating in $\mathcal{L}^1.$

\begin{lemma}(Integrating over subset). Define the measure space $(\Omega, \sigmalgebra, \mu)$. For any $\mu-$measurable function set A and $f \in \mathcal{L}^1(d\mu)$, we define integrating over a set $A \subset \Omega$ as 
$$
\int_{A}fd\mu \coloneqq \int_{X}1_{A}fd\mu
$$
where $1_{A}$ is the indicator function.
\end{lemma}

\begin{proposition_exam}{$\mathcal{L}^1$ is a vector space}{} Define the measure space $(\Omega, \sigmalgebra, \mu)$. Let $f, g \in \mathcal{L}^1(d\mu)$ and $\alpha, \beta \in \mathbb{R}.$ Then, we have that $\alpha f + \beta g \in \mathcal{L}^1(d\mu)$. That is, $\mathcal{L}^1$ is a vector space.
\end{proposition_exam}

\begin{proof}
First, we use the fact that 
$$
\bigg| \alpha f + \beta g \bigg| \leq |\alpha||f| + |\beta||g|
$$
Then, we note that integration is monotone with respect to $\sigmalgebra^+.$ Therefore, the right hand side is in $\mathcal{L}^1$ and therefore the left hand side is in $\mathcal{L}^1.$
\end{proof}


\begin{proposition_exam}{Properties of Lebesgue integrals}{}Define the measure space $(\Omega, \sigmalgebra, \mu)$. Let $f, g \in \mathcal{L}^1(d\mu)$. Then we have that
\begin{enumerate}
\item For all $\alpha, \beta \in \mathbb{R}$  
$$\int_{\Omega}(\alpha f + \beta g)d\mu = \alpha \int_{\Omega} fd\mu + \beta \int_{\Omega} gd\mu.$$

\item If $A, B \in \mathcal{F}$ are disjoint, then 
$$
\int_{A \cup B}fd\mu = \int_{A}fd\mu + \int_{B}fd\mu.
$$
\item We have the \textbf{triangle inequality} 
$$
\bigg|\int_{\Omega}fd\mu \bigg| \leq \int_{\Omega}|f|d\mu.
$$
\end{enumerate}
\end{proposition_exam}

\begin{remark}Every function that is Riemann integrable is Lebesgue integrable. However, the converse does not hold.
\end{remark}





% \begin{corollary}If $\int f^-d\mu < \infty$ and $\int g^-d\mu < \infty$ then $\int (f+g)d\mu$ exist and $\int(f+g)d\mu = \int fd\mu - \int gd\mu.$ This holds if $\int f^+d\mu < \infty$ and $\int g^+d\mu < \infty.$
% \end{corollary}




\lecture{8}{$\mathcal{L}^p$-spaces}
\section{Lebesgue Spaces}
\section{Lebesgue Spaces}
\subsection{$\mathcal{L}^p$-spaces}
We now extend upon $\mathcal{L}^1$-spaces.
\begin{definition_exam}{$\mathcal{L}^p$-norm}{}Define the measure space $(\Omega, \sigmalgebra, \mu)$. Let $1 \leq p < \infty$ and $f: \Omega \rightarrow \mathbb{R}.$ We call 
$$
||f||^p \coloneqq \bigg(\int_{\Omega}|f|^pd\mu \bigg)^{1/p}
$$
the $\mathcal{L}^p-$norm of f.
\end{definition_exam}

\begin{remark}Alternatively, we can say $f \in \mathcal{L}^p$ if $|f|^p \in \mathcal{L}^1.$ That is, $\int |f|^pd\mu < \infty.$
\end{remark}

\begin{definition_exam}{$\mathcal{L}^p$-space}{}Define the measure space $(\Omega, \sigmalgebra, \mu)$. We define the space 
$$
\mathcal{L}^p(\Omega, \sigmalgebra, \mu) = \{f:\Omega \rightarrow \mathbb{R}: \text{f is measurable and }||f||_p < \infty \}.
$$
We call $\mathcal{L}^p(d\mu)$ the Lebesgue space.
\end{definition_exam}

\begin{proposition_exam}{$\mathcal{L}^p(d\mu)$ is a vector space}{}The space $\mathcal{L}^p(\Omega, \mathcal{F},\mu)$ is a vector space.
\end{proposition_exam}

\begin{proof} First, suppose that $f, g \in \mathcal{L}^p.$ Then 
$$
|f + g|^p \leq \bigg(|f| + |g| \bigg)^p \leq \bigg(2 \cdot \max\{f, g\} \bigg)^p \leq 2^p\bigg( \max\{f^p, g^p\}\bigg) \leq 2^p\bigg(|f|^p + |g|^p \bigg)
$$
Then, on the right hand side
$$
\int_{\Omega} 2^p\bigg(|f|^p + |g|^p \bigg)d\mu < \infty
$$
and therefore $|f + g|^p \in \mathcal{L}^1.$ This means that $f + g \in \mathcal{L}^p.$ 

Now, assume $\alpha \in \mathbb{R}$ and $f \in \mathcal{L}^p.$
$$
\int_{\Omega} \alpha |f|^pd\mu = \alpha \int_{\Omega} |f|^pd\mu < \infty
$$
and therefore $\alpha f \in \mathcal{L}^p.$
\end{proof}

\begin{claim}Define the measure space $(\Omega, \sigmalgebra, \mu)$. If $f, g\in \sigmalgebra$, $f \leq g$ and $\int f^{-}d\mu < \infty$, then $\int gd\mu$ exists and 
$$
\int fd\mu \leq \int gd\mu.
$$
\end{claim}

We can actually strengthen conditions if two functions are equal almsot everywhere.

\begin{claim}Define the measure space $(\Omega, \sigmalgebra, \mu)$. Let $f, g \in \mathcal{F}$ be measurable functions and $f = g$ a.e. Then $\int fd\mu$ if well-defined if and only if $\int gd\mu$ is well-defined then 
$$
\int fd\mu = \int gd\mu.
$$
\end{claim}

We revisit some theorems we have previously stated with stronger conditions of it holding a.e.

\begin{corollary}The MCT, Fatou's lemma, and the reversed Fatou lemma hold if the conditions hold a.e:
\begin{enumerate}
\item (Fatou's Lemma) If $f_n$ are measurable functions with $f_n \geq 0$ a.e. then $\int \underline{\lim}f_nd\mu \leq \underline{\lim}\int f_nd\mu$
\item (MCT) If in addition $f_n \rightarrow f$ monotonically pointwise a.e. then $\int f_nd\mu \rightarrow \int fd\mu$ as $n \rightarrow \infty.$
\item (Reversed Fatou) If $f, f_n$ are measurable functions with $0 \leq f_n \leq g$ a.e and $g \in \mathcal{L}^1$ then $\int \overline{\lim}f_nd\mu \geq \overline{\lim}\int f_nd\mu.$
\end{enumerate}
\end{corollary}


\begin{claim}(Strengthened reverse Fatou Lemma). Define the measure space $(\Omega, \sigmalgebra, \mu)$. Suppose $f_n$ are measurable with $f_n \leq g$ a.e and $g \in L^1$ then 
$$
\int \overline{\lim}f_nd\mu \geq \overline{\lim}\int f_nd\mu.
$$
\end{claim}

\subsection{Modes of convergence}

First, recall that the definition of pointwise convergence that for a sequence of functions $\{f_n\}_{n \geq 1}$ that for all $x \in X$ and for all $\epsilon > 0$, there exists a $N = N(\epsilon, x) \in \mathbb{N}$ such that if $n \geq N$, then 
$$
|f_n(x) - f(x)| < \epsilon.
$$

Now, for almost surely convergent, we relax this assumption by not requiring it not to converge for all $\omega \in \Omega$ but the ones that don't, belong to a set of measure zero.
That is, let $X_n$ be a sequence of random variables on the same probability space $(\Omega, \mathcal{F}, P).$ Then 
$$
P(\omega \in \Omega: lim_{n \rightarrow \infty}X_n(\omega) = X(\omega)) = 1.
$$
That is, the set of points $\omega$ that it does not converge to has a probability of zero.


\begin{definition_exam}{Convergence almost everywhere}{}Suppose $\{f_n\}_{n \geq 1}$ is a sequence of measurable functions $(\Omega, \sigmalgebra, \mu) \rightarrow (\overline{\mathbb{R}}, \overline{\mathbb{B}})$. Then $f_n$ converges in f \textbf{almost everywhere} (\textbf{almost surely} if $\mu$ is a probability measure) if $\lim f_n(\omega) = f(\omega)$ pointwise on a set $E \in \sigmalgebra$ and $\mu(E^c) = 0.$
\end{definition_exam}



\begin{definition_exam}{Convergence in $\mathcal{L}^p$}{}Suppose $\{f_n\}_{n \geq 1}$ is a sequence of measurable functions $(\Omega, \sigmalgebra, \mu) \rightarrow (\overline{\mathbb{R}}, \overline{\mathbb{B}})$. Suppose that $f \in \sigmalgebra$ is a measurable function. We say that $f_n \rightarrow f$ in $\mathcal{L}^p$ if $$||f_n - f||^p = \int_{\Omega}|f_n - f|^pd\mu \rightarrow 0$$ as $n \rightarrow \infty.$
\end{definition_exam}

\begin{remark}This is also known as convergence in the p-th mean as we will soon see that expectation of a random variable is just the Lebesgue integral. Alternatively, we say that $X_n$ converges to X in $p-th$ moment if 
$$
\lim_{n \rightarrow \infty}E\bigg[|X_n - X|^p\bigg] = 0.
$$

When p = 2, we call this \textbf{convergence in quadratic mean}.
\end{remark}


\begin{proposition_exam}{Convergence in p-th mean is integrable}{}Let $\{f_n\} \in \mathcal{L}^p(X).$ If $f_n \rightarrow f$ in $\mathcal{L}^p$, that is $\int|f_n - f|^pd\mu \rightarrow 0$, then $f \in \mathcal{L}^p.$
\end{proposition_exam}

\begin{proof} First, we have that $\lim_{n \rightarrow \infty}\int |f_n - f|^pd\mu = 0.$ Then, for every $\epsilon >0,$ there exists $N_{\epsilon} > 0$ such that 
$$
\int |f_n - f|^pd\mu \leq \frac{\epsilon}{2^{p-1}}
$$
for all $n \geq N_{\epsilon}.$ Then, by adding $f_n - f_n$ and the triangle inequality 
$$
\int |f|^pd\mu \leq 2^{p - 1}\int |f - f_n|^pd\mu + 2^{p - 1}\int |f_n|^pd\mu = 2^{p - 1}\frac{\epsilon}{2^{p - 1}} + 2^{p - 1}\int |f_n|^pd\mu < \infty
$$
Therefore, $\int |f|^pd\mu < \infty$ and hence $f \in \mathcal{L}^p.$
\end{proof}

Without additional assumptions, there is no relationship between convergence almost everywhere and converge in $\mathcal{L}^p.$
\begin{corollary}Suppose $\{f_n\}_{n \geq 1}$ is a sequence of measurable functions $(\Omega, \sigmalgebra, \mu) \rightarrow (\overline{\mathbb{R}}, \overline{\mathbb{B}})$. If $f_n \rightarrow f$ almost everywhere, it \textbf{does not} mean that $f_n \rightarrow f$ in $\mathcal{L}^1.$
\end{corollary}

\begin{proof} Define the measure space $((0,1), \borelsigmaalgebra, \lambda)$. Define the sequence of functions $f_n = n1_{(0,\frac{1}{n})}$. Then $f_n \rightarrow 0$ a.e. but $\int|f_n - f|d\mu = \int n1_{(0,\frac{1}{n})}d\mu = 1.$
\end{proof}


We now introduce a new limit theorem which is extremely useful.

\begin{theorem_exam}{Dominated Convergence Theorem}{}Let $\{f_n\} \in \sigmalgebra$ be a sequence of measurable functions on a measure space $(\Omega, \sigmalgebra, \mu)$. Suppose that the sequence $f_n \rightarrow f$ pointwise almost everywhere. Furthermore, suppose that $|f_n(\omega)| \leq g(\omega)$ for all $\omega \in \Omega$ a.e for $g \in \mathcal{L}^1(\Omega)$. Then
\begin{enumerate}
\item $f_n, f \in \mathcal{L}^1$ for all $n \in \mathbb{N}$ 
\item $\int_{\Omega}|f_n - f|d\mu = 0$ as $n \rightarrow \infty$. That is, $f_n \rightarrow f$ in $\mathcal{L}^1.$
\end{enumerate}
\end{theorem_exam}

\begin{proof} It is clear that $f_n, f \in \mathcal{L}^1$ as both are bounded by $g \in \mathcal{L}^1.$ Now, let 
$$
\phi_n = |f - f_n| \in \sigmalgebra^+
$$
Then, 
$$
\phi_n \rightarrow 0 \text{ a.e.}
$$
Furthermore, $\phi_n \in \mathcal{L}^1$ as 
$$
\phi_n(\omega) \leq |f(\omega)| + |f_n(\omega)| \leq 2g(\omega)
$$
for a.e. $\omega \in \Omega.$

Then, for a.e. $\omega \in \Omega$
$$
\overline{lim}\int \phi_nd\mu \leq \int \overline{lim} \phi_nd\mu = 0
$$
where the first inequality comes from reverse Fatou's lemma and the final equality comes from the fact that $\phi_n \rightarrow 0$ a.e. Therefore, we can conclude that $f_n \rightarrow f$ in $\mathcal{L}^1.$
\end{proof}

\begin{remark} Two big takeaways is that the sequence of functions and its limit $f_n, f$ are integrable. Additionally, we can strengthen the convergence from pointwise to $\mathcal{L}^1$ convergence.
\end{remark}


We state a very important result from the dominated convergence theorem.

\begin{proposition_exam}{Interchange limit and integrals due to DCT}{}Let $\{f_n\} \in \sigmalgebra$ be a sequence of measurable functions on a measure space $(\Omega, \sigmalgebra, \mu)$. If $f_n \rightarrow f$ in $\mathcal{L}^1$, then $$\lim_{n \rightarrow \infty}\int f_nd\mu = \int \lim_{n \rightarrow \infty}f_nd\mu = \int fd\mu.$$ That is, if $f_n \rightarrow f$ in $\mathcal{L}^1$, then $\int f_nd\mu \rightarrow \int fd\mu.$
\end{proposition_exam}
\begin{proof} We have that $\int|f_n - f|d\mu \rightarrow 0$. Then, by the triangle inequality, we have that 
$$
\bigg|\int_{\Omega}fd\mu - \int_{\Omega}f_nd\mu \bigg| \leq \int_{\Omega}|f - f_n|d\mu < \epsilon
$$
for all $n \geq N_{\epsilon}.$ Therefore, we can conclude that 
$$
\int f_nd\mu \rightarrow \int fd\mu.
$$
\end{proof}

We now show a case where the converse of the above state \textbf{does not hold}. That is, being able to interchange the limit and integrals $\int f_nd\mu \rightarrow \int fd\mu$ does not necessarily imply $f_n \rightarrow f$ converges in $\mathcal{L}^1$. 

First, we recall that the Monotone Convergence Theorem requires an increasing sequence of non-negative measurable functions $f_n \uparrow f.$

\begin{claim}(The Monotone Convergence Theorem does not imply $\mathcal{L}^1$ convergence). Let $\{f_n\} \in \sigmalgebra^+$ be a sequence of measurable \textbf{non-negative} functions on a measure space $(\Omega, \mathcal{F}, \mu)$. Furthermore, assume that $f_n \uparrow f$. Therefore, we have that $$\int f_nd\mu \uparrow \int fd\mu.$$ However, \textbf{it does not follow} that $f_n \rightarrow f$ in $\mathcal{L}^1.$
\end{claim}


However, if we can also specify a dominating function, then we can then conclude that being able to interchange limits and integrals $\int f_nd\mu \rightarrow \int fd\mu$ \textbf{does indeed} imply $f_n \rightarrow f$ converges in $\mathcal{L}^1$.

\begin{proposition_exam}{Dominated convergence theorem and convergence in $\mathcal{L}^1$}{}Let $\{f_n\} \in \sigmalgebra^+$ be a sequence of measurable \textbf{non-negative} functions on a measure space $(X, \mathcal{F}, \mu)$. Assume that $f_n \uparrow f$ is a montone sequence which converges pointwise. Furthermore, assume that $f \in \mathcal{L}^1.$ Then, by the Monotone Convergence Theorem $$\int f_nd\mu \uparrow \int fd\mu.$$ Furthermore, by the dominated convergence theorem, where f is the dominating function, we have that 
$$
||f - f_n|| = \int_{\Omega}|f - f_n|d\mu \rightarrow 0.
$$
That is, $f \rightarrow f_n $ in $\mathcal{L}^1.$
\end{proposition_exam}

We can state a condition in order for convergence almost everywhere to imply convergence in $\mathcal{L}^1$.

\begin{theorem_exam}{Scheffe's Lemma}{} Suppose that $f_n, f \in \mathcal{L}^1(\Omega, \mathcal{F}, \mu)$ and that $f_n \rightarrow f$ a.e. Then $f_n \rightarrow f$ in $\mathcal{L}^1$ if and only if $$\int |f_n|d\mu \rightarrow \int |f|d\mu$$
\end{theorem_exam}


\begin{remark}Scheffe's lemma implies that if $f_n \rightarrow f$ in $\mathcal{L}^1$, it \textbf{does not mean} that $f_n \rightarrow f$ almost everywhere if $\int |f_n|d\mu \rightarrow \int |f|d\mu$.
\end{remark}


We now state a weaker type of convergence.

\begin{definition_exam}{Convergence in measure}{}Let $\{f_n\}_{n \geq 1}$ be a sequence of measurable functions in $(\Omega, \sigmalgebra, \mu)$. The sequence $f_n$ \textbf{converges to f in measure} if for all $\epsilon > 0$
$$
\mu\bigg(\omega: |f_n - f| > \epsilon \bigg) \rightarrow 0
$$
as $n \rightarrow \infty.$
\end{definition_exam}

\begin{remark}If $\mu$ is a probability measure, then this is known as \textbf{convergence in probability}. We write that a sequence of random variables $\{X_n\}$ converges in probability towards the random variable X if for all $\epsilon > 0$ 
$$
\lim_{n \rightarrow \infty}P(\{\omega: |X_n(\omega) - X(\omega)| > \epsilon\}) = \lim_{n \rightarrow \infty}P(|X_n - X| > \epsilon) = 0.
$$
\end{remark}

We can see that this is a weaker type of convergence as it is implied by other forms of convergence.

\begin{theorem_exam}{Convergence almost everywhere implies convergence in measure}{}Let $\{f_n\}_{n \geq 1}$ be a sequence of measurable functions in $(\Omega, \sigmalgebra, \mu)$. If $f_n \rightarrow f$ almost everywhere and $\mu(\Omega) < \infty$, then $f_n \rightarrow f$ in measure.
\end{theorem_exam}

\begin{proof} We will make sure of the dominating convergence theorem where the constant function 1 will be our dominating function and hence why we require $\mu(\Omega) < \infty.$ Fix $\epsilon > 0$ and let $A_n = \{\omega: |f_n - f| > \epsilon\}$ and define $g_n = 1_{A_{n}}.$ Since $f_n \rightarrow f$ a.e. then $g_n \rightarrow 0$ a.e. Furthermore, as the function is bounded $g_n \leq 1$ whereby $\int_{\Omega}1d\mu = \mu(\Omega) < \infty$, this implies that the constant function $1 \in \mathcal{L}^1.$ Then, as a result of the dominating convergence theorem, $g_n \in \mathcal{L}^1$ and $g_n \rightarrow 0$ in $\mathcal{L}^1.$ Therefore, we have that 
$$
\mu(A_n) = \int_{\Omega}g_nd\mu \rightarrow \int 0d\mu = 0
$$
Therefore, $f_n \rightarrow f$ in measure.
\end{proof}

\begin{remark}In probability spaces, as $\prob(\Omega) = 1$, this means that \textbf{convergence almost surely always implies convergence in probability}.
\end{remark}

We elaborate with an example on why we need a finite measure. 
\begin{example}Let $f_n = 1_{(n,\infty)}$ defined on the measure space $([0, \infty), \borelsigmaalgebra, \lambda)$. Clearly, $f_n \rightarrow 0$ almost everywhere. However, $\lambda(\{\omega: |f_n(\omega) - 0| > \frac{1}{2}\}) = \infty.$ Therefore, $f_n$ does not convergence to 0 in measure.
\end{example}

The converse of convergence in measure does not imply convergence almost everywhere.
\begin{corollary}Let $f_n$ be measurable functions on $(\Omega, \mathcal{F}, \mu)$. Suppose that $f_n \rightarrow f$ in measure. This \textbf{does not mean} that $f_n \rightarrow f$ almost everywhere.
\end{corollary}

We now state an important inequality in probability theory.

\begin{proposition_exam}{Markov's Inequality}{}Define a measure space $(\Omega, \sigmalgebra, \mu)$. Let $f \in \mathcal{F}^+$ be a non-negative measurable function and $\alpha \in \mathbb{R}^+$. Then, \textbf{Markov's inequality} states that 
$$
\mu\bigg(\{\omega \in \Omega: f(\omega) \geq \alpha\} \bigg) \leq \frac{1}{\alpha}\int_{\Omega}fd\mu.
$$
If $(\Omega, \sigmalgebra, \mu) = (\Omega, \sigmalgebra, \prob)$, and we defined $X:(\Omega, \sigmalgebra) \rightarrow (\positiveextendedreal, \overline{\borelsigmaalgebra})$ to be a random variable, then Markov's inequality is 
$$
\prob\bigg(X \geq \alpha \bigg) \leq \frac{1}{\alpha}\mathbb{E}[X].
$$
\end{proposition_exam}

\begin{proof} As $f \in \sigmalgebra^+,$ we have that 
$$
f \geq f \cdot 1_{\{f \geq \alpha\}} \geq \alpha 1_{\{f \geq \alpha\}} \geq 0
$$
Then, taking integrals 
$$
\int fd\mu \geq \int \alpha 1_{f \geq \alpha}d\mu = \alpha \mu(\{\omega: f(\omega) \geq \alpha\})
$$
\end{proof}

We can use Markov's inequality to help us prove another convergence relationship.
\begin{proposition_exam}{Convergence in $\mathcal{L}^1$ implies convergence in measure}{}Let $f_n$ be measurable functions on $(\Omega, \mathcal{F}, \mu)$. Suppose that $f_n \rightarrow f$ in $\mathcal{L}^1.$ Then, $f_n \rightarrow f$ in measure.
\end{proposition_exam}

\begin{proof} Fix $\epsilon > 0.$ Then, by Markov's inequality, 
$$
\mu(|f_n - f| > \epsilon) \leq \frac{1}{\epsilon}\int |f_n - f|d\mu \rightarrow 0
$$
as $n \rightarrow \infty$ since $f_n \rightarrow f$ in $\mathcal{L}^1.$
\end{proof}

\begin{remark} This actually holds for $f_n \rightarrow f$ in $\mathcal{L}^p$ for any $p > 0.$ In probability language, this says that \textbf{convergence in mean} implies \textbf{convergence in probability.}
\end{remark}

Whilst we may not have that convergence in measure imply convergence almost everywhere, we have something close to it.
\begin{claim}Let $f_n$ be measurable functions on $(\Omega, \mathcal{F}, \mu)$. Suppose that $f_n \rightarrow f$ in measure. Then, there exists a sub-sequence $\{n_k\}$ such that $f_{n_{k}} \rightarrow f$ almost everywhere as $k \rightarrow \infty.$ 
\end{claim}

\begin{corollary} The claim also applies if $f_n \rightarrow f$ in $\mathcal{L}^1.$
\end{corollary}

However, if we add in an extra assumption, we can show that \textbf{convergence in measure implies convergence in} $\mathcal{L}^1.$ The dominated convergence theorem provides \textbf{sufficient conditions} under which almost everywhere convergence of a sequence of functions implies convergence in the $\mathcal{L}^1$ norm.

\begin{proposition_exam}{Convergence in measure with dominating function implies convergence in $\mathcal{L}^1$}{}Let $f_n$ be measurable functions on $(\Omega, \mathcal{F}, \mu)$. Suppose that $f_n \rightarrow f$ in measure. Furthermore, assume that there exists an integrable dominating function $g \in \mathcal{L}^1$ such that $|f_n| \leq g$ almost everywhere. Then $f_n \rightarrow f$ in $\mathcal{L}^1.$
\end{proposition_exam}

\begin{proof} We prove by contradiction. Assume that $\int |f_n - f|d\mu \not \rightarrow 0.$ Then, this means that for all $\epsilon > 0$, there exists a subsequence $\{n_k\}$ such that for all k 
\begin{equation}
\int |f_{n_{k}} - f|d\mu > \epsilon
\tag{*}
\end{equation}
However, by assumption $f_{n_{k}} \rightarrow f$ in measure. By our previous result, there exists a further subsequence $\{m_k\} \subset \{n_k\}$ such that 
$$
f_{m_{k}} \rightarrow f \text{ a.e.}
$$
Then, recall that $f_{m_{k}} \leq g \in \mathcal{L}^1$. Therefore, by the dominating convergence theorem 
$$
f_{m_{k}} \rightarrow f \text{ in } \mathcal{L}^1
$$
This contradicts the original claim (*) and therefore we can conclude that $f_n \rightarrow f$ in $\mathcal{L}^1.$
\end{proof}

\begin{remark} Therefore, if we ever have convergence in measure and a dominating function, then we can strengthen this to convergence in $\mathcal{L}^1.$
\end{remark}


We now state the weakest form of convergence.

\begin{definition_exam}{Weak Convergence}{} A sequence of probability measures $\mu_n$ converges weakly to a probability measure $\mu$ if for all $x \in \mathbb{R},$ with $\mu(\{x\}) = 0$, we have that 
$$
\mu_n((-\infty, x]) \rightarrow \mu((-\infty, x])
$$
\end{definition_exam}

We can in fact relate this form of convergence to the distribution function F.

\begin{definition_exam}{Converges in Distribution}{}Let $\{X_n\}_{n \geq 1}$ be a sequence of random variables. We say that the sequence $X_n$ converges in distribution to a random variable X if 
$$
\lim_{n \rightarrow \infty}F_n(x) = F(x)
$$
for every number $x \in \mathbb{R}$ at which F is continuous. Here, $F_n$ and F are the cumulative distribution functions of the random variables $X_n$ and X respectively.
\end{definition_exam}

\begin{proposition_exam}{Relationship between weak convergence and convergence in distribution}{} Let $\{X_n\}_{n \geq 1}$ be a sequence of random variables. Then, if the random variables $X_n$ converges in distribution, 
$$
F_{X_n} \rightarrow F_X
$$
then, $X_n \rightarrow X$ weakly.
\end{proposition_exam}

\begin{remark} The reason it is called \textbf{weak} convergence is that the $\{X_n\}$ and $X$ \textbf{does not need} to be defined on the same probability space as in previous forms of convergence.
\end{remark}

The following claim shows the relationship between this new form of convergence to those previously seen.

\begin{claim} Suppose that $X_n \rightarrow X$ in probability. Then $X_n \rightarrow X$ weakly.
\end{claim}

\subsection{Inequalities in the $\mathcal{L}^p$-space}

Earlier, we alluded to the fact that $||f||_p$ is known as the $\mathcal{L}^p-$norm. We shall prove some theorems using it and also show that it is in fact a \textbf{pseudonorm}.

\begin{lemma}(Young's Inequality). Let $p, q > 1$ be such that 
$$
\frac{1}{p} + \frac{1}{q} = 1.
$$
Then,
$$
st \leq \frac{1}{p}s^p + \frac{1}{q}t^q
$$
for all $s,t \geq 0.$
\end{lemma}

Using Young's inequalities, we can derive inequalities for $\mathcal{L}^p-$norms.

\begin{proposition_exam}{Hlder's Inequality}{}Let f,g be measurable functions and $p,q > \infty$ with $\frac{1}{p} + \frac{1}{q} = 1.$ Then 
$$
||f\cdot g|| = \int |f \cdot g|d\mu \leq \bigg(\int|f|^pd\mu \bigg)^{1/p}\bigg(\int|g|^qd\mu \bigg)^{1/q} = ||f||_p||g||_q
$$
for all $f \in \mathcal{L}^p(\Omega)$ and $g \in \mathcal{L}^q(\Omega).$
\end{proposition_exam}

Hlder's inequality is actually a generalisation of the Cauchy-Schwarz inequality.
\begin{theorem}(Cauchy-Schwarz Inequality). Let $p = q = 2.$ Then, let $f,g$ be measurable functions $f,g \in \mathcal{L}^2(X).$ Then 
$$
||fg||_{2} = \bigg| \int_{\Omega}fgd\mu\bigg|^2 \leq \int_{\Omega}|f^2|d\mu \int_{\Omega}|g^2|d\mu = ||f||_2^{2}||g||_{2}^{2}
$$
\end{theorem}


\begin{proposition_exam}{Minkowski's Inequality}{}Let $(\Omega, \sigmalgebra, \mu)$ be a measure space. Fix $p \in [1,\infty)$. Then, for measurable functions $f,g \in \mathcal{L}^p(\Omega)$, then 
$$
||f + g||_p = \bigg(\int |f+g|^pd\mu \bigg)^{1/p} \leq \bigg(\int |f|^pd\mu \bigg)^{1/p} + \bigg(\int |g|^pd\mu \bigg)^{1/p} = ||f||_p + ||g||_p.
$$
\end{proposition_exam}

\begin{remark}This is the triangle inequality for the $\mathcal{L}^p$ norm $||.||_p.$
\end{remark}

We can now summarise the properties of why $\mathcal{L}^p-$norm is in fact a pseudonorm.

\begin{proposition}(Properties of the $\mathcal{L}^p$-pseudonorm). Let $1 \leq p < \infty$. Then, for $f,g \in \mathcal{L}^p(X)$ and $\alpha \in \mathbb{R}$, we have 
\begin{enumerate}
\item $||f||_p \geq 0$ with equality if and only if $f = 0$ almost everywhere.
\item $||\alpha f ||_p = |\alpha| \;||f||_p$
\item $||f + g||_p \leq ||f||_p + ||g||_p$ (Minkowski's inequality).
\end{enumerate}
\end{proposition}

\begin{remark}The reason that $\mathcal{L}^p$-norm is not a proper norm since $||f||_p = 0$ \textbf{does not} necessarily imply that $f = 0$ is the zero function. This is important as in a normed vector space V, there is a \textbf{unique vector} $v \in V$ with $||v|| = 0$, known as the \textbf{zero vector}.
\end{remark}

We will see later on how can we turn the pseudnorm $||.||_p$ in a proper norm.

\subsection{Completeness of the $\mathcal{L}^p$-space}
We now look at sequences of functions in the $\mathcal{L}^p-$space.

\begin{definition}(Cauchy sequence). Let $\{f_n\}, f \in \mathcal{L}^p.$ We say that $\{f_n\}_{n \geq 1}$ is a \textbf{Cauchy sequence} in $\mathcal{L}^p$ if for every $\epsilon > 0$, there exists a $n_0 \in \mathbb{N}$ such that 
$$
||f_n - f_m||_p < \epsilon 
$$
for all $n, m > n_0.$
\end{definition}
\begin{remark}Recall that 
$$
||f_n - f_m||_p = (\int|f_n - f_m|^pd\mu)^{\frac{1}{p}}.
$$
\end{remark}

\begin{lemma}Every convergent sequence is a Cauchy sequence.
\end{lemma}

We want to show that $\mathcal{L}^p$ is complete. That is, every Cauchy sequence converges. The idea to show this is that if a Cauchy sequence has a convergent subsequence, then it converges. Note that for general sequences, this is not true.

First, recall that in $\mathcal{L}^1$, we have shown that if $f_n \rightarrow f$ in $L^1$, then there exists a sub-sequence $\{n_k\}$ such that $f_{n_{k}} \rightarrow f$ a.e. We extend this idea to $\mathcal{L}^p(X)$ space.

We use the next two lemmas to show completeness of the $\mathcal{L}^p(X)$ space.
\begin{lemma}Suppose that $\{f_n\}$ is a Cauchy sequence in $\mathcal{L}^p(X).$ If $\{f_{n_{k}}\}$ is a convergent subsequence, with $f_{n_{k}} \rightarrow f$ in $\mathcal{L}^p(X)$, then $f_n \rightarrow f$ in $\mathcal{L}^p(X).$
\end{lemma}

\begin{lemma}Let $\{g_k\}$ be a sequence of functions in $\mathcal{L}^p(X)$ such that 
$$
\sum_{k=1}^{\infty}||g_k||_p < \infty.
$$
Then, there exists a function $f \in \mathcal{L}^p(X)$ such that $f = \sum_{k=0}^{\infty}g_k$ converges pointwise almost everywhere and in $\mathcal{L}^p(X).$
\end{lemma}

We can now state the main theorem of this section.
\begin{theorem_exam}{Completeness of $\mathcal{L}^p$}{}Let $\{f_n\}_{n \geq 1}$ be a Cauchy sequence in $\mathcal{L}^p.$ Then, there exists a function $f \in \mathcal{L}^p$ such that $f_n \rightarrow f$ in $\mathcal{L}^p.$ Moreover, $\{f_n\}_{n \geq 1}$ has a subsequence that converges almost everywhere.
\end{theorem_exam}

\newpage
\subsection{$L^p$-spaces}

We have seen in the previous section that $\mathcal{L}^p-$norm is not a proper norm since $||f||_p = 0$ does not imply that $f = 0$ is the zero function. We can can only conclude that $f = 0$ almost everywhere. What we do is that we consider functions to be equal if they are equal almost everywhere. Hence, we can define an equivalence relation where $f \sim g$ if f = g almost everywhere.

\begin{definition_exam}{Equivalence class of functions equal almost everywhere}{} Let $(\Omega, \sigmalgebra, \mu)$ be a measure space. Let f be a measurable function. We define the equivalence class of f by 
$$
[f] = \{g: \Omega \rightarrow \mathbb{R}: \text{g is measurable and } f = g \text{ almost everywhere}\}.
$$
\end{definition_exam}


From this, we can introduce a family of vector spaces of these equivalence classes. 

\begin{definition_exam}{$L^p$-space}{} Let $(\Omega, \sigmalgebra, \mu)$ be a measure space. For $1 \leq p < \infty$, we define 
$$
L^p(\Omega, \sigmalgebra, \mu) \coloneqq \{[f]: f \in \mathcal{L}^p(\Omega,\sigmalgebra,\mu)\}.
$$
We set the $L^p$-norm as 
$$
\bigg|\bigg| [f]\bigg|\bigg|_p \coloneqq ||f||_p
$$
Similarly, we set 
$$
[f] + [g] \coloneqq [f + g] \quad \text{and} \quad \alpha[f] \coloneqq [\alpha f]
$$
for all $[f], [g] \in L^p(\Omega)$ and $\alpha \in \mathbb{R}.$
\end{definition_exam}


\begin{remark}In practice, we write $f \in L^p(\Omega)$ and call it an $L^p-$function rather than [f]. In many situations, we choose a representative in the equivalence class from $\mathcal{L}^p(\Omega).$
\end{remark}

\begin{remark}The norm $||.||_p$ on $L^p(\Omega)$ is a proper norm now.
\end{remark}

\begin{claim}(The $L^p(\Omega)$ class is the quotient space). Define the measure space $(\Omega, \sigmalgebra, \mu).$ Define $\mathcal{L}^p(\Omega)$ and $L^p(\Omega)$ to be as before. Then, define $\mathcal{N}(\Omega) = \{g: \Omega \rightarrow \mathbb{R}| \text{g is measurable and g = 0 almost everywhere}\}$. Then, $\mathcal{N}(\Omega)$ is a vector subspace of $\mathcal{L}^p(\Omega)$ and 
$$
L(\Omega) = \frac{\mathcal{L}^p(\Omega)}{\mathcal{N}(\Omega)}
$$
is the quotient space.
\end{claim}

\begin{lemma}Every inner product induces a norm. However, only a norm which satisfies the parallelogram law can define an inner product.
\end{lemma}

\begin{theorem_exam}{$L^p$-norm is a Banach space}{}Let $(\Omega, \sigmalgebra, \mu)$ be a measure space. Then, for $1 \leq p < \infty$, define the vector space $L^p(\Omega).$ The space $L^p(\Omega)$ is a complete normed space with respect to the norm $||.||_p.$
\end{theorem_exam}

\begin{remark}A complete normed vector space is called a \textbf{Banach space}.
\end{remark}

Furthermore, recall that a complete inner product space is called a \textbf{Hilbert space}. There is only \textbf{one} $L^p$-space that is a Hilbert space.

\begin{proposition_exam}{$L^2$-space is a Hilbert space}{}Let $L^2(\Omega)$ be a Banach space with respect to the $||.||_2$ norm. We have that $L^2(\Omega)$ is a complete inner product space with the inner product 
$$
\sqrt{\langle f, g \rangle} = \int_{\Omega}fg\;d\mu.
$$
\end{proposition_exam}


\lecture{9}{Expectation and Radon-Nikodym Theorem}
\section{Expectation}
\section{Expectation}
\subsection{Expectation}

\begin{definition_exam}{Expectation}{}Define the probability space $(\Omega, \sigmalgebra, \prob).$ Define the random variable $X: (\Omega, \sigmalgebra) \rightarrow (\extendedreal, \overline{\borelsigmaalgebra})$. The expectation of the random variable X is 
$$
E(X) = \int_{\Omega}Xd\prob
$$
provided the integral is well-defined. That is, the expectation is the Lebesgue integral with respect to the probability measure $\prob$.
\end{definition_exam}

\begin{remark}
Recall that $E(X) = \int_{\Omega}Xd\prob$ is well-defined if and only if $\min(\int_{\Omega}X^+d\prob, \int_{\Omega}X^-d\prob) < \infty.$ That is, either $E(X^+) < \infty$ and $E(X^-) \leq \infty$ \textbf{or} $E(X^+) \leq \infty$ and $E(X^-) < \infty.$
\end{remark}

\begin{lemma}X does not admit an expectation if and only if $E(X^+) = \infty$ \textbf{and} $E(X^-) = \infty.$
\end{lemma}

Recall that for a random variable X defined on $(\Omega, \mathcal{F}, \prob)$, we define the probability measure induced by X $\mu_X$ on $(\overline{\mathbb{R}}, \overline{\mathbb{B}})$ as 
$$
\mu_X(B) = \prob(X \in B)
$$
for all $B \in \overline{\mathbb{B}}.$

\begin{definition_exam}{Discrete Random Variable}{}A random variable X defined on $(\Omega, \mathcal{F}, \prob)$ is \textbf{discrete} if there exists a distinct sequence $\{x_k\}_k \subset \overline{\mathbb{R}}$ such that 
$$
\sum_k \prob(X = x_k) = \sum_k\mu_X(\{x_k\}) = 1.
$$
We denote by $\prob_X(x) = \mu_X(\{x\})$ the \textbf{probability mass function} of the discrete random variable X. The set $\{x_k: \prob_X(x_k) > 0\}$ is called the \textbf{support} of the probability mass function.
\end{definition_exam}

\begin{remark}In this construction, it is clear that X will take on one of the values $\{x_k\}$, that is, $\prob(X \in \{x_k\}) = 1$. However, in general, $\prob(X(\Omega) \neq \{x_k\}).$
\end{remark}

\begin{proposition_exam}{Expectation of discrete random variable is well-defined}{} Define a probability space $(\Omega, \sigmalgebra, \prob).$ Let X be a discrete random variable with support $\{x_k\}.$ Then, $E(X)$ is well-defined if and only if 
$$
\min\bigg\{\sum_{k: x_k > 0}x_k\prob_{X}(x_k), -\sum_{k: x_k < 0}x_k\prob_{X}(x_k) \bigg\} < \infty.
$$
\end{proposition_exam}

We now have a new definition for the expectation of a random variable.
\begin{definition_exam}{Expectation of a discrete random variable}{} Let X be a discrete random variable. Let the expectation E(X) be well-defined. Then, the expectation of the discrete random variable X is 
$$
E(X) = \sum_kx_k\prob_X(x_k).
$$
\end{definition_exam}


We also state the condition for when the expectation is not only defined but integrable.
\begin{proposition_exam}{Integrability of discrete random variable}{}Let X be a discrete random variable. Furthermore, assume that E(X) is defined. Then, $X \in L^1$ if and only if $\sum_k|x_k|\prob_X(x_k) < \infty.$
\end{proposition_exam}

\begin{remark}If $X \in L^1$, this implies that $E(X) < \infty$ where we require E(X) to be defined in the first place.
\end{remark}

We now work our way up to the Law of the unconscious statistician.
\begin{lemma}Let X be a discrete random variable. Let $h: \overline{\mathbb{R}} \rightarrow \overline{\mathbb{R}}$ be a measurable function. Then, $Y = h(X)$ is a random variable. Furthermore, Y is a \textbf{discrete} random variable.
\end{lemma}

Hence, we can show that we can compute the expectation of Y using the distribution function induced by the random variable X.
\begin{theorem_exam}{Law of the unconscious statistician}{}Let X be a discrete random variable. Let $Y = h(X)$ be a discrete random variable where $h: \overline{\mathbb{R}} \rightarrow \overline{\mathbb{R}}$ is a measurable function. Then, if $E(X)$ is well-defined, then $E(Y)$ is well-defined. Furthermore, we can write 
$$
E(Y) = \sum_kh(x_k)\prob_X(x_k)
$$
where $E(Y) < \infty$ if $X \in L^1.$
\end{theorem_exam}

\subsection{The Radon-Nikodym Theorem}
We have established distributions and cumulative distribution functions. We will now work our way towards defining density functions.

\begin{definition}(Integrals over subsets). Let $A \in \mathcal{F}.$ Let f be a measurable function. We then define the integral of f over A as 
$$
\int_Afd\mu = \int_{\Omega}f1_{A}d\mu
$$
provided the right hand side exists.
\end{definition}

\begin{definition_exam}{Measures with a density}{}
Let $(X, \mathcal{A}, \mu)$ be a measure space and $g: X \rightarrow [0, \infty)$ be a measurable function. For $A \in \mathcal{A}$, we define 
$$
\nu(A) \coloneqq \int_{A}gd\mu.
$$
for all $A \in \mathcal{A}$. We have that $\nu$ is a measure. We call g the \textbf{density} of $\nu$ with respect to $\mu.$
\end{definition_exam}

\begin{proof} We prove the 2 conditions needed for a measure.
$$
\nu(\emptyset) = \int_{\emptyset}gd\mu = \int_X1_{\emptyset}gd\mu = 0.
$$
Let $A_k \in \mathcal{A}, k \in \mathbb{N}$ be disjoint sets. 
Then 
$$
\nu(\bigcup_{k=0}^{\infty}A_k) = \int_{\bigcup_{k=0}^{\infty}A_k}gd\mu = \int_X1_{\bigcup_{k=0}^{\infty}A_k}gd\mu = \int_X\sum_{k=0}^{\infty}1_{A_{k}}gd\mu = \sum_{k=0}^{\infty}\int_X1_{A_{k}}gd\mu = \sum_{k=0}^{\infty}\nu(A_k)
$$
where the second last equality arises from the monotone convergence theorem applied to power series. Hence, $\nu$ is a measure.
\end{proof}


We are now interested in the question that if $\mu$ and $\nu$ are arbitrary measures both defined on the $\sigma-$algebra $\mathcal{A}$, does $\nu$ have a density with respect to $\mu$. That is, does there exist a measurable function $g: X \rightarrow [0,\infty)$ such that 
$$
\nu(A) = \int_{A}gd\mu
$$
for all $A \in \mathcal{A}.$

The general answer is \textbf{no}. However, there is a condition needed for this to always hold.


\begin{definition_exam}{Absolutely Continuous}{}Let $\mu, \nu$ be measures defined on the same $\sigma-$algebra of subsets of X. We call $\nu$ \textbf{absolutely continuous} with respect to $\mu$ if for every $A \in \mathcal{A}$, $\mu(A) = 0$ implies that $\nu(A) = 0.$ If that is the case, we write 
$$
\nu << \mu.
$$
\end{definition_exam}

\begin{remark}This can also be thought of as $\nu$ being \textbf{dominated} by the measure $\mu.$
\end{remark}

Hence, if we have two measures that are absolutely continuous, then we have a density function.

\begin{theorem_exam}{Radon-Nikodym Theorem}{}Define the measure space $(\Omega, \sigmalgebra, \mu).$ Suppose $\mu$ and $\nu$ are $\sigma-$finite measures defined on the same $\sigma-$algebra $\mathcal{F}.$ Moreover, assume that $\nu << \mu.$ Then, $\nu$ has a density function $f: \Omega \rightarrow [0, \infty)$ with respect to $\mu$ such that 
$$
\nu(A) = \int_{A}fd\mu
$$
for all $A \in \mathcal{F}.$

Moreover, the density is \textbf{essentially unique}, that is, any two density function are equal $\mu-$almost everywhere.
\end{theorem_exam}

\begin{remark}We can write
$$
\int_{\Omega}fd\nu = \int_{\Omega}f\frac{d \nu }{d \mu}d\mu
$$
if we let $\frac{d\nu}{d\mu} = f$ where f is the density function from the Radon-Nikodym theorem. In this case, f is also known as the \textbf{Radon-Nikodym derivative} of $\nu$ with respect to $\mu$ which exists if $\nu << \mu.$
\end{remark}



We now relate all these measure theory concepts to probability theory. Let $(\Omega, \mathcal{F}, \prob)$ be our probability space. Let X be our random variable to $(\mathbb{R}, \mathbb{B})$. Recall that the \textbf{distribution} measure of the random variable X is the probability measure $\mu_X$ on $\mathbb{B}$ defined by 
$$
\mu_X(B) = \prob[X^{-1}(B)]
$$
for all $B \in \mathbb{B}$. That is, $\mu_X$ is the \textbf{push-forward} of the measure $\prob$ by the map X. 

Finally, we can also work with the real-valued $F_X$ defined by 
$$
F_X(x) = \mu_X((-\infty, x]) = \prob[X \leq x]
$$
for $x \in \mathbb{R}$. We call $F_x$ the \textbf{(cumulative) distribution function} of the random variable X. We can now relate the Radon-Nikodym theorem to all of this.


\begin{definition_exam}{Distribution function is Absolutely Continuous to the Lebesgue Measure}{}Let $(\Omega, \mathcal{F}, \prob)$ be a probability space. Let X be the random variable $(\Omega, \mathcal{F}) \rightarrow (\mathbb{R}, \mathbb{B}).$ The distribution measure $\mu_X = \prob[X^{-1}(B)]$, is \textbf{absolutely continuous} with respect to the Lebesgue measure $\lambda$ on $\mathbb{B}(\mathbb{R})$ if $\mu_{X}(\mathbb{R}) = 1$ and there exists a measurable function $f: (\mathbb{R}, \borelsigmaalgebra) \rightarrow ([0, \infty], \borelsigmaalgebra)$ such that 
$$
\mu_X(B) = \int_Bfd\lambda
$$
for all Borel sets $B \in \mathbb{B}.$ We call the function $f$ the \textbf{(probability) density function} of $\mu_X$.
\end{definition_exam}

\begin{remark}In other words, the Radon-Nikodym derivative $\frac{d\mu_X}{d\lambda}$ is the probability density function (pdf) of X. 
\end{remark}


\begin{lemma}There is a one-to-one correspondence between distribution measures and distribution functions.
\end{lemma}

\begin{remark}
Many random variables can induce the same distribution measure and cumulative distribution function. However, the converse does not hold.
\end{remark}


We now show how we can get continuous random variables. First, we need a different characterisation of absolutely continuous.

\begin{theorem_exam}{Characterisation of absolutely continuous cumulative distribution function}{}Let $\mu$ be a finite Borel measure on $\mathbb{R}$ and $F(t) \coloneqq \mu((-\infty,t])$ be the cumulative distribution function associated with $\mu$. Denote by $\lambda$, the Lebesgue measure on $\mathbb{R}.$ Then, $\mu << \lambda$ if and only if for every $\epsilon > 0$, there exists a $\delta > 0$ such that 
$$
\sum_{k=1}^{\infty}|F(b_k) - F(a_k)| < \epsilon
$$
for every countable collection $(a_k, b_k)$ of disjoint intervals such that 
$$
\sum_{k=1}^{\infty}|b_k - a_k| < \delta.
$$
\end{theorem_exam}

Hence, we can state where continuous random variables come from.
\begin{proposition_exam}{Cumulative Distribution Function is Continuous}{}Let F be a cumulative distribution function associated to the Borel measure $\mu$. Then, if F is absolutely continuous, then F is a continuous function.
\end{proposition_exam}

\begin{remark}This gives us that if our random variable X has a cumulative distribution function that is absolutely continuous, then the cumulative distribution function is continuous. This is what is meant by a continuous random variable.
\end{remark}

\subsection{Substitution theorem for random variables}
In practice, we don't want (and can't) integrate the random variable X over the sample space $\Omega$. We would would rather work with the distribution of X. In particular, we want to express integrals over $\Omega$ with respect to $\prob$ into integrals over $\mathbb{R}$ with respect to the distribution function $\mu_X.$ First, we recall a few technical results.
\begin{lemma}Let $X: \Omega \rightarrow \mathbb{R}$ be a random variable on the probability space $(\Omega, \sigmalgebra, P)$ and $h: \mathbb{R} \rightarrow \mathbb{R}$ be Borel measurable. Then $h \circ X: \Omega \rightarrow \mathbb{R}$ is measurable.
\end{lemma}

\begin{claim}Let X be a random variable on the probability space $(\Omega, \sigmalgebra, P).$ Then, the set function 
$$
\mu_X(B) = P(X^{-1}(B)) = P(\{\omega: X(\omega) \in B\})
$$
for all Borel sets $B \in \borelsigmaalgebra$ is a measure.
\end{claim}

We now state a proposition we will use alot later. We will state it for the case of a simple function but it can easily be extended to non-negative and measurable function.
\begin{proposition_exam}{Change of variables formula}{} Let $X: \Omega \rightarrow \mathbb{R}$ be a random variable on the probability space $(\Omega, \sigmalgebra, \prob)$ and $h: \mathbb{R} \rightarrow [0,\infty)$ be a Borel non-negative simple function. Then 
$$
\int_{\Omega}h\circ Xd\prob = \int_{\mathbb{R}}hd\mu_X.
$$
\end{proposition_exam}

\begin{proof} As h is a simple function, let $h = \sum_{k=1}^{n}a_k1_{A_{k}}.$ Now 
$$
(1_{A_{k}} \circ X)(\omega) = 1_{A_{k}}(X(\omega))
$$
where $X(\omega) \in A_k$ if and only if $\omega \in X^{-1}(A_k).$ Hence, we can write 
$$
h \circ X = \sum_{k=1}^{n}a_k1_{A_{k}}\circ X = \sum_{k=1}^{n}a_k1_{X^{-1}(A_{k})}.
$$
Now, we can integrate to get our desired result 
$$
\int_{\Omega}h \circ Xd\prob = \int_{\Omega}\sum_{k=1}^{n}a_k1_{A_{k}}\circ Xd\prob = \int_{\Omega}\sum_{k=1}^{n}a_k1_{X^{-1}(A_k)}d\prob
$$
$$
= \sum_{k=1}^{n}\int_{\Omega}a_k1_{X^{-1}(A_k)}d\prob = \sum_{k=1}^{n}a_k \prob(X^{-1}(A_k))
$$
where recall that by definition $\mu_X(A_k) = \prob(X^{-1}(A_k))$, so therefore we have that
$$
= \sum_{k=1}^{n}a_k\mu_{X}(A_k) = \int_{\mathbb{R}}hd\mu_X
$$
where we used the fact that h is a simple function $h = \sum_{k=1}^{n}a_k1_{A_{k}}.$
\end{proof}

Notice that the change of variables integrates over the domain of the functions!

We can extend the change of variables formula to h being non-negative and measurable using the usual machinary in measure theory.

\subsection{Expectation of Functions of Random Variables}

We first define the change of variables theorem for \textbf{non-negative} functions of random variables.

\begin{theorem_exam}{Change of variables formula for non-negative random variables}{} Let X be a random variable defined on a probability space $(\Omega, \mathcal{F}, P)$. Let $\mu_X$ be the distribution probability measure on $(\overline{\mathbb{R}}, \overline{\borelsigmaalgebra})$ induced by X. Now, suppose that $h: (\overline{\mathbb{R}}, \overline{\borelsigmaalgebra}) \rightarrow (\overline{\mathbb{R}}^+, \overline{\borelsigmaalgebra}^+)$ is a measurable and non-negative function. Let $Y = h(X).$ Then 
\begin{enumerate}
\item  $Y \in \mathcal{F}^+$ is a measurable non-negative random variable; 
\item $
E(Y) = \int_{\Omega} YdP = \int_{\Omega}h \circ XdP = \int_{\mathbb{R}}hd\mu_X .
$
\end{enumerate}
\end{theorem_exam}
\begin{proof} $Y \in \sigmalgebra^+$ is clear as $X \in \sigmalgebra^+$ and h is a measurable non-negative function. 

We can apply the change of variables formula to $E(Y) = \int_{\Omega} YdP$ to get the desired result where 
$$
E(Y) = \int_{\mathbb{R}}hd\mu_X .
$$
\end{proof}

Before we extend the change of variables theorem to hold for all measurable functions $h \in \sigmalgebra$, we require another condition.
\begin{proposition}Let X be a random variable defined on a probability space $(\Omega, \mathcal{F}, P)$. Suppose that the function $h: \mathbb{R} \rightarrow \mathbb{R}$ is Borel measurable. Then, $h \circ X \in L^1(\Omega,P)$ if and only if $h \in L^1(\mathbb{R},\mu_X)$ where $\mu_X$ is the distribution measure induced by the random variable X.
\end{proposition}

Now, we extend the above theorem to measurable functions h.

\begin{theorem_exam}{Change of variables formula for $L^1$ functions}{}Let X be a random variable defined on a probability space $(\Omega, \mathcal{F}, P)$. Let $\mu_X$ be the distribution probability measure on $(\overline{\mathbb{R}}, \overline{\borelsigmaalgebra})$ induced by X. Now, suppose that $h: (\overline{\mathbb{R}}, \overline{\borelsigmaalgebra}) \rightarrow (\overline{\mathbb{R}}, \overline{\borelsigmaalgebra})$ is a measurable function. Furthermore, assume that $h \in L^1(\mathbb{R}, \mu_X).$ Then we have that 
$$
E(Y) = \int_{\Omega} YdP = \int_{\Omega}h \circ XdP = \int_{\mathbb{R}}hd\mu_X .
$$
\end{theorem_exam}

\begin{proof}(Sketch). This theorem follows from the change of variables formula for non-negative random variables as we can write $h = h^+ - h^-.$
\end{proof}

\begin{remark}
The change of variables formula for non-negative random variables and $L^1$ functions hold for \textbf{any} random variable.
\end{remark}


Recall that if $\mu_X$ is absolutely continuous with respect to the Lebesgue measure $\lambda$, then there exists a density function f. We first state the following claim to help us prove the subsequent theorem.

\begin{proposition_exam}{Radon-Nikodym for distribution and Lebesgue measure}{}Suppose $\mu_X$ is a probability measure on $(\overline{\mathbb{R}}, \overline{\mathbb{B}})$ that is absolutely continuous with respect to the Lebesgue measure $\lambda$ and the Radon-Nikodym derivative is the density function f. Then, for any measurable function $h:(\overline{\mathbb{R}}, \overline{\mathbb{B}}) \rightarrow (\overline{\mathbb{R}}, \overline{\mathbb{B}})$, we have that 
$$
\int_{\overline{\mathbb{R}}}hd\mu_X = \int_{\mathbb{R}}hd\mu_X = \int_{\mathbb{R}}h\cdot fd\lambda.
$$
\end{proposition_exam}

\begin{proof} First, recall that $\mu(\mathbb{R}) = 1.$ This gives us 
$$
\int_{\overline{\mathbb{R}}}hd\mu_X = \int_{\mathbb{R}}hd\mu_X + \int_{\{-\infty, \infty\}}hd\mu_X
$$
Now, we look at the second term 
$$
\int_{\{-\infty, \infty\}}hd\mu_X \leq \int_{\{-\infty, \infty\}}\infty d\mu_X = \infty\mu_X(\{-\infty, \infty\}) = \infty \cdot 0 = 0.
$$
Therefore, we have that 
$$
\int_{\overline{\mathbb{R}}}hd\mu_X = \int_{\mathbb{R}}hd\mu_X
$$
We now want to show 
$$
\int_{\mathbb{R}}hd\mu_X = \int_{\mathbb{R}}h\cdot 
$$
First, let $h = 1_A$ be an indicator function for some $A \in \overline{\borelsigmaalgebra}.$ Then, we have that 
$$
\int_{\mathbb{R}}hd\mu_X = \int_{\mathbb{R}}1_{A}d\mu_X = \mu_X(A) = \int_Afd\lambda = \int_{\mathbb{R}}1_Afd\lambda = \int_{\mathbb{R}}h\cdot fd\lambda 
$$
We can then extend this to show simple functions by using the linearity of the integral. Then, for non-negative measurable functions, we can use the monotone convergence theorem. Finally, for measurable functions, we can split it up into positive and negative parts.
\end{proof}

\begin{theorem_exam}{Expectation with density functions}{}Let $(\Omega, \sigmalgebra, P)$ be a probability space. Let X be a random variable. Let $h: (\overline{\mathbb{R}}, \overline{\mathbb{B}}) \rightarrow (\overline{\mathbb{R}}, \overline{\mathbb{B}})$ be a measurable function. Define $Y = h(X).$ If X has a density function f, then $\mu_X$ is absolutely continuous with respect to the Lebesgue measure $\lambda$. Then we can define the expectation of Y using the Lebesgue integral
$$
E(Y) = \int_{\Omega}h \circ XdP = \int_{\mathbb{R}}hd\mu_X = \int_{\mathbb{R}}h\cdot fd\lambda
$$
with the left hand side defined if and only if the right hand side is defined.
\end{theorem_exam}

We are now interested in expressing expectations in terms of the Riemann integral rather than the Lebesgue integral.

\begin{theorem}(Expectation of non-negative functions using Riemann integrals). Define the probability space $(\Omega, \sigmalgebra, P)$. Let X be a random variable that has a density function f and let $h: \mathbb{R} \rightarrow \mathbb{R}^+$ be a measurable function such that $g(x) = h(x)f(x)$ is a Riemann integrable function on any finite interval. Denote $\int_{-\infty}^{\infty}dx$ as the Riemann integral and $\int d\lambda$ as the Lebesgue integral. Then 
$$
E(Y) = \int_{\mathbb{R}}h\cdot fd\lambda = \int_{-\infty}^{\infty}h(x)f(x)dx.
$$
\end{theorem}

\begin{proof}(Sketch). First write $E(Y) = \int_{\mathbb{R}}h\circ fd\lambda$ using the expectation with density functions theorem. Then, recall that a function that is Riemann integrable on a finite interval is equal to the Lebesgue integral of the function.
\end{proof}


\begin{corollary}Define the probability space $(\Omega, \sigmalgebra, P)$. Let X be a random variable that has a density function f and let $h: \mathbb{R} \rightarrow \mathbb{R}^+$ be a measurable function such that $g(x) = h(x)f(x)$ is a Riemann integrable function on any finite interval. Then, $X \in L^{1}(\Omega)$ if and only if the following Riemann integral is finite 
$$
\int_{-\infty}^{\infty}|x|f(x)dx < \infty.
$$
\end{corollary}

We now generalise the above theorem to hold for any measurable function h.


\begin{theorem_exam}{Expectation of measurable functions using Riemann integrals}{} Define the probability space $(\Omega, \sigmalgebra, P)$. Let X be a random variable that has a density function f and let $h: \mathbb{R} \rightarrow \mathbb{R}$ be a measurable function such that $g(x) = h(x)f(x)$ is a Riemann integrable function on any finite interval. Denote $\int_{-\infty}^{\infty}dx$ as the Riemann integral and $\int d\lambda$ as the Lebesgue integral. Then 
$$
E(Y) = \int_{\mathbb{R}}h\circ fd\lambda = \int_{-\infty}^{\infty}h(x)f(x)dx.
$$
\end{theorem_exam}


\begin{corollary}Define the probability space $(\Omega, \sigmalgebra, P)$. Let X be a random variable that has a density function f and let $h: \mathbb{R} \rightarrow \mathbb{R}$ be a measurable function such that $g(x) = h(x)f(x)$ is a Riemann integrable function on any finite interval. Then, $X \in L^{1}(\Omega)$ if and only if the following Riemann integral is finite 
$$
\min \bigg\{\int_{-\infty}^{\infty}h^+(x)f(x)dx,\int_{-\infty}^{\infty}h^-(x)f(x)dx \bigg \} < \infty.
$$
In this case, then 
$$
E(Y) = \int_{-\infty}^{\infty}h(x)f(x)dx.
$$
\end{corollary}


\begin{corollary}Define the probability space $(\Omega, \sigmalgebra, P)$. Let X be a random variable that has a density function f and let $h(x) = x$ be the identity function. Suppose that $g(x) = xf(x)$ is Riemann integrable on any finite interval. Then $E(X)$ is well-defined if and only if 
$$
\int_{-\infty}^{0}xf(x)dx > -\infty \quad \text{or} \quad \int_{0}^{\infty}xf(x)dx < \infty.
$$
If E(X) is well-defined, then 
$$
E(X) = \int_{-\infty}^{\infty}xf(x)dx.
$$
\end{corollary}

We can now state an important result that we only need to know the distribution function of the random variable X rather than X itself in order to compute expectation and variance.



\begin{proposition_exam}{Expectation and variance of a random variable}{} Define the probability space $(\Omega, \sigmalgebra, P)$. Let X be a random variable with distribution measure $\mu_X$. Suppose that X has density function f. Furthermore, suppose that $E(X)$ is well-defined. Then 
$$
E[X] = \int_{-\infty}^{\infty}xf(x)dx
$$
and 
$$
Var(X) = \int_{-\infty}^{\infty}x^2f(x)dx - E[X]^2.
$$
\end{proposition_exam}


We now state some theorem regarding expectation of random variables.

\begin{definition}(Bounded random variable). Let $X$ be a random variable. X is said to be bounded if 
$$
X \leq C < \infty
$$
almost surely.
\end{definition}

Recall that earlier we did not establish a direct relationship between convergence almost surely and convergence in $L^1.$ We can now do so if we impose an additional assumption.

\begin{theorem_exam}{Bounded Convergence Theorem}{}Let $X_n$ be a sequence of random variables defined on the probability space $(\Omega, \mathcal{F}, P).$ If $X_n$ are bounded and $X_n \rightarrow X$ almost surely, then 
$$
X_n \rightarrow X \text{ in } L^1
$$
\end{theorem_exam}

\begin{proof} We have that as $X_n$ are bounded random variables, then $X_n \leq C$ for all n. Therefore 
$$
\lim_{n \rightarrow \infty}\int_{\Omega}|X_n - X|d\prob = \lim_{n \rightarrow \infty}\int_{\Omega \setminus N}|X_n - X|d\prob = \int_{\Omega \setminus N}\lim_{n \rightarrow \infty}|X_n - X|d\prob = 0
$$
where N is a set of measure zero where $X_n \not \rightarrow X.$ The interchange of integral and limit arises from the dominating convergence theorem, whereby we then use the fact that $X_n \rightarrow X$ a.s. on $\Omega \setminus N.$
\end{proof}

\begin{remark}Recall that in a probability space, convergence in $L^1$ is also known as \textbf{convergence in the mean.} Therefore, if our random variables are bounded and they converge almost surely, then they also converge in mean. The bounded convergence theorem is a weakened form of the dominating convergence theorem whereby the dominating function is now a constant.
\end{remark}

We now state a series of claims regarding the expectation of sequences of random variables.
\begin{claim}Let X be a sequence of random variables defined on $(\Omega, \mathcal{F}, P).$ Then, we have the following.
\begin{enumerate}
\item (Finite additivity) If $X_i \in L^1(\Omega)$, then $E(\sum_{i=1}^{n}X_i) = \sum_{i=1}^{n}E(X_i).$
\item (Countable additivity) If $X_n \geq 0$ almost surely, then $E(\sum_{i=1}^{\infty}X_n) = \sum_{i=1}^{\infty}E(X_i).$
\item (Finite expectation implies bounded almost surely) If X is a random variable with $E(X) < \infty$, then $P(X < \infty) = 1.$
\item If $X_n \geq 0$ almost surely and $\sum_{i=1}^{\infty}E(X_n) < \infty$ then $\sum_{i=1}^{\infty}X_i < \infty$ almost surely. Furthemore, $X_n \rightarrow 0$ almost surely as $n \rightarrow \infty.$
\end{enumerate}
\end{claim}

\begin{proof}(Sketch). (1) Finite additivity can be proven by induction where for n = 2
$$
E(X_1 + X_2) = \int_{\Omega}X_1 + X_2d\prob = \int_{\Omega}X_1d\prob + \int_{\Omega}X_2d\prob = E(X_1) + E(X_2) = \sum_{i=1}^{2}E(X_i).
$$

(2) We can extend finite addivity to countable additivity by defining $Y_n = \sum_{i=1}^{n}X_i$ and noting that $Y_n \leq Y_{n + 1}$. We can then use finite addivitiy and the monotone convergence theorem to get our desired result 
$$
\lim_{n \rightarrow \infty}\sum_{i=1}^{n}E(X_i) = \lim_{n \rightarrow \infty}E(\sum_{i=1}^{n}X_i) = \lim_{n \rightarrow \infty}\int_{\Omega}Y_nd\prob = \int_{\Omega}\lim_{n \rightarrow \infty}Y_nd\prob = E(\sum_{i=1}^{\infty}X_i).
$$

(3) We show this by proof by contradiction. Suppose that $\prob(X < \infty) \neq 1$. Then $\prob(X = \infty) = \epsilon.$ Then, define the set S to be the set where $X = \infty.$ Then, we have that
$$
E(X) = \int_{\Omega}Xd\prob = \int_{\Omega \setminus S}Xd\prob + \int_{S}Xd\prob = \infty.
$$

(4) First, by countable additivity, we have that 
$$
E(\sum_{i=1}^{\infty}X_n) = \sum_{i=1}^{\infty}E(X_i) < \infty
$$
Then, by (3), a random variable with finite expectation implies that it is bounded almost surely 
\begin{equation}
\prob( \sum_{i=1}^{\infty}X_i < \infty) = 1 
\tag{*}
\end{equation}

Define the set 
$$
S = \{\omega: \sum_{i=1}^{\infty}X_i(\omega) < \infty\}
$$
and by (*), this implies that $\prob(S) = 1.$ Now, for a fixed $\omega \in \Omega$, we have that 
$$
\lim_{n \rightarrow \infty}\sum_{i=1}^{n}X_n(\omega) \leq C
$$
where we define C to be the supremum bound for all $X_i.$ We can therefore apply the bounded convergence theorem 
$$
\lim_{n \rightarrow \infty}X_n(\omega) = \lim_{n \rightarrow \infty}\sum_{i=1}^{n}X_n(\omega) - \lim_{n \rightarrow \infty}\sum_{i=1}^{n - }X_n(\omega) = C - C = 0.
$$
Therefore, we can conclude that for every $X_n \rightarrow 0$ almost surely.
\end{proof}

We now state a theorem that is useful for us when computing moments.
\begin{theorem_exam}{$L^p$-spaces are nested}{}Suppose X is a measurable function defined on the measure space $(\Omega, \mathcal{F}, \mu)$ with $\mu(\Omega) < \infty$. Then 

\begin{enumerate}
\item If $X \in L^p(\Omega)$ for $p \geq 1$, then $$X \in L^r(\Omega)$$ for all $r \in [1, p].$ 
\item Furthermore, if $\mu = P$, then 
$$
||X||_r \leq ||X||_p.
$$
\end{enumerate}

\end{theorem_exam}

\begin{remark}We will soon see that if a random variable $X \in L^2(\Omega)$, then that means $X \in L^1(\Omega)$ as well. This will be helpful for computing momentss.
\end{remark}


\subsection{Convex Functions}
We go on a quick detour on convexity.
\begin{definition_exam}{Convex Function}{}A function $\phi: I \rightarrow \mathbb{R}$ is convex on $I \subset \mathbb{R}$ where I is some open interval if for all $x, y \in I$ and $t \in [0,1]$, we have that 
$$
\phi(tx + (1 - t)y) \leq t\phi(x) + (1 - t)\phi(y).
$$
\end{definition_exam}

\begin{lemma}The p-norms are convex functions.
\end{lemma}

\begin{theorem_exam}{Jensen's Inequality}{}Let $\phi: I \rightarrow \mathbb{R}$ be a convex function on an open interval $I \subset \mathbb{R}$ and let $X$ be a random variable in $L^1$ with $P(X \in I) = 1$. Then, $E[\phi(X)]$ is well defined and 
$$
E[\phi(X)] \geq \phi(E[X]).
$$
\end{theorem_exam}

\begin{corollary}Let $\phi(x) = x^2$. Then, we have that $$[E(X)]^2 \leq E(X^2)$$
\end{corollary}

\subsection{Variance and Covariance}

We move on to defining variance and covariance.
\begin{lemma}Suppose that $X \in L^1(\Omega).$ Then, $\mu = E(X) < \infty$. Then, $E(X - \mu)^2$ is well-defined.
\end{lemma}
We now want to see if $E(X - \mu)^2$ is integrable.

\begin{lemma}Let X be a random variable such that $X \in L^1(\Omega)$. We have that $(X - \mu)^2 \in L^1$ if and only if $X \in L^2.$
\end{lemma}

\begin{proof} We have that $(X - \mu)^2 = X^2 - 2\mu X + \mu^2$. From this, it is clear that $(X - \mu)^2 \in L^1$ if and only if $X^2 \in L^1$ 
\end{proof}

\begin{definition_exam}{Variance}{} Let X be a random variable such that $X \in L^2(\Omega)$.
Then, the \textbf{variance} of X is defined by 
$$
Var(X) = E((X - \mu)^2) < \infty.
$$
\end{definition_exam}

We state a useful theorem involving the variance of a random variable.

\begin{theorem_exam}{Chebychev's Inequality}{}For $X \in L^1$ with $\mu = E[X]$, we have that 
$$
\prob(|X - \mu| \geq \epsilon) \leq \frac{Var(X)}{\epsilon^2}.
$$
\end{theorem_exam}

We now define the notion to relate how 2 random variables relate to each other.

\begin{definition_exam}{Covariance}{}Define $X,Y$ to be random variable such that $X, Y \in L^1(\Omega).$ Furthermore, assume that their product $X \cdot Y \in L^1(\Omega).$ We define the covariance of X and Y to be 
$$
Cov(X,Y) = E[X - E(X)][Y - E(Y)] = E[XY] - E(X)\cdot E(Y)
$$
\end{definition_exam}

We now extend the notion of variance of a sum of random variables.

\begin{proposition_exam}{Variance of sum of random variables}{}Let $X_1,...,X_n$ be random variables such that $X_1,...,X_n \in L^2(\Omega$). Then the product $X_iX_j \in L^1(\Omega)$ for all $i,j.$ Furthermore, 
$$
Var(\sum_{i=1}^{n}X_i) = \sum_{i=1}^{n}Var(X_i) + \sum_{i,j}Cov(X_i, X_j).
$$
\end{proposition_exam}

\begin{remark}Generally, if $X, Y \in L^1(\Omega)$, it does not follow that $X.Y \in L^1(\Omega).$ It does follow if $X, Y \in L^2(\Omega).$
\end{remark}

\begin{theorem}(Cauchy-Schwarz). Let $X_i, X_j \in L^1(\Omega).$ Then 
$$
||X_iX_j||_1 \leq ||X_i||_2 \cdot ||X_j||_2
$$
\end{theorem}

\begin{theorem_exam}{Independence of random variables implies expectations is independent}{} Let X and Y be random variables such that X,Y are independent and $X,Y \in L^1(\Omega)$. Then $X \cdot Y \in L^1(\Omega)$ and 
$$
E[XY] = E[X]E[Y].
$$
\end{theorem_exam}

\begin{corollary}If X,Y are independent $L^1$ random variables, then 
\begin{enumerate}
\item Cov(X,Y) = 0
\item If X, Y are also in $L^2(\Omega)$, then $Var(X+Y) = Var(X) + Var(Y).$
\end{enumerate}
\end{corollary}


\begin{claim}If $X_i$ are independent random variables and $\phi_i: \overline{\mathbb{R}} \rightarrow \overline{\mathbb{R}}$ are measurable functions, then $Y_i = \phi_i(X_i)$ are independent random variables.
\end{claim}

\begin{theorem_exam}{Version of Strong Law of Large Numbers}{}Suppose that $X_i$ are independent and identically distributed random variables with finite fourth moment $||X_i||_4 \leq C < \infty.$ Let $S_n = \sum_{i=1}^{n}X_i.$ Then, 
$$
\frac{S_n}{n} \rightarrow \mu = E(X_i)
$$
almost surely as $N \rightarrow \infty.$
\end{theorem_exam}

\lecture{10}{Product Measures}
\section{Product Measures}
\section{Product Measures}
\subsection{Caratheodory Extension Theorem for Product Measures}
We now want to move into working with multiple random variables. This section only looks at the case of having two measurable spaces $(\Omega_j, \sigmalgebra_j)$ for j=1,2. There are two ways to define measures on product spaces. We can use Caratheodory's extension theorem on a semi-algebra of rectangles or we can use the monotone class theorem as seen in lectures. We will illustrate both methods. First, we present a series of steps to derive the product measure using Caratheodory's extension theorem.

\begin{definition_exam}{Rectangles}{} Define the measure spaces $(\Omega_i, \sigmalgebra_i, \mu_i)$ for i = 1,2. Define the product space $\Omega_1 \times \Omega_2 = \{(x,y): x \in \Omega_1, y \in \Omega_2\}.$ Then, define $\sigmalgebra_1 \times \sigmalgebra_2$ as the class of rectangles $E_1 \times E_2$ where $E_j \in \sigmalgebra_j.$
\end{definition_exam}

\begin{lemma}The class of rectangles $\sigmalgebra_1 \times \sigmalgebra_2$ is a semi-algebra.
\end{lemma}

\begin{definition_exam}{x and y section of a rectangle}{}Define the measure spaces $(\Omega_i, \sigmalgebra_i, \mu_i)$ for i = 1,2. Let $\sigmalgebra_1 \times \sigmalgebra_2$ be the class of rectangles. Then, take a rectangle $A \in \sigmalgebra_1 \times \sigmalgebra_2.$ Then, the x-section $A_x$ and the y-section $A^y$ of the rectangle A is defined as 
$$
\begin{cases}
A_x = \{y \in \Omega_2: (x,y) \in A\} \quad \text{for } x \in \Omega_1\\\\
A^y = \{x \in \Omega_1: (x,y) \in A\} \quad \text{for } y \in \Omega_2.
\end{cases}
$$

Furthermore, $A_x \subseteq \Omega_2$ and $A^y \subseteq \Omega_1.$
\end{definition_exam}

We can define measurable sets from the x and y section.

\begin{proposition_exam}{The x and y section of rectangles are measurable}{}Let $\sigmalgebra_1 \times \sigmalgebra_2$ be the class of rectangles. Let $A \in \sigmalgebra_1 \times \sigmalgebra_2$ be a rectangle. Denote $A_x$ as the x-section of the rectangle and $A^y$ the y-section of the rectangle. Then 
$$
\begin{cases}
A_x \in \sigmalgebra_2 \quad \text{for all }x \in \sigmalgebra_2\\\\
A^y \in \sigmalgebra_1 \quad \text{for all }x \in \sigmalgebra_1
\end{cases}
$$
\end{proposition_exam}

We can take the semi-algebra of rectangles, define a pre-measure on it, and from that, use Caratheodory's extension theorem to define the product measure.

\begin{proposition_exam}{Unique extension to construct product measure}{}Define the measure spaces $(\Omega_i, \sigmalgebra_i, \mu_i)$ for i = 1,2. Let $\sigmalgebra_1 \times \sigmalgebra_2$ be the class of rectangles. Define the pre-measure on $\sigmalgebra_1 \times \sigmalgebra_2$ as
$$
\mu(E_1 \times E_2) = \mu_1(E_1)\mu_2(E_2).
$$
Then, $\mu(.)$ is $\sigma-$additive. Furthermore, if $\mu_i$ are $\sigma-$finite, then by Caratheodory's extension theorem, we can extend $\mu$ uniquely to the $\sa$ generated by the class of rectangles $\sigma(\sigmalgebra_1 \times \sigmalgebra_2).$
\end{proposition_exam}

\subsection{Product Measure}
We now illustrate the construction of the product measure using the Monotone class theorem.

\begin{definition}(Cartesian Product of Sample Spaces)
Define the measurable spaces $(\Omega_j, \sigmalgebra_j)$ for j=1,2. Let $\Omega = \Omega_1 \times \Omega_2 = \{(\omega_1, \omega_2): \omega_i \in \Omega_i\}.$
\end{definition}

\begin{claim}Define the measurable spaces $(\Omega_j, \sigmalgebra_j)$ for j=1,2. Let $I = \{A_1 \times A_2: A_i \in \sigmalgebra_i\}.$ Then I is a $\pi-$system.
\end{claim}

\begin{proof} Let $A_1 \times A_2 = A \in I$ and $B_1 \times B_2 \in I$ where $A_i \in \sigmalgebra_i$ and $B_i \in \sigmalgebra_i.$ Then
$$
A \cap B = (A_1 \times A_2) \cap (B_1 \times B_2) = (A_1 \cap B_1) \times (A_2 \cap B_2)
$$
We have that $(A_j \cap B_j) \in \sigmalgebra_j$ as $A_j, B_j \in \sigmalgebra_j$ and $\sigmalgebra_j$ is a $\sa.$ Therefore, by definition of I, 
$$
A \cap B \in I
$$
and therefore we can conclude that I is a $\pi-$system.
\end{proof}

\begin{definition_exam}{Product $\sa$}{}
Define the measurable spaces $(\Omega_j, \sigmalgebra_j)$ for j=1,2. Let $I = \{A_1 \times A_2: A_i \in \sigmalgebra_i\}.$ Then, $\sigmalgebra = \sigma(I)$ is the \textbf{product} $\sa$ which we denote by $\mathcal{\sigmalgebra} = \sigmalgebra_1 \times \sigmalgebra_2$.
\end{definition_exam}

\begin{definition_exam}{Co-ordinate map}{} Let $\Omega$ be the Cartesian product of $\Omega_1, \Omega_2$ and $\sigmalgebra = \sigmalgebra_1 \times \sigmalgebra_2.$ The $i^{th}$ coordinate map $p_i: \Omega \rightarrow \Omega_i$ is defined as 
$$
p_i(\omega_1, \omega_2) = \omega_i.
$$
\end{definition_exam}

\begin{claim}Let $p_i$ be the coordinate map. Then, the map $p_i$ is measurable with respect to the product $\sa$ $\sigmalgebra.$
\end{claim}

\begin{proof} First, recall that $\Omega = \Omega_1 \times \Omega_2.$ The i-th coordinate map $p_i$ is defined as 
$$
p_i: \Omega \rightarrow \Omega_i
$$
where $p_i(\omega_1, \omega_2) \rightarrow \omega_i.$ Then, to show that $p_i$ is measurable with respect to $\sigmalgebra,$ we need to show that for each $A \in \sigmalgebra_i$, we have that $p_i^{-1}(A) \in \sigmalgebra.$ It is clear that 
$$
p_1^{-1}(A_1) = A_1 \times \Omega_2 \quad \text{ for all } A_1 \in \sigmalgebra_1
$$
$$
p_2^{-1}(A_1) = \Omega_1 \times A_2 \quad \text{ for all } A_2 \in \sigmalgebra_2
$$
As $A_1 \in \sigmalgebra_1$ and $\Omega_2 \in \sigmalgebra_2$, we can conclude that $A_1 \times \Omega_2 \in I$ and therefore $A_1 \times \Omega_2 \in \sigma(I) = \sigmalgebra.$ A similar argument holds to argue that $\Omega_1 \times A_2 \in \sigma(I).$ Therefore, $p_i$ is measurable with respect to $\sigmalgebra.$
\end{proof}

\begin{claim}(Equivalent way of constructing the product $\sa$). Let $p_i$ be the $i^{th}$ co-ordinate map for i = 1,2. Then, an alternative method to construct the product $\sa$ would be 
$$
\sigmalgebra = \sigma(p_1,p_2).
$$

Equivalently, we can construct the product $\sa$ through 
$$
\sigmalgebra = \sigma(B_1 \times \Omega_2, \Omega_1 \times B_2: B_i \in \sigmalgebra_i).
$$
\end{claim}

\begin{proof} We have already shown that 
$$
p_1^{-1}(A_1) = A_1 \times \Omega_2 \quad p_2^{-1}(A_2) = \Omega_1 \times A_2
$$
for all $A_1 \in \sigmalgebra_1$ and $A_2 \in \sigmalgebra_2.$ Therefore, we have that 
$$
\sigma(p_1, p_2) = \sigma(A_1 \times \Omega_2, \Omega_1 \times A_2: A_i \in \sigmalgebra_i)
$$

Additionally, we know that 
$$
(A_1 \times \Omega_2) \cap (\Omega_1 \times A_2) = A_1 \times A_2
$$
and therefore, we can conclude that 
$$
\sigma(p_1, p_2) = \sigma(A_1 \times \Omega_2, \Omega_1 \times A_2: A_i \in \sigmalgebra_i) = \sigma(A_1 \times A_2: A_i \in \sigmalgebra_i) = \sigma(I) = \sigmalgebra.
$$
\end{proof}

We now show that a function from the product measurable space is measurable when fixing one of its parameters. However, we first need a theorem that we will use repeatedly.


\begin{theorem_exam}{The Monotone-Class Theorem}{}Let $\mathcal{H}$ be a class of bounded functions from $\Omega \rightarrow \mathbb{R}$ such that 
\begin{enumerate}
\item $\mathcal{H}$ is a vector space over $\mathbb{R}$
\item $1_{\Omega} \in \mathcal{H}$
\item If $f_n \in \mathcal{H}$ satisfies that $0 \leq f_n \leq C < \infty$ and $f_n \uparrow$, then $\lim f_n \in \mathcal{H}$.
\end{enumerate}
Then, if $1_{A} \in \mathcal{H}$ for all sets $A$ in a $\pi-$system I, then $\mathcal{H}$ contains every bounded $\sigma(I)-$measurable function on $\Omega.$ 
\end{theorem_exam}

\begin{remark} Condition 2 states that the constant function is in $\mathcal{H}.$ Condition 3 is known as closed under bounded convergence.
\end{remark}

Before we can prove the monotone-class theorem, we need a lemma.
\begin{lemma} Let $\mathcal{H}$ be the class of bounded functions described in the montone-class theorem. Define the collection 
$$
\mathcal{L} = \{A \subset \Omega: 1_A \in \mathcal{H}\}
$$
Then, $\mathcal{L}$ is a $\lambda-$system.
\end{lemma}
\begin{proof} $\Omega \in \mathcal{L}$ by assumption of $\mathcal{H}.$ Now, suppose that $A, B \in \mathcal{L}$ with $A \subset B.$ Then, 
$$
1_{B \setminus A} = 1_B - 1_A \in \mathcal{H}
$$
as $1_A, 1_B \in \mathcal{H}$ by assumption and $\mathcal{H}$ is a vector space. Finally, suppose that $A_n \in \mathcal{L}$ with $A_n \uparrow A.$ Then $1_{A_{n}} \in \mathcal{H}$ for all $n \in \mathbb{N}$. Then 
$$
1_{A_{n}} \uparrow 1_A \in \mathcal{H}
$$
due to the closed under bounded convergence property of $\mathcal{H}.$ Therefore, $1_A \in \mathcal{H}$ and we can conclude that $A \in \mathcal{L}.$ Therefore, $\mathcal{L}$ is a $\lambda-$system.
\end{proof}

We can prove the montone class theorem.

\begin{proof}(Montone-Class theorem). Let $\mathcal{L} = \{A \subset \Omega: 1_A \in \mathcal{H}\}.$ By assumption, $I$ has the property that $1_A \in \mathcal{H}$ for all sets $A \in I.$ Therefore 
$$
I \subset \mathcal{L}
$$
and by Dynkin's $\pi-\lambda$ theorem, we have that $\sigma(I) \subset \mathcal{L}.$ Now, recall that all bounded simple functions is a linear combination of indicator functions. Therefore, we denote $\delta_b(\sigma(I))$ to be the sets with simple function associated to the sets in $\sigma(I)$. We have that 
$$
\delta_b(\sigma(I)) \subset \mathcal{L}
$$
Now, if $f \in \sigma(I)$ and $0 \leq f \leq M < \infty,$ then defining $f_n = \alpha^{(n)}\circ f$, we have that $f_n \in \mathcal{H}$ as $\mathcal{H}$ is a vector space. Furthermore, $0 \leq f_n \leq M$ and hence hence $f_n \uparrow f$ implies that $f \in \mathcal{H}.$

Now, suppose that $f \in \sigma(I)$ is any measurable function $|f| \leq M < \infty.$ We can write $f = f^+ - f^-$. By our previous result, $f^+, f^- \in \mathcal{H}$ and therefore $f \in \mathcal{H}$ again due to the fact that $\mathcal{H}$ is a vector space.
\end{proof}

We now show that functions from the product sample space $\Omega$ are measurable with respect to their arguments.

\begin{proposition_exam}{Measurable functions of the measurable product space}{}Let $(\Omega, \sigmalgebra)$ be a measurable space where $\Omega$ is the product sample space and $\sigmalgebra$ is the product $\sa$. Define the function $f: (\Omega, \sigmalgebra) \rightarrow (\extendedreal, \overline{\borelsigmaalgebra})$ to be a measurable function. Then 
\begin{enumerate}
\item For all $\omega_1 \in \Omega_1$, we have that $f(\omega_1,.): (\Omega_2, \sigmalgebra_2) \rightarrow (\extendedreal, \overline{\borelsigmaalgebra})$ is measurable with respect to $\sigmalgebra_2$;
\item For all $\omega_2 \in \Omega_2$, we have that $f(.,\omega_2): (\Omega_1, \sigmalgebra_1) \rightarrow (\extendedreal, \overline{\borelsigmaalgebra})$ is measurable with respect to $\sigmalgebra_1$.
\end{enumerate}
\end{proposition_exam}

\begin{remark}That is, for 1, we can fix a point $\omega_1 \in \Omega_1.$ Then, varying $\omega_2 \in \Omega_2$, we have that the function is measurable with respect to $\sigmalgebra_2.$
\end{remark}

\begin{proof} Define the collection of functions 
$$
\mathcal{H} = \{f: \Omega \rightarrow \mathbb{R} \text{ such that f is bounded and satisfies conditions (1) and (2)} \}
$$
We can show that $\mathcal{H}$ satisfies the conditions for the monotone class theorem for the set of real-valued bounded functions. Now, recall the $\pi-$system 
$$
I = \{A_1 \times A_2: A_i \in \sigmalgebra_i\}
$$
We have that $1_A \subset \mathcal{H}$ for all sets $A \in I$ where we define 
$$
1_A = 1_{A_{1} \times A_{2}}(\omega_1, \omega_2) = 1_{A_{1}}(\omega_1)1_{A_{2}}(\omega_2)
$$
Therefore, by the monotone class theorem, we have that $\mathcal{H}$ contains every bounded $\sigma(I)-$measurable function. Now, recal lthat by definition, the product $\sa = \sigma(I) = \sigma(p_1, p_2)$ where $p_i$ is the i-th projection map, which is measurable with respect to $\sa.$ Therefore, by (*)
$$
\sigma(I) = \{\text{bounded and } \sigmalgebra-\text{measurable functions}\} \subset \mathcal{H}
$$
However, by definition of $\mathcal{H}$ satisfying the conditions (1) and (2), we can conclude that all functions in $\mathcal{H}$ are bounded and satisfy conditions (1) and (2).
\end{proof}

It is worth noting that our construction of the product $\sa$ works for a countable product of measure spaces but problematic if we had an uncountable product of measure spaces as $\sa$ are not necessarily closed by uncountable intersections, which was an operation we used frequently in our construction of the product $\sa.$

\subsection{Fubini's Theorem}
We could define the product measure by taking rectangles $A_1 \times A_2$ where $A_1 \in \sigmalgebra_1, A_2 \in \sigmalgebra_2$ and using Caratheodory's theorem to extend the measure $\mu(A_1 \times A_2) = \mu_1(A_1)\mu_2(A_2).$ However, Fubini's theorem lets us define the product measure in a different manner.

Recall that we said that $f(\omega_1,.)$ is measurable with respect to $\sigmalgebra_2$ for all $\omega_1 \in \Omega_1.$ That means we can integrate $f(\omega_1,.)$ with respect to $\mu_2$. Likewise, as $f(\cdot, \omega_2)$ is measurable with respect to $\sigmalgebra_1,$ we can integrate $f(\cdot, \omega_2)$ with respect to $\mu_1.$

\begin{definition_exam}{Integral functions}{}Assume that $\mu_i$ are finite measures on $(\Omega_i, \sigmalgebra_i)$ for i=1, 2. Define the function $f: (\Omega,\sigmalgebra) \rightarrow (\mathbb{R}, \borelsigmaalgebra)$ to be bounded and measurable. Then $f(\omega_1,.)$ and $f(.,\omega_2)$ are bounded and measurable. We define the integral functions
$$
\begin{cases}
I_1(\omega_1;f) = \int_{\Omega_{2}}f(\omega_1,.)d\mu_2\\\\
I_2(\omega_2;f) = \int_{\Omega_{1}}f(.,\omega_2)d\mu_1
\end{cases}
$$
which are well defined functions from $\Omega_i \rightarrow \mathbb{R}.$ That is, $I_1: \Omega_1 \rightarrow \mathbb{R}$ and $I_2: \Omega_2 \rightarrow \mathbb{R}.$
\end{definition_exam}

\begin{remark}As the function f is bounded and measurable, this means that its integral is well-defined.
\end{remark}

We now have integral functions $I_i: \Omega_i \rightarrow \mathbb{R}.$ We now want to again integrate these integrals, but before that, we need to show that $I_1$ is measurable with respect to $\sigmalgebra_1$ and $I_2$ is measurable with respect to $\sigmalgebra_2.$

\begin{proposition_exam}{First form of Fubini's theorem}{}Define the measure spaces $(\Omega_i, \sigmalgebra_i, \mu_i)$ for $i = 1, 2.$ Define the function $f: (\Omega, \sigmalgebra) \rightarrow (\mathbb{R}, \borelsigmaalgebra)$ to be bounded and measurable. We then have the following.
\begin{enumerate}
\item $I_1(\cdot;f): (\Omega_1, \sigmalgebra_1) \rightarrow (\real, \borelsigmaalgebra)$ is bounded and measurable with respect to $\sigmalgebra_1$.
\item $I_2(\cdot;f): (\Omega_2, \sigmalgebra_2) \rightarrow (\real, \borelsigmaalgebra)$ is bounded and measurable with respect to $\sigmalgebra_2$. 
\item We have Fubini's theorem 
$$
\int_{\Omega_{1}}I_1(\cdot;f)d\mu_1 = \int_{\Omega_{2}}I_2(\cdot;f)d\mu_2.
$$
\end{enumerate}
\end{proposition_exam}

\begin{proof} First, we define the class of all bounded functions
$$\mathcal{H} = \{f: \Omega \rightarrow \mathbb{R} \text{ such that f is bounded and satisfy conditions 1, 2, 3}\}$$ We can show that $\mathcal{H}$ satisfy all the requirements for the monotone class theorem from before. Furthermore, $\mathcal{H}$ contains $1_A$ for every set $A \in I = \{A_1 \times A_2: A_i \in \sigmalgebra\}$ where we define the indicator function
$$
1_A(\omega_1, \omega_2) = 1_{A_{1}}(\omega_1)1_{A_{2}}(\omega_2)
$$
Now, recall that $\sigma(I)$ is the set of all $\sigma-$measurable function. Then, by the monotone class theorem
$$
\mathcal{H} \supset \text{ every bounded }\sigmalgebra-\text{measurable function}
$$
By construction, 
$$
\mathcal{H} \subset \text{ every bounded }\sigmalgebra-\text{measurable function}
$$
Therefore, we can conclude that for any function in the class $f \in \mathcal{H},$ it satisfies conditions 1, 2, 3.
\end{proof}
\begin{remark}Note that we now further integrate $I_1$ (which itself is an integral with respect to $\mu_2$) with respect to $\mu_1.$
\end{remark}

We now can define the product measure using Fubini's theorem.

\begin{definition_exam}{Product Measure}{}Let $(\Omega_i, \sigmalgebra_i, \mu_i)$ be measure spaces and $\mu_i$ is finite for $i = 1, 2$. We define the \textbf{product measure} $\Omega: \sigmalgebra \rightarrow \positivereal$ as 
$$
\mu(A) = \int_{\Omega_{1}}I_1(\cdot,1_A)d\mu_1 = \int_{\Omega_{2}}I_2(\cdot,1_A)d\mu_2
$$
for $A \in \sigmalgebra.$
\end{definition_exam}

\begin{remark}More explicitly, $$
\begin{cases}
\int_{\Omega_{1}}I_1(\cdot,1_A)d\mu_1 = \int_{\Omega_{1}} \bigg(\int_{\Omega_{2}}1_{A}(\omega_1, \cdot)d\mu_2 \bigg) d\mu_1\\\\
\int_{\Omega_{2}}I_2(1_A, \cdot)d\mu_2 = \int_{\Omega_{2}} \bigg(\int_{\Omega_{1}}1_{A}(\cdot,  \omega_2, )d\mu_1 \bigg) d\mu_2
\end{cases}
$$
\end{remark}


\begin{proposition_exam}{Uniqueness of the product measure}{}Let $\mu$ be the product measure defined above. We then have the following claims.

\begin{enumerate}
\item $\mu$ is a measure on the measure product space $(\Omega, \sigmalgebra)$.
\item $\mu(A_1 \times A_2) = \mu_1(A_1)\mu_2(A_2)$ for all $A_i \in \sigmalgebra_i$.
\item If $\nu$ is another measure on $(\Omega, \sigmalgebra)$ with 
$$
\nu(A_1 \times A_2) = \mu(A_1 \times A_2) = \mu_1(A_1)\mu_2(A_2)
$$
for all $A_i \in \sigmalgebra_i$. Then $\mu = \nu.$
\end{enumerate}

That is, the product measure $\mu$ is a unique extension of $\mu_1, \mu_2.$
\end{proposition_exam}

\begin{proof} For (1), recall that 
$$
\mu(A) = \int_{\Omega_{1}}I_1(\cdot; 1_A)d\mu_1 = \int_{\Omega_{1}}\int_{\Omega_2}1_A(\omega_1, \omega_2)d\mu_2d\mu_1 
$$
Let $A = \emptyset.$ Then 
$$
\mu(\emptyset) = \int_{\Omega_{1}}I_1(\cdot; 1_{\emptyset})d\mu_1 = \int_{\Omega_{1}}\int_{\Omega_2}1_{\emptyset}(\omega_1, \omega_2)d\mu_2d\mu_1  = \int_{\Omega_{1}} 0 d\mu_1 = 0
$$
Therefore $\mu(\emptyset) = 0.$ Now, suppose that $A_1, A_2, ... \in \sigmalgebra$ are disjoint sets. Then, note that for a fixed $\omega_1 \in \Omega_1$ we have that 
$$
I_1(\omega_1;1_{\cup A_k}) = \int_{\Omega_2}1_{\cup A_k}(\omega_1, \omega_2)d\mu_2 = \int_{\Omega_2}\sum_{k=1}^{\infty}1_{A_{k}}(\omega_1, \omega_2)d\mu_2 = \int_{\Omega_2}\lim_{n \rightarrow \infty}\sum_{k=1}^{n}1_{A_{k}}(\omega_1, \omega_2)d\mu_2
$$
and then by monotone convergence theorem 
\begin{equation}
= \lim_{n \rightarrow \infty}\sum_{k=1}^{n}\int_{\Omega_2}1_{A_{k}}(\omega_1, \omega_2)d\mu_2 = \sum_{k=1}^{\infty}I_1(\omega_1; 1_{A_{k}})
\tag{*}
\end{equation}

Therefore, we have that 
$$
\mu(\cup_kA_k) = \int_{\Omega_1}I_1(\omega_1; 1_{\cup_{A_{k}}})d\mu_1 = \int_{\Omega_{1}}\sum_{k=1}^{\infty}I_1(\omega_1; 1_{A_{k}})d\mu_1 = \int_{\Omega_{1}}\lim_{n \rightarrow \infty}\sum_{k=1}^{n}\int_{\Omega_2}1_{A_{k}}(\omega_1, \omega_2)d\mu_2 d\mu_1
$$
$$
= \lim_{n \rightarrow \infty}\sum_{k=1}^{n}\int_{\Omega_{1}}\int_{\Omega_2}1_{A_{k}}(\omega_1, \omega_2)d\mu_2 d\mu_1
$$
$$
= \sum_{k=1}^{\infty}\int_{\Omega_1}I_1(\omega_1; 1_{A_{k}})d\mu_1 = \sum_{k=1}^{\infty}\mu(A_k)
$$
by definition.

Now for claim 2, recall that $1_{A_{1}\times A_{2}}(\omega_1, \omega_2) = 1_{A_{1}}(\omega_1)1_{A_{2}}(\omega_2).$ Then, we have that 
$$
I_1(\omega_1;1_{\cup A}) = \int_{\Omega_{2}}1_A(\omega_1, \omega_2)d\mu_2 = 1_{A_{1}}(\omega_1)\int_{\Omega_{2}}1_{A_{2}}(\omega_2)d\mu_2
$$

Therefore, we have that 
$$
\mu(A) = \mu(A_1 \times A_2) = \int_{\Omega_{1}}I_1(\omega_1; A_1 \times A_2)d\mu_1 = \int_{\Omega_{1}}1_{A_{1}}(\omega_1)\int_{\Omega_{2}}1_{A_{2}}(\omega_2)d\mu_2d\mu_1
$$
$$
= \int_{\Omega_{1}}1_{A_{1}}(\omega_1)d\mu_1\int_{\Omega_{2}}1_{A_{2}}(\omega_2)d\mu_2 = \mu_1(A_1)\mu_2(A_2)
$$

For (3), first recall that $\sigmalgebra = \sigma(I) = \sigma(A_1 \times A_2: A_i \in \sigmalgebra_i)$. Furthermore, recall that if two probability measures $\mu, \nu$ agree on a $\pi-$system $I,$ then they agree on the $\sa$ generated by that $\pi-$system $\sigma(I).$ Therefore, as I was shown to be a $\pi-$system where $\nu(A_1 \times A_2) = \mu(A_1 \times A_2)$ agree for all $A_1 \times A_2 \in I,$ then they also agree on $\sigma(I) = \sigmalgebra.$
\end{proof}

We now a product measure using the Lebesgue measure.

\begin{definition_exam}{Lebesgue's Measure on $\mathbb{R}^2$}{} There exists a unique measure $\lambda_2$ on $(\real^2, \borelsigmaalgebra^2)$ such that for any intervals $I_j = (a_j,b_j]$, we have that 
$$
\lambda_2(I_1 \times I_2) = \lambda(I_1)\lambda(I_2) = (b_1 - a_1)(b_2 - a_2).
$$
Here, $\borelsigmaalgebra^2 = \sigma(\borelsigmaalgebra \times \borelsigmaalgebra) = \borelsigmaalgebra(\mathbb{R}^2).$
\end{definition_exam}

We now state two important theorems. Here, we relax the condition for f to be bounded to now being non-negative or integrable.

\begin{theorem_exam}{Tonelli's Theorem}{} Let $(\Omega_j, \sigmalgebra_j, \mu_j)$ be measure spaces for j=1,2 where $\Omega_j$ is $\sigma-$finite with respect to $\mu_j.$ Define $\mu$ to be the product measure on the product measure space $(\Omega, \sigmalgebra)$. Take a non-negative measurable function $f: \Omega \rightarrow \positiveextendedreal$. Then

\begin{enumerate}
\item $I_1(.;f): (\Omega_1, \sigmalgebra_1) \rightarrow (\real, \borelsigmaalgebra)$ is bounded and measurable with respect to $\sigmalgebra_1$.
\item $I_2(.;f): (\Omega_2, \sigmalgebra_2) \rightarrow (\real, \borelsigmaalgebra)$ is bounded and measurable with respect to $\sigmalgebra_2$. 
\item $$
\int_{\Omega_{1}}I_1(.;f)d\mu_1 = \int fd\mu = \int_{\Omega_{2}}I_2(.;f)d\mu_2.
$$

\end{enumerate}
\end{theorem_exam}



\begin{theorem_exam}{Fubini's Theorem}{} Let $(\Omega_j, \sigmalgebra_j, \mu_j)$ be measure spaces for j=1,2 where $\Omega_j$ is $\sigma-$finite with respect to $\mu_j.$ Define $\mu$ to be the product measure on the product measure space $(\Omega, \sigmalgebra)$. Take an integrable and measurable function $f: \Omega \rightarrow \real$ where $f \in L^{1}(\Omega)$. Then

\begin{enumerate}
\item $I_1(.;f): (\Omega_1, \sigmalgebra_1) \rightarrow (\real, \borelsigmaalgebra) \in L^{1}(\Omega_1).$
\item $I_2(.;f): (\Omega_2, \sigmalgebra_2) \rightarrow (\real, \borelsigmaalgebra) \in L^{1}(\Omega_2).$ 
\item $$
\int_{\Omega_{1}}I_1(.;f)d\mu_1 = \int fd\mu = \int_{\Omega_{2}}I_2(.;f)d\mu_2.
$$

\end{enumerate}
\end{theorem_exam}

\subsection{Product Measure on n-dimensional space}

We can actually what we have seen to if we had $(\Omega_i, \sigmalgebra_i, \mu_i)$ for i = 1,...,n that are $\sigma-$finite measure spaces. We can inductively define a product $\sa$ by $\sigmalgebra = \sigmalgebra_1 \times ... \times \sigmalgebra_n$ and a product measure by $\mu = \mu_1 \times ... \times \mu_n.$ 

\begin{proposition_exam}{Tonelli's Theorem on n-dimensional space}{}Define the product space $(\Omega, \sigmalgebra)$ of n measurable spaces $(\Omega_i, \sigmalgebra_i, \mu_i)$. Then, let $f:(\Omega, \sigmalgebra) \rightarrow (\positivereal, \borelsigmaalgebra)$ be a nonnegative and measurable function. Then, for any permutation $\pi \in S_n$
$$
\int fd\mu = \int_{\Omega_{\pi(1)}}...\int_{\Omega_{\pi(n)}}fd\mu_{\pi(1)}...d\mu_{\pi(n)}.
$$
\end{proposition_exam}

\begin{remark}The same holds for Fubini's theorem if $f \in L^1(\Omega, \sigmalgebra, \mu).$
\end{remark}

\begin{proposition_exam}{Lebesgue measure on $\mathbb{R}^n$}{}There exists a unique Lebesgue measure $\lambda_n$ on $(\mathbb{R}^n, \borelsigmaalgebra^n)$ such that for any intervals $I_j = (a_j,b_j]$ 
$$
\lambda_n(I_1 \times ... \times I_n) = \prod_{j=1}^{n}\lambda(I_j) = \prod_{j=1}^{n}\bigg(b_j - aj \bigg)
$$
\end{proposition_exam}

\subsection{Random Vectors}
We now want to work in dimensions of size n.

\begin{definition_exam}{Random Vector}{}A measurable function $\textbf{X} = (X_1,...,X_n): (\Omega, \sigmalgebra) \rightarrow (\mathbb{R}^n, \borelsigmaalgebra^n)$ is called a \textbf{random vector.}
\end{definition_exam}

\begin{claim}\textbf{X} is a random vector if and only if $X_i$ is a random variable for i = 1,...,n.
\end{claim}

\begin{definition_exam}{Probability measure induced by random vector}{}Define the product measure space $(\Omega, \sigmalgebra, \prob).$ Then, the random vector $\textbf{X} = (X_1,...,X_n)$ induces a probability measure on $(\extendedreal^n, \overline{\borelsigmaalgebra}^n)$ by 
$$
\mu_{\textbf{X}}(B) = \prob(\textbf{X} \in B)
$$
for all Borel set $B \in \overline{\borelsigmaalgebra}^n.$ $\mu_{\textbf{X}}$ is called the probability measure induced by the random vector X.
\end{definition_exam}


\begin{definition_exam}{Density function of random vector}{}Define the product measure space $(\Omega, \sigmalgebra, \prob).$ Define the random vector $\textbf{X} = (X_1,...,X_n)$ and its induced probability measure $\mu_{\textbf{X}}.$ Then, if $\mu_{\textbf{X}}$ is absolutely continuous with respect to the Lebesgue measure on $\mathbb{R}^n$ $\lambda_n$ if $\mu_{\textbf{X}}(\mathbb{R}^n) = 1$ and there exists a non-negative and measurable function $f: \mathbb{R}^n \rightarrow [0,\infty]$  such that 

$$
\mu_{\textbf{X}} (B) = \int_{B} f d \lambda_{n}
$$

for all Borel sets $B \in \borelsigmaalgebra^n$. Then, f is called the density of $\mu_{\textbf{X}}.$
\end{definition_exam}

\begin{claim}If $\textbf{X} = (X_1,...,X_n)$ has a density, then so does each $X_i$ for i = 1,...,n. Furthermore, 
$$
f_{X_{i}}(x) = \int ... \int f(\textbf{x})d\lambda (x_1)... d\lambda (x_{i-1})d\lambda (x_{i+1})...d\lambda (x_{n}).
$$
\end{claim}


\begin{claim}If the random variables $X_1,...,X_n$ are independent and if each $X_i$ has density $f_i$, then $\textbf{X} = (X_1,...,X_n)$ has a density 
$$
f(x_1,...,x_n) = \prod_{i=1}^{n}f_i(x_i).
$$
\end{claim}

\subsection{Change of variables for Random Vectors}

We now have a multi-dimensional analogue of the change of variables theorem.

\begin{theorem_exam}{Change of variables formula for non-negative randon vector}{}Let $\textbf{X}$ be a random vector defined on a probability $(\Omega, \sigmalgebra, \prob)$ and let $\mu_{\textbf{X}}$ be its induced measure on $(\extendedreal^+, \overline{\borelsigmaalgebra}^n)$. Suppose that $h: (\extendedreal, \overline{\borelsigmaalgebra}^n) \rightarrow (\overline{\positivereal}, \overline{\borelsigmaalgebra}^+)$ is measurable and let $\textbf{Y} = h(\textbf{X}).$ Then \textbf{Y} is a non-negative random variable and 
$$
\int \textbf{Y}d\prob = E(\textbf{Y}) = E(h(\textbf{X})) = \int_{\mathbb{R}^n}hd\mu_{\textbf{X}}.
$$
\end{theorem_exam}

\begin{theorem_exam}{Change of variables formula for measurable randon vector}{}Let $\textbf{X}$ be a random vector defined on a probability $(\Omega, \sigmalgebra, \prob)$ and let $\mu_{\textbf{X}}$ be its induced measure on $(\extendedreal^+, \overline{\borelsigmaalgebra}^n)$. Suppose that $h: (\extendedreal, \overline{\borelsigmaalgebra}^n) \rightarrow (\overline{\real}, \overline{\borelsigmaalgebra})$ is measurable and let $\textbf{Y} = h(\textbf{X}).$ Then \textbf{Y} is a random variable. 

\begin{enumerate}
\item $E(\textbf{Y}) = \int \textbf{Y}d\prob$ is defined if and only if $\int_{\mathbb{R}^n}hd\mu_{\textbf{X}}$ is defined and then $E(\textbf{Y}) = \int_{\mathbb{R}^n}hd\mu_{\textbf{X}}.$
\item $\textbf{Y} = h(\textbf{X}) \in L^1(\Omega, \sigmalgebra, \prob)$ if and only if $h \in L^1(\overline{\real}^n, \overline{\borelsigmaalgebra}^n, \mu_{\textbf{X}}$. Then
$$
\int \textbf{Y}d\prob = E(\textbf{Y}) = E(h(\textbf{X})) = \int_{\mathbb{R}^n}hd\mu_{\textbf{X}}.
$$
\end{enumerate}
\end{theorem_exam}

\begin{theorem}If the random vector \textbf{X} has a density f, then 
$$
E(\textbf{Y}) = E(h(\textbf{X})) = \int_{\mathbb{R}^n}h \circ fd\lambda_n
$$
with the LHS defined if and only if the RHS is. Furthermore, if $h \circ f$ is Riemann integrable, we can compute $E(\textbf{Y})$ using iterated \textbf{Riemann integrals}
$$
\int_{\mathbb{R}^n}h \circ fd\lambda_n = \int_{\real}...\int_{\real}h\circ fd\lambda(x_1)...d\lambda(x_n).
$$
\end{theorem}


\lecture{11}{Conditional Expectation}
\section{Conditional Expectation}
\section{Conditional Expectation}
\subsection{Introduction}

\begin{definition_exam}{Conditional Expectation}{}Let $(\Omega, \sigmalgebra, P)$ be a probabiliy space and $X: \Omega \rightarrow \mathbb{R}$ be a random variable. Let $X \in L^1(\Omega, \sigmalgebra, P).$ Moreover, let $\sigmalgebra_0 \subseteq \sigmalgebra$ be a $\sa.$ 

Then, the random variable $X_0$ is called the conditional expectation of X given $\sigmalgebra_0$ if 
\begin{enumerate}
\item $X_0$ is measurable with respect to the $\sa$ $\sigmalgebra_0$;
\item We have that $\int_A X_0dP = \int_A XdP$ for all $A \in \sigmalgebra_0.$
\end{enumerate}

If both conditions are satisfied, we write 
$$
E[X|\sigmalgebra_0] \coloneqq X_0
$$
and say that $X_0$ is a \textbf{version of} $E[X|\sigmalgebra_0].$
\end{definition_exam}

We can show that the conditional expectation exists and is unique. First, we require a lemma.
\begin{lemma}Let $X_0$ be a random variable that satisfies the 2 conditions to be a version of the conditional expectation $E[X|\sigmalgebra_0].$ Then, $X_0 \in L^1(\Omega, \sigmalgebra, P).$
\end{lemma}

\begin{proposition_exam}{Existence and uniqueness of conditional expectation}{}For every random variable $X \in L^1(\Omega, \sigmalgebra, P)$ and every $\sa$ $\sigmalgebra_0 \subseteq \sigmalgebra,$ the conditional expectation $E[X|\sigmalgebra_0]$ exists and is unique.
\end{proposition_exam}

\lecture{12}{Conditional Expectation}
\section{Conditional Expectation}
\subsection{Properties of conditional expectation}

\begin{proposition_exam}{Properties of conditional expectation}{} Define the probability space $(\Omega, \sigmalgebra, P).$ Define two random variables X and Y. Assume that $X, Y \in L^1(\Omega, \sigmalgebra, P).$ Then we have the following.
\begin{enumerate}
\item $E(aX + bY|\sigmalgebra) = aE(X|\sigmalgebra) + E(Y|\sigmalgebra)$;
\item If $X \leq Y$ then $E(X|\sigmalgebra) \leq E(Y|\sigmalgebra);$
\item If $X_n \geq 0$ and $X_n \uparrow X$ with $E[X] < \infty$, then 
$$
E[X_n|\sigmalgebra] \uparrow E[X|\sigmalgebra].
$$
\end{enumerate}
\end{proposition_exam}

\begin{theorem}Let $\phi$ be a convex function and let $E[|X|], E[|\phi(X)|] < \infty$. Then, we have that 
$$
\phi(E[X|\sigmalgebra]) \leq E[\phi(X)|\sigmalgebra].
$$
\end{theorem}

\begin{theorem}If $X \in \sigmalgebra$ and $E[|Y|], E[|XY|] < \infty$ then 
$$
E[XY|\sigmalgebra] = XE[Y|\sigmalgebra].
$$
\end{theorem}


\lecture{13}{Cramr-Rao Lower Bound}
\section{Exponential Families}
\section{Exponential Families}
\textit{We revisit ideas on the Cramr-Rao lower bound and examine the assumptions behind them. We additionally revisit ideas from previous courses.}
\subsection{Moment Generating Functions}

Let X be a random variable. Recall that the k-th moment of X is given by $E[X^k].$

\begin{definition_exam}{Moment Generating Function}{}Let X be a random variable with CDF $F_X.$ The Moment Generating Function (MGF) $M_X$ of X is given by 
$$
M_X(t) = E[e^{tX}]
$$
provided that the expectation exists for t in a neighbourhood of 0.
\end{definition_exam}

Hence, if X is a continuous random variable, we can write 
$$
M_X(t) = \int_{supp(X)}e^{tx}f_X(x)dx
$$
where $supp(X)$ is the support of the random variable X.

\begin{theorem_exam}{Moments of random variable}{}If the random variable X has the MGF $M_X$, then 
$$
E[X^n] = \frac{d^n}{dt^n}M_X(t)|_{t = 0}.
$$
That is, the n-th moment of X is given by the n-th derivative of the MGF of X evaluated at t = 0.
\end{theorem_exam}
\begin{proof} We assume that we can interchange differentiation with respect to t and the integral. 
$$
\frac{d}{dt}M_X(t) = \frac{d}{dt}\int_{-\infty}^{\infty}e^{tx}f_X(x)dx
$$
$$
= \int_{-\infty}^{\infty}\frac{d}{dt}e^{tx}f_X(x)dx
$$
$$
= \int_{-\infty}^{\infty}\bigg(xe^{tx} \bigg)f_X(x)dx
$$
$$
= E[Xe^{tX}].
$$
Then, evaluating at t = 0
$$
\frac{d}{dt}M_X(t)|_{t = 0} = E[Xe^{0X}] = E[X].
$$
We can follow a similar argument for the n-th moment.
\end{proof}

\begin{definition_exam}{Cumulant Generating Function}{}Let X be a random variable with MGF $M_X.$ Then, the cumulant generating function $K_X(t)$ of X is given by 
$$
K_X(t) = log(M_X(t)) = logE[e^{tX}].
$$
\end{definition_exam}


\subsection{Sufficient Statistics}
\begin{definition}(Statistic). A statistic $T(\utilde{X})$ is a function of the data vector $\utilde{X}.$
\end{definition}

\begin{definition_exam}{Sufficient Statistic}{}A statistic $T(\utilde{X})$ is a \textbf{sufficient statistic} for $\theta$ if the conditional distribution of the sample $\utilde{X}$ given the value $T(\utilde{X})$ does not depend on $\theta.$
\end{definition_exam}

\begin{theorem}(Sufficiency principle). If $T(\utilde{X})$ is a sufficient statistic for the parameter $\theta$, then any inference on $\theta$ should depend on the sample $\utilde{X}$ only through the sufficient statistic $T(\utilde{X}).$
\end{theorem}

We can say that 2 samples $\utilde{x}, \tilde{y}$ are equal if $T(\utilde{x}) = T(\tilde{y})$ even if $\utilde{x} \neq \tilde{y}.$

We can view that the function $T(.)$ is a partition of the sample space $\mathcal{X}$ whereby 
$$
\mathcal{T} = \{t: t = T(\utilde{x}) \text{ for a } \utilde{x} \in \mathcal{X}\}.
$$
Hence, we can partition the sample space 
$$
\mathcal{X} = \bigcup_{t \in \mathcal{T}}A_t
$$
whereby $A_t = \{\utilde{x} \in \mathcal{X}: T(\utilde{x}) = t\}$.

\begin{theorem}If $p(\utilde{x}|\theta)$ is the joint PMF/PDF of $\utilde{X}$ and $q(t|\theta)$ is the PMF/PDF of $T(\utilde{X})$, then $T(\utilde{X})$ is a sufficient statistic for $\theta$ if for every $x \in \mathcal{X}$ the ratio $\frac{p(\utilde{x}|\theta)}{q(T(\utilde{x})|\theta)}$ is constant as a function of $\theta.$
\end{theorem}


\begin{theorem_exam}{Factorisation Theorem}{}Let $f(\utilde{x}|\theta)$ be the joint PMF/PDF of the sample. Then, $T(\utilde{X})$ is a sufficient statistic for $\theta$ if and only if there exists functions $g(t|\theta)$ and $h(\utilde{x})$ such that for all sample points $x \in \mathcal{X}$ and all parameter points $\theta \in \Theta$, 
$$
f(\utilde{x}|\theta) = g(T(\utilde{x})|\theta)h(\utilde{x}).
$$
\end{theorem_exam}

\subsection{Introduction}

Suppose that $\{p_{\theta}(.): \theta \in \Theta\}$ is a 1-parameter family of densities with respect to a $\sigma-$finite measure $\nu$ on $\mathbb{R}^d,$ where d is the dimension of the data.

\begin{lemma}Given a density $p_{\theta}$ and measure $\nu$, we can define a probability measure 
$$
\prob_{\theta}(B) = \int_{B}p_{\theta}(\utilde{x})d\nu(\utilde{x})
$$
where B is a Borel set and $\nu$ is either the Lebesgue or counting measure.
\end{lemma}

\begin{definition_exam}{Score function}{}Let $p_{\theta}(\utilde{x})$ be the density function. Then, the score function is defined as $$\ell_{\theta}^{\circ}(\utilde{x}) = \frac{\partial}{\partial \theta}log\; p_{\theta}(\utilde{x}).$$
\end{definition_exam}

\begin{definition}(Support). The support $\mathcal{X}_{\theta}$ is the smallest set whose complement has 0 probability $\prob_{\theta}(\mathcal{X}_{\theta}^c) = 0.$
\end{definition}

\begin{definition_exam}{Assumption 1: Support of distribution does not depend on the parameter}{}The support $\mathcal{X}_{\theta} = \mathcal{X}$ does not depend on the parameter $\theta$.
\end{definition_exam}

\begin{remark}This rules out the uniform $U[0,\theta]$ distribution.
\end{remark}

From assumption 1, we have that the integral of the density over the support is 1. That is 
\begin{equation}
\prob_{\theta}(\mathcal{X}) = \int...\int_{\mathcal{X}}p_{\theta}(\utilde{x})d\nu(\utilde{x}) = 1 \tag{13.1}
\end{equation}

From this, we can state our next assumption.

\begin{definition_exam}{Assumption 2: Density is twice differentiable}{}The density function $p_{\theta}$ is twice differentiable with respect to $\theta$ everywhere inside the integral sign. That is, 
$$
p_{\theta}^{'} = \frac{\partial p_{\theta}}{\partial \theta}
$$
$$
p_{\theta}^{''} = \frac{\partial^2 p_{\theta}}{\partial \theta^2}
$$
exists for all $x \in \mathcal{X}.$
\end{definition_exam}

Using assumption (1) and assumption (2), we have that the integral of the derivatives of the density function is zero
\begin{equation}
\int...\int_{\mathcal{X}}p_{\theta}^{'}(\utilde{x})d\nu(\utilde{x}) = 0 \tag{13.2}
\end{equation}

\begin{equation}
\int...\int_{\mathcal{X}}p_{\theta}^{''}(\utilde{x})d\nu(\utilde{x}) = 0 \tag{13.3}
\end{equation}

for all $\theta \in \Theta.$

Since the density function is non-negative $p_{\theta}(\utilde{x}) > 0$ for all $x \in \mathcal{X}$, this means we can divide and multiply by the density in equation (13.2).

\begin{equation}
\int ... \int_{\mathcal{X}}\frac{p_{\theta}^{'}(\utilde{x})}{p_{\theta}(\utilde{x})}p_{\theta}(\utilde{x})d\nu(\utilde{x}) = \int ... \int_{\theta}\ell_{\theta}^{\circ}(\utilde{x})p_{\theta}(\utilde{x})d\nu(\utilde{x}) = \mathbb{E}_{\theta}[\ell_{\theta}^{\circ}(\utilde{x})] = 0.
\end{equation}

This leads to an interesting result.

\begin{proposition_exam}{Expectation of the score function is zero}{}Under assumption (1) and (2), the expectation of the score function $\ell_{\theta}^{\circ}(\utilde{x})$ is 0
$$
\mathbb{E}_{\theta}[\ell_{\theta}^{\circ}(\utilde{x})] = 0.
$$
\end{proposition_exam}

We can show that the second derivative of the score function as 
$$
\ell_{\theta}^{\circ \circ} = \frac{\partial^2}{\partial \theta^2}log\;p_{\theta} = \frac{p_{\theta}^{''}}{p_{\theta}} - \ell_{\theta}^{\circ}.
$$

The variance of the score function is therefore given by 
$$
Var_{\theta}[\ell_{\theta}^{\circ}(\utilde{x})] = - \int ... \int_{\mathcal{X}}\ell_{\theta}^{\circ \circ}p_{\theta}d\nu(\utilde{x}).
$$

\begin{definition}(Unbiased estimator). The function $\hat{\theta}(\utilde{x})$ is an unbiased estimator of the parameter $\theta$ if 
$$
E_{\theta}[\hat{\theta}(\utilde{x})] = \int ... \int_{\mathcal{X}}\hat{\theta}(\utilde{x})p_{\theta}(\utilde{x})d\nu(\utilde{x}) = \theta
$$
for all $\theta \in \Theta.$
\end{definition}

We can take the derivative of the expression for an unbiased estimator to derive our next assumption.

\begin{definition_exam}{Assumption 3: Differentiate expression for unbiased estimators inside integral sign}{}Define the function $\hat{\theta}(\utilde{x})$ to be an unbiased estimator of the parameter $\theta$ denoted by 
$$
E_{\theta}[\hat{\theta}(\utilde{x})] = \int ... \int_{\mathcal{X}}\hat{\theta}(\utilde{x})p_{\theta}(\utilde{x})d\nu(\utilde{x}) = \theta
$$
We then assume that we are able to differentiate inside this expression to get 
$$
\int ... \int_{\mathcal{X}}\hat{\theta}(\utilde{x})p_{\theta}^{'}(\utilde{x})d\nu(\utilde{x}) = 1
$$
\end{definition_exam}

Regarding assumptions 2 and 3, we note that this is in fact an application of Leibnitz's rule.
\begin{proposition_exam}{Leibnitz's Rule}{}Suppose that $f(x,\theta)$ is a function with parameter $\theta.$ Suppose that there exists a dominating function $g \in L^1.$ Then 
$$
\frac{d}{d\theta}\int_a^b f(x,\theta)dx = \int_a^b \frac{\partial}{\partial \theta}f(x,\theta)dx
$$
\end{proposition_exam}

Leibnitz's rule essentially asks when are we able to interchange limits and integration as the derivative is a form of a limit 

$$
\frac{\partial}{\partial \theta}f(x,\theta) = \lim_{\delta \rightarrow 0}\frac{f(x, \theta + \delta) - f(x, \theta)}{\delta}.
$$

In particular, we are able to do so under the assumptions of the dominating convergence theorem.

We state an important result of assumption 3.

\begin{proposition_exam}{The covariance of unbiased estimator and score function is 1}{}Assume that assumptions (1)-(3) holds. Let $\hat{\theta}(.)$ be an unbiased estimator of $\theta.$ Furthermore, let $\ell_{\theta}^{\circ}(\utilde{x})$ be the score function. Then, the covariance of the unbiased estimator and score function is 
$$
Cov_{\theta}[\hat{\theta}(\utilde{x}), \ell_{\theta}^{\circ}(\utilde{x})] = 1.
$$
\end{proposition_exam}

\begin{proof} We have that 
$$
1 = \int ... \int_{\mathcal{X}}\hat{\theta}(\utilde{x})p_{\theta}^{'}(\utilde{x})d\nu(\utilde{x})
$$
$$
= \int ... \int_{\mathcal{X}}\hat{\theta}(\utilde{x})\ell_{\theta}^{\circ}(\utilde{x})p_{\theta}(\utilde{x})d\nu(\utilde{x})
$$
due to the fact that the expectation of the score function is zero and by the definition of covariance
$$
= Cov_{\theta}[\hat{\theta}(\utilde{x}), \ell_{\theta}^{\circ}(\utilde{x})].
$$
\end{proof}

Hence, if we have an unbiased estimator, its covariance with the score function is 1. We can use this result to determine the variance of our estimator.

\begin{definition}(Correlation Inequality). The correlation inequality between an unbiased estimator $\hat{\theta}$ and score function $\ell_{\theta}^{\circ}$ is 
$$
Cov_{\theta}[\hat{\theta}(\utilde{x}), \ell_{\theta}^{\circ}(\utilde{x})]^2 \leq Var_{\theta}(\hat{\theta}(\utilde{x})) Var_{\theta}(\ell_{\theta}^{\circ}(\utilde{x}))
$$
with equality if and only if $\hat{\theta}(\utilde{x})$ and $\ell_{\theta}^{\circ}(\utilde{x})$ are lienarly related so that 
$$
\ell_{\theta}^{\circ}(\utilde{x}) = a_{\theta} + b_{\theta}\hat{\theta}(\utilde{x}).
$$
\end{definition}

\begin{definition_exam}{Cramer-Rao Lower Bound}{}Suppose that $\hat{\theta}$ is an unbiased estimator of $\theta.$ Furthermore, let $\ell_{\theta}^{\circ}(\utilde{x})$ be the score function. Then, the Cramer-Rao lower bound for the estimator $\hat{\theta}$ is 
$$
Var_{\theta}(\hat{\theta}(\utilde{x})) \geq \frac{1}{Var_{\theta}(\ell_{\theta}^{\circ}(\utilde{x}))}.
$$
\end{definition_exam}

An estimator is minimum variance if the score function is a linear function of the estimator.

\begin{proposition_exam}{Condition for minimum variance estimator}{}Suppose that $\hat{\theta}$ is an unbiased estimator of $\theta.$ Furthermore, let $\ell_{\theta}^{\circ}(\utilde{x})$ be the score function. Then, the estimator $\hat{\theta}$ attains the Cramer-Rao lower bound if the score function is of the form 
$$
\ell_{\theta}^{\circ}(\utilde{x}) = \frac{\hat{\theta}(\utilde{x}) - \theta}{Var_{\theta}(\hat{\theta}(\utilde{x}))}.
$$
\end{proposition_exam}


\lecture{14}{Exponential Families}
\section{Exponential Families}
\subsection{Exponential Family}
The exponential family is a widely unified family of distributions. There are many famous distributions which are examples of the exponential family when we restrict the space to the real line $\mathbb{R}.$ We can see that there are properties underlying all these different distributions when we view it from an exponential family point of view.


The 2 important elements required to define an exponential family is a $\sigma-$finite measure and sufficient statistic. We first recall the definition of the exponential family.


\begin{definition_exam}{Exponential family density}{}

We define the probability density function of the exponential family 
$$
q_{\utilde{\eta}}(\utilde{x}) = e^{\utilde{\theta}(\utilde{\eta})^T\utilde{s}(\utilde{x}) - c(\utilde{\eta}) - H(\utilde{x})}
$$

for $\utilde{x} \in \mathbb{R}^n.$ In particular, we have that $\utilde{\eta} \in \mathcal{H} \subseteq \mathbb{R}^d$, $\utilde{\theta}(\utilde{\eta}): \mathbb{R}^d \rightarrow \mathbb{R}^d,$ $H: \mathbb{R}^n \rightarrow \mathbb{R},$ $c: \mathbb{R}^d \rightarrow \mathbb{R}$. Finally, $\utilde{s}(.): \mathbb{R}^n \rightarrow \mathbb{R}^d$ is the sufficient statistic.
\end{definition_exam}

However, it may be difficult to write things out in terms of $\utilde{\theta}(\utilde{\eta})$. Therefore, if $\utilde{\theta}(\utilde{\eta})$ is a homeomorphism, we can then just suppress the $\utilde{\eta}$ and work with only $\utilde{\theta}$ instead. We can then just convert things back into $\utilde{\theta}(\utilde{\eta})$ when we are done. This will be known as the natural parameterisation.

\begin{definition_exam}{Natural Parameter Space}{}Suppose that $\nu(.)$ is a $\sigma-$finite measure on $\mathbb{R}^n$ and $s: \mathbb{R}^n \rightarrow \mathbb{R}^d$ is a d-dimensional sufficient statistic. We define the \textbf{natural parameter space} as 
$$
\mathcal{N} = \{\utilde{\theta} \in \mathbb{R}^d: \int_{\mathbb{R}^n}e^{\utilde{\theta}^T \utilde{s}(\utilde{x})}d\nu(\utilde{x}) < \infty\}.
$$
\end{definition_exam}

We see that the natural parameter space depends on the measure $\nu$ and sufficient statistic $s(.).$


\begin{definition}(MGF and CGF of the sufficient statistic). Suppose that $\nu(.)$ is a $\sigma-$finite measure on $\mathbb{R}^n$ and $s: \mathbb{R}^n \rightarrow \mathbb{R}^d$ is a d-dimensional sufficient statistic. Let $\mathcal{N}$ be the natural parameter space. For $\theta \in \mathcal{N}$, we define the moment generating function of the sufficient statistic
$$
m(\utilde{\theta}) = \int_{\mathbb{R}^n}e^{\utilde{\theta}^Ts(\utilde{x})}d\nu (\utilde{x})
$$
where $m(\utilde{\theta}) < \infty$ for all $\utilde{\theta} \in \mathcal{N}.$

Furthermore, we define the cumulant generating function of the sufficient statistic as 
$$
K(\theta) = log \;m(\theta).
$$
\end{definition}

Now, we can express the exponential family in the canonical (natural) parameterisation.

\begin{definition_exam}{Exponential family density with natural parameterisation}{}

For all $\utilde{\theta} \in \mathcal{N},$ we define
$$
p_{\utilde{\theta}}(\utilde{x}) = e^{\utilde{\theta}^T\utilde{s}(\utilde{x}) - K(\utilde{\theta})}
$$
where $p_{\utilde{\theta}}$ is a probability density and $K(\utilde{\theta})$ is the cumulant generating function of the sufficient statistic. Then, any Borel set is assigned mass 
$$
\prob_{\utilde{\theta}}(B) = \int_{B}e^{\utilde{\theta}^T\utilde{s}(\utilde{x}) - K(\utilde{\theta})}d\nu(\utilde{x})
$$
where $\prob_{\utilde{\theta}}$ is the probability measure. Here, $s: \mathbb{R}^n \rightarrow \mathbb{R}^d$ is the sufficient statistic, $\utilde{x} \in \mathbb{R}^n$, $\mu \in \mathcal{N} \subseteq \mathbb{R}^d.$ The family $\{p_{\utilde{\theta}}: \utilde{\theta} \in \mathcal{N}\}$ is the family of exponential family densities with a natural parameterisation.
\end{definition_exam}

\begin{theorem}Suppose the sequence $\{a_n: n=0,1,2,...\}$ is such that for some $r > 0$
$$
\lim_{k \rightarrow \infty}\sum_{n=0}^{k}a_nx^n = \ell(x)
$$
exists and is finite for all $|x| < r$. Then r is known as the \textbf{radius of convergence}. Then, we can differentiate it term by term any number of times 
$$
\frac{d^k}{dx^k}\ell(x)|_{x = 0} = a_k \cdot k!
$$
for k = 1,2,3...
\end{theorem}


For certain exponential families, we can differentiate with respect to $\theta$ any number of times inside the integral.

\begin{theorem_exam}{Power series theorem for the MGF of the sufficient statistic}{}Let $\mathcal{N} = \{\theta: \int e^{\theta^Ts(\utilde{x})}d\nu(\utilde{x} < \infty\}$ be the natural parameter space. Let $\mathcal{N}$ be an open interval and $\theta_0 \in \mathcal{N}$ be an interior point. Then, with the moment generating function of the sufficient statistic $m(\theta) = \int_{\mathcal{X}}e^{\theta^Ts(\utilde{x})}d\nu(\utilde{x})$, we can differentiate $m(\theta)$ any number of times inside the integral sign for all $\theta \in \mathcal{N}$
$$
\frac{d^km(\theta)}{d\theta^k}|_{\theta = \theta_0} = m_k(\theta_0) = \int_{\mathbb{R}}[s(\utilde{x})]^ke^{\theta^Ts(\utilde{x})}d\nu(\utilde{x}).
$$
\end{theorem_exam}
\begin{remark}If $\mathcal{N}$ is an open interval, then every point $\theta \in \mathcal{N}$ is an interior point.
\end{remark}

This is a significant result because this means that assumption 2 and 3 for CRLB holds!

\begin{corollary} Assumptions 2 and 3 for the CRLB holds for exponential families for all $\theta \in \mathcal{N}$.
\end{corollary}

\subsection{The Mean-Value Parameter}
In this last section, we show that we can further parameterise the exponential family when its in its natural parameterisation. The reason we are interested is that for exponential families, the CRLB is only obtained when we have a mean value parameterisation. That is, the MLE is a function of the mean of the sufficient statistic and the mean of the sufficient statistic is an unbiased estimator of the mean value parameter. Therefore, we have that we can now get an unbiased estimator of the parameter and the relationship of the score function and the estimator will be such that the CRLB will be obtained.

Reall that the cumulant generating function is defined as $K(\theta) = log \;M(\theta).$

\begin{proposition_exam}{First and second derivative of the cumulant generating function}{}Let $s(\utilde{x})$ be the sufficient statistic and let $K(\theta)$ be the cumulant generating function of the sufficient statistic. Then
$$
\frac{\partial}{\partial \theta_i}K(\theta) = E_{\theta}(s_i(\utilde{x})).
$$
Furthermore, we have that 
$$
\frac{\partial^2}{\partial \theta_i \partial \theta_j}K(\theta) = Cov_{\theta}(s_i(\utilde{x}), s_j(\utilde{x})).
$$

Combining these two facts, we have that 
$$
\begin{cases}
\mathbb{E}_{\theta}(\utilde{s}(\utilde{x})) = K^{'}(\theta)\\\\
Var_{\theta}(\utilde{s}(\utilde{x})) = K^{''}(\theta)
\end{cases}
$$
\end{proposition_exam}

With this, we can now define our new parameterisation.

\begin{definition_exam}{Mean value parameter}{} We define a smooth change of parameter from $\theta$ to $\mu$ as 
$$
\theta \rightarrow \mu(\theta) = \mathbb{E}_{\theta}(\utilde{s}(\utilde{X})).
$$
\end{definition_exam}

That is, the expected value of the sufficient statistic is the mean-value parameter.


\begin{theorem_exam}{Existence of mean-value map inverse}{}The inverse map from the mean-value parameter $\mu$ to $\theta$ is well-defined if the covariance matrix of the sufficient statistic $s(\utilde{X})$ is non-singular.
\end{theorem_exam}
\begin{remark}The Jacobian of the mean-value change of parameters is the covariance matrix of the sufficient statistic.
\end{remark}

\begin{definition}(Mean-Value Parameter Space). The mean-value parameter space $\mathcal{M}$ is the image under the mean value transformation of the natural parameter space. That is 
$$
\mathcal{M} = \{\mu \in \mathbb{R}: \int_{\mathcal{X}}e^{\mu s(\utilde{x})}d\nu(\utilde{X}) < \infty\}.
$$
\end{definition}

\begin{definition}(Convex Hull). The convex hull of a set A is the smallest convex set that contains the set A.
\end{definition}

\begin{remark}The mean-value parameter space $\mathcal{M}$ is the convex hull of the support of the original base measure $\nu(.).$
\end{remark}

\begin{proposition}The support $\mathcal{X}$ of the natural parameter space $\mathcal{N}$ agrees with the support of the mean-value parameter space $\mathcal{M}.$
\end{proposition}

We recall a result from vector calculus which we will need to write out the mean-value parameterisation of the exponential family.
\begin{definition}Let $\alpha: I_1 \rightarrow \mathbb{R}$ and $\beta: I_2 \rightarrow \mathbb{R}$ be parameterised smooth curves. Then, $\beta$ is a reparameterisation of $\alpha$ if there exists a smooth function $\psi$ such that $\psi: I_2 \rightarrow I_1$ with a smooth inverse 
$$
\beta: \alpha \circ \psi.
$$
\end{definition}

\begin{definition_exam}{Density of mean value parameterisation}{}The family of densities for the exponential family under the mean value parameterisation $\{q_{\mu}(.): \mu \in \mathcal{M}\}$ is given by 
$$
q_{\mu}(\utilde{x}) = p_{\theta}(\mu)(\utilde{x}) = e^{\theta(\mu)s(\utilde{x}) - K(\theta(\mu))}.
$$
\end{definition_exam}

\begin{claim} The support of the mean-value parameter space $\mathcal{M}$ is the same support as the natural parameter space $\mathcal{N}.$
\end{claim}

\begin{proposition}The mean value parameterisation satisfies the 3 regularity conditions.
\end{proposition}


\begin{proposition_exam}{The sufficient statistic is MVUE}{}Under the mean-value parameterisation, the sufficient statistic $\utilde{s}(\utilde{x})$ is a minimum variance unbiased estimator of the mean-value parameter $\mu = \theta(\mu).$
\end{proposition_exam}

\begin{proof} First, the sufficient statistic $s(\utilde{x})$ is an unbiased estimator for the mean value parameter $\mu.$ The score function has the form 
$$
\ell_{\mu}^{\circ} = \frac{s(\utilde{x}) - \mu}{Var_{\mu}[s(\utilde{x})]}
$$
which is the form we need for the unbiased estimator $s(\utilde{x})$ to attain the Cramr-Rao lower bound.
\end{proof}



\lecture{15}{Local Asymptotic Normality}
\section{Local Asymptotic Normality}
\section{Local Asymptotic Normality}
\textit{In this lecture, we introduce the notion of local asymptotic normality. That is, the distribution of the log likelihood ratio is asymptotically normal in a local sense. Furthermore, the LAN property guarantees us the existence of a score vector and information matrix at our point of analysis. Finally, this will allow us to analyse other sequences that are nearby.}

\subsection{Taylor's Theorem}

First, we recall somethings from calculus. We can approximate differentiable functions using a Taylor polynomial and from there, derive the Taylor series.

\begin{definition}(Taylor Polynomial). Let f be a function that is differentiable n times on an open interval containing x = c. Then, the \textbf{Taylor polynomial of f at c} is 
$$
P_n(x) = f(c) + \frac{f^{(1)}(c)}{1!}(x - c) + \frac{f^{(2)}(c)}{2!}(x - c)^2 + ... + \frac{f^{(n)}(c)}{n!}(x - c)^{n}.
$$
\end{definition}


\begin{theorem_exam}{Taylor's Theorem}{}Suppose that f is n + 1 tiems differentiable on an interval containing x = c. Let $P_n(x) = f(c) + \frac{f^{(1)}(c)}{1!}(x - c) + ... + \frac{f^{(n)}(c)}{n!}(x - c)^{n}$ be the $n^{th}$ order Taylor polynomial of f at x = c. Then, 
$$
f(x) = P_n(x) + E_n(x)
$$
where $E_n(x)$ is the error term of $P_n(x)$ from f(x) and for $\epsilon$ between c and x, the \textbf{Lagrange remainder} form of the error $E_n$ is given by the formula 
$$
E_n(x) = \frac{f^{(n + 1)}(\epsilon)}{(n + 1)!}(x - c)^{n+1}.
$$
\end{theorem_exam}

\begin{corollary}Suppose that derivatives of all orders exists on an interval containing x and c. Then, Taylor's theorem holds and if for any x we have that $\lim_{n \rightarrow \infty}E_n(x) = 0$ then 
$$
\lim_{n \rightarrow \infty}P_n(x) = f(x).
$$
\end{corollary}


\subsection{Weak Convergence}
So far, we have seen 3 modes of convergence (a.s convergence, convergence in probability and $\mathcal{L}^p-$convergence). We will now introduce another one called \textbf{weak convergence} or \textbf{convergence in distribution}. This is different to the other 3 forms of convergence as the convergence only depends on their distribution.

\begin{definition_exam}{Weak Convergence}{}Let $(\Omega, \borelsigmaalgebra)$ be a measurable space where $(\Omega,d)$ is a metric space and $\borelsigmaalgebra$ is the Borel $\sa$ on $\Omega$. Let $\{\mu_n\}_{n \in \mathbb{N}}$ be a sequence of probability measures on $(\Omega, \borelsigmaalgebra)$. We say that $\mu_n$ \textbf{converges weakly} to a probability measure $\mu$ on $(\Omega, \borelsigmaalgebra)$ and write $\mu_n \xrightarrow{w} \mu$ if 
$$
\int fd\mu_n \rightarrow \int fd\mu
$$
for all $f \in C_b(\Omega)$ where $C_b(\Omega)$ denotes the set of all continuous and bounded functions $f: \Omega \rightarrow \mathbb{R}.$
\end{definition_exam}


From this, convergence in distribution is simply random variables weakly converging.
\begin{definition_exam}{Convergence in distribution}{}A sequence $\{X_n\}_{n \in \mathbb{N}}$ of random variables is said to \textbf{converge in distribution} to the random variable X if $\mu_{X_{n}} \xrightarrow{w} \mu_{X}$ where $\mu_X$ is the distribution measure induced by the random variable X. We then write this as $X_n \xrightarrow{d} X.$ 
\end{definition_exam}

In other words, a characterisation of convergence in distribution is that the expected value of bounded continuous functionals converges. We give other characterisation of convergence in distribution.

\begin{lemma}(Portmanteau Lemma). For any random variables $X_n$ and X, the following statements are equivalent.
\begin{enumerate}
\item $X_n \xrightarrow{d} X$
\item $P(X_n \leq x) \rightarrow P(X \leq x)$
\item $\mathbb{E}[f(X_n)] \rightarrow \mathbb{E}[f(X)]$ for all bounded, Lipschitz functions f
\end{enumerate}
\end{lemma}

\begin{proposition}(Uniqueness of weak convergence). Suppose that $\{\mu_n\}_{n \in \mathbb{N}}$ is a sequence of probability measures on $(\Omega, \borelsigmaalgebra)$ such that $\mu_n \xrightarrow{w} \mu$ and $\mu_n \xrightarrow{w} \mu^{'}.$ Then $\mu = \mu^{'}.$
\end{proposition}

\subsection{Asymptotic Statistics}
Why do we care about asymptotic statistics? In most statistical models in a frequentist setting, exact inference is not feasible and hence asymptotic results can provide convenient approximations. Furthermore, we can gain valuable theoretical insights into complex models and complex problems. We can also define new measures of optimality in an asymptotic setting.

\begin{definition}(Asymptotic distribution). Let us define the sequence of non-random constants $\{a_n\}, \{b_n\}$. Let $\{\hat{\theta}_n\}$ be a sequence of estimators. Then, suppose that 
$$
b_n(\hat{\theta}_n - a_n) \xrightarrow{d} G
$$
where G is a distribution. Then, $\{\hat{\theta}_n\}$ is said to have the asymptotic distribution G.
\end{definition}

We describe some other useful results we will need. The continuous-mapping theorem states that if a sequence of random vectors $X_n$ converges to X and g is continuous, then $g(X_n)$ converges to g. This holds for multiple forms of convergence.

\begin{theorem}(Continuous Mapping Theorem). Let $g$ be a continuous function at every point of a set C such that $\mathbb{P}(X \in C) = 1.$ Then 
\begin{enumerate}
\item If $X_n \xrightarrow{d} X$ then $g(X_n) \xrightarrow{d} g(X)$
\item If $X_n \xrightarrow{p} X$ then $g(X_n) \xrightarrow{p} g(X)$
\item If $X_n \xrightarrow{a.s.} X$ then $g(X_n) \xrightarrow{a.s.} g(X)$
\end{enumerate}
\end{theorem}

\begin{definition}(Bounded in probability). Let $\{X_n\}$ be a sequence of random vectors. Then, the sequence is bounded in probability if for every $\epsilon > 0$, there exists a constant M such that 
$$
\sup_{n}\mathbb{P}(|X_n| > M) < \epsilon
$$
\end{definition}

\begin{lemma}Every weakly converging sequence $X_n$ is bounded in probability.
\end{lemma}


In the i.i.d setting 
$$
\utilde{S_n} = n^{-1/2}\sum_{i=1}^{n}\utilde{\ell_{\theta}^{\circ}}(\utilde{X_i})
$$

Then, to compute the information 
$$
\mathbb{E}[\utilde{S_n}\utilde{S_n}^T] = \frac{1}{n}\bigg[\sum_{i=1}^{n}\utilde{\ell_{\theta}^{\circ}}(\utilde{X_i}) \cdot \utilde{\ell_{\theta}^{\circ}}(\utilde{X_i})^T \bigg]
$$

\subsection{Local Asymptotic Normality}

We are now interested in \textbf{sequences of parametric models} for the data $\utilde{x}$. That is, we will define a sequence of probability models $\{p_{n\theta}(.)\}$ whereby we will have a different sample space $\mathcal{X}_n$ and measure $\nu_n(.)$ for each n. The LAN property as we will soon see captures a particular aspect of regularity in regular parametric models.


\begin{definition_exam}{Log Likelihood Ratio}{}Suppose that for each $n = 1,2,...$ and each $\utilde{\theta} \in \Theta \subseteq \mathbb{R}^d$, we have a probability distribution $\prob_{n \utilde{\theta}}$ on a sample space $\mathcal{X}_n$ whose density function with respect to the measure $\nu_n(.)$ is $p_{n \utilde{\theta}}(.).$ Fix an interior point $\utilde{\theta_0} \in \Theta.$ Define the sequence of supports $A_n = A_n(\utilde{\theta_0}) = \{\utilde{x}: \mathcal{X}_n: p_{n \utilde{\theta}}(\utilde{x}) > 0 \}$. Then, for any other $\utilde{\theta_1} \in \Theta$, we define the \textbf{log likelihood ratio} as 
$$
L_n(\utilde{x}; \utilde{\theta_1}|\utilde{\theta_0}) = 
\begin{cases}
\frac{log\;p_{n \utilde{\theta}_{1}}(\utilde{x}) }{log\;p_{n \tilde{\theta_{0}}}(\utilde{x})} \quad \text{for } \utilde{x} \in A_n\\\\
0 \quad \text{for } \utilde{x} \in A_n^c
\end{cases}
$$
where we define $L_n$ to be zero outside of the support $A_n.$
\end{definition_exam}

\begin{remark}
We can give a different interpretation of the log likelihood ratio. Suppose that $\prob_{n\utilde{\theta_1}}$ is absolutely continuous with respect to $\prob_{n\utilde{\theta_0}}$. Then, the log likelihood ratio is the logarithm of the Radon-Nikodym derivative of these two probability measures.
\end{remark}


We now want to do "local Pitman analysis" of the log likelihood ratio $L_n.$ We want to restrict our analysis to a local area where $\utilde{\theta_n} = \utilde{\theta_0} + n^{-\frac{1}{2}}\utilde{h}.$ We can think of this as we are taking a step $\utilde{h}$ away from the original point $\utilde{\theta_0}$. Then, we can define the LAN property as a local property around $\utilde{\theta_0}.$



\begin{definition_exam}{Local Asymptotic Normality}{}Let $L_n(\utilde{x}; \utilde{\theta_1}|\utilde{\theta_0})$ be the log likelihood of $\utilde{\theta_1}$ against the true value $\utilde{\theta_0}.$ We say that the \textbf{local asymptotic normality} property holds at $\utilde{\theta_0}$ if there exists a symmetric positive definite matrix $\utilde{J} = \utilde{J}(\utilde{\theta_0})$ and a random vector $\utilde{S_n} = \utilde{S_n}(\utilde{X_n}; \utilde{\theta_0})$ such that 
$$
\utilde{S_n}(\utilde{X_n}; \utilde{\theta_0}) \xrightarrow{d} \mathcal{N}(\utilde{0}, \utilde{J})
$$
where $\utilde{0}$ is the zero mean vector and covariance matrix $\utilde{J}$ such that when $\utilde{X_n} \sim \prob_{n \utilde{\theta_0}}$, for any d-dimensional vector $\utilde{h} \in \mathbb{R}^d$, the log likelihood ratio satisfies 
$$
L_n(\utilde{x}; \utilde{\theta_0} + n^{-\frac{1}{2}}\utilde{h}|\utilde{\theta_0}) = \utilde{h}^T\utilde{S_n} - \frac{1}{2}\utilde{h}^T\utilde{J}\utilde{h} + R_n
$$
where the remainder $R_n = R_n(\utilde{\theta_0}; \utilde{h}) \xrightarrow{p} 0.$
\end{definition_exam}

\begin{definition}(Vector of scores and information matrix). The random d-dimensional vector $\utilde{S_n}$ is the vector of scores and $\utilde{J}$ is the information matrix.
\end{definition}

\begin{remark}The information matrix $\utilde{J}$ is usually the covariance matrix of the first derivatives of the log likelihood. Therefore, the information matrix can be interpreted to be the asymptotic variance of the scores.
\end{remark}

\begin{remark} We will later see conditions which imply the LAN property but it is worth noting that if the conditions which imply LAN holds, then we can show that $
\utilde{S_n}(\utilde{X_n}; \utilde{\theta_0}) \xrightarrow{d} \mathcal{N}(\utilde{0}, \utilde{J})
$ using the central limit theorem.
\end{remark}
 
There are a few things we can remark. First, the score function converges to the multivariate normal distribution through the central limit theorem. This leads to the following result.

\begin{proposition_exam}{Log likelihood Ratio is asymptotically normal under LAN}{}The log likelihood ratio is asymptotically normal at $\utilde{\theta_0}$ if the LAN property holds at $\utilde{\theta_0}.$ That is, if $\utilde{X_n} \sim \prob_{n \utilde{\theta_0}}$, then
$$
L_n \xrightarrow{d} \mathcal{N}\bigg(-\frac{\utilde{h}^T\utilde{J}\utilde{h}}{2},\utilde{h}^T\utilde{J}\utilde{h} \bigg)
$$
\end{proposition_exam}

Hence, essentially, the LAN property states that the log likelihood ratio is a linear combination of the scores vector.

\begin{proposition_exam}{Density of a nearby sequence}{}Under the support, the density of a nearby sequence is given by the density under $\utilde{\theta_0}$ times the log likelihood ratio.
$$
\prob_{n(\utilde{\theta_0} + n^{-1/2}\utilde{h})} = e^{L_n}\prob_{n\utilde{\theta_0}}
$$
\end{proposition_exam}

\begin{proof} First, recall that the log likelihood ratio is given by
$$
L_n = log \bigg\{\frac{\prob_{n(\utilde{\theta_0} + n^{-1/2}\utilde{h})}}{\prob_{n\utilde{\theta_0}}} \bigg\}
$$
We can arrange this to get our desired result.
\end{proof}

\subsection{Le Cam's First Lemma}

We are now interested in the consequences of the local asymptotic normality property. We note that the LAN conditions only happens when the true distribution is $\prob_{\utilde{\theta_0}}$ under the sequence $\{\prob_{n}(\utilde{\theta_0})\}$. However, Le Cam showed that it also implies important properties for sequences that are nearby. In particular, we want to look at the nearby sequence $\{\prob_{n}(\utilde{\theta_0} + n^{-\frac{1}{2}}\utilde{h})\}$.

For a fixed n, the $\mathbb{P}_{n \utilde{\theta}}$ need not all have the same support unlike the exponential family.
\begin{definition_exam}{Contiguity}{}Denote $(\Omega_n, \sigmalgebra_n)$ be a sequence of measurable spaces, each equipped with two measures $P_n$ and $Q_n.$ We say that $Q_n$ is contiguous with respect to $P_n$ if for every sequence $A_n$ of measurable sets, $P_n(A_n) \rightarrow 0$ implies that $Q_n(A_n) \rightarrow 0.$
\end{definition_exam}

\begin{remark}We can say that two sequences of probability measures are contiguous if asymptotically, they share the same support. The notion of contiguity extends the concept of absolute continuity to the sequences of measures.
\end{remark}

Le Cam's first lemma states that sequences that are "nearby" are contiguous with one another. That is, the supports agree in an asymptotic sense.

\begin{theorem_exam}{Le Cam's First Lemma}{}Suppose that for each $n = 1,2,...$ and each $\utilde{\theta} \in \Theta \subseteq \mathbb{R}^d$, we have a probability distribution $\prob_{n \utilde{\theta}}$ on a sample space $\mathcal{X}_n$ whose density function with respect to the measure $\nu_n(.)$ is $p_{n \utilde{\theta}}(.).$ Fix an interior point $\utilde{\theta_0} \in \Theta.$ Define the sequence of supports $A_n = A_n(\utilde{\theta_0}) = \{\utilde{x}: \mathcal{X}_n: p_{n \utilde{\theta}}(\utilde{x}) > 0 \}$. Suppose that the LAN property holds at $\utilde{\theta_0}$. Then for a nearby sequence, the probability of a nearby alternative
$$
\prob_{n(\utilde{\theta_0} + n^{-\frac{1}{2}}\utilde{h})}(A_n) \rightarrow 1.
$$
\end{theorem_exam}

\begin{proof} The goal is to show that for any $\epsilon > 0,$ we have that $\prob_{n(\utilde{\theta_0} + n^{-\frac{1}{2}}\utilde{h})}(A_n) \geq 1 - \epsilon$ for the sequence of supports $A_n.$ First, the LAN property implies that for $\utilde{X_n} \sim \prob_{n \utilde{\theta_0}},$ we have that the log likelihood ratio
$$
L_n \xrightarrow{d} \mathcal{N}\bigg(\frac{-\delta^2}{2}, \delta^2\bigg)
$$
where $\delta^2 = \utilde{h}^T\utilde{J}\utilde{h}.$

We let $F_n$ be the CDF of the log likelihood ratio $L_n$ under the true distribution $\prob_{n \utilde{\theta_0}}.$ Let $F, f$ be the CDF and PDF of the limiting distribution of the log likelihood ratio $\mathcal{N}(\frac{-\delta^2}{2}, \delta^2).$ Additionally, let $G, g$ be the CDF and PDf of the limiting distribution of $\mathcal{N}(\frac{+\delta^2}{2}, \delta^2)$. 

Now, we can use the fact that for all v,
$$
g(v) = e^vf(v).
$$
Fix $\epsilon > 0$ and choose $M_{\epsilon}$ such that the upper quantile $G(M_{\epsilon}) > 1 - \epsilon.$ We are interested in the probability under the nearby parameter of the support 
$$
\prob_{n(\utilde{\theta_0} + n^{-1/2}\utilde{h})} (A_n) = \int_{A_n}d\prob_{n(\utilde{\theta_0} + n^{-1/2}\utilde{h})}
$$
$$
= \int_{A_{n}}e^{L_n}d\prob_{n \utilde{\theta_0}} = \int_{A_{n}}e^{L_n}p_{n \utilde{\theta_0}}(\utilde{x})d\nu_n(\utilde{x}) = \int_{\mathcal{X}_n}e^{L_n}d\prob_{n \utilde{\theta_0}} = \int_{-\infty}^{\infty}e^vdF_n(v)
$$

A characterisation of convergence in distribution is convergence of bounded continuous function 
$$
\geq \int_{-\infty}^{\infty}e^v 1\{v \leq M_{\epsilon}\} dF_n(v) \rightarrow \int_{-\infty}^{\infty}e^v 1\{v \leq M_{\epsilon}\} dF(v)
$$
since $F_n \xrightarrow{d} F$ where $e^v 1\{v \leq M_{\epsilon}\}$ is a bounded continuous function. Hence, we have that 
$$
= \int_{-\infty}^{\infty} 1\{v \leq M_{\epsilon}\} dG(v) = G(M_{\epsilon}) > 1 - \epsilon.
$$
As $\epsilon$ was arbitrary, this proves the theorem as 
$$
\prob_{n(\utilde{\theta_0} + n^{-1/2}\utilde{h})} (A_n) \geq 1 - \epsilon
$$
for arbitrary $\epsilon.$
\end{proof}


\begin{remark}Le Cam's first lemma is significant as the support under the true parameter and a nearby sequence may be different for a fixed n, but in the limit, they are the same.
\end{remark}

\subsection{LAN Property in Exponential Families}

We now give an example for the exponential family. Let $\{\prob_{\utilde{\theta}}: \utilde{\theta} \in \mathcal{N}\}$ be an exponential distribution on $\mathbb{R}^k$ where $\mathcal{N} = \{\int e^{\theta s(\utilde{x})} < \infty\}$ is the natural parameter space. Therefore, the density function of $\prob_{\utilde{\theta}}$ with respect to the $\sigma-$finite measure $\nu(.)$ is of the form 
$$
p_{\utilde{\theta}}(\utilde{x}) = e^{\utilde{\theta}^T\utilde{s}(\utilde{x}) - K(\utilde{\theta})}.
$$

Suppose that $\utilde{X}_1,...,\utilde{X}_n$ are i.i.d with common distribution $\prob_{\utilde{\theta_0}}$ for some true unknown $\utilde{\theta_0} \in \mathcal{N}.$ Then, fix $\utilde{h} \in \mathbb{R}^d$ where $d << k$ and consider the log likelihood ratio 

\begin{equation}
L(h) = \text{log} \prod_{i=1}^{n} \bigg\{ \frac{p_{\utilde{\theta_0} + n^{-\frac{1}{2}}\utilde{h}}(\utilde{X_i}) }{p_{\utilde{\theta}_{0}}(\utilde{X_i}) }\bigg\} = \utilde{h}^Tn^{-1/2}\sum_{i=1}^{n}\utilde{s}(\utilde{x_i}) - n[K(\utilde{\theta_0} + n^{-1/2}\utilde{h}) - K(\utilde{\theta_0})] \tag{*}
\end{equation}

We can interpret K to be the cumulant generating function if $\nu(.)$ is a probability measure. Furthermore, it is infinitely smooth from the theorem that allows us to infinitely differentiate the moment generating function of the sufficient statistic. We can then therefore apply a 2nd order Taylor series expansion on K.

$$
K(\utilde{\theta_0} + n^{-1/2}\utilde{h}) = K(\utilde{\theta_0}) + n^{-1/2}h^T\utilde{K}^{'}(\utilde{\theta_0}) + n^{-1/2}\utilde{h}^T\utilde{K}^{''}(\utilde{\theta_n^*})\utilde{h}^T
$$
for some $\utilde{\theta_n^*}$ between $\utilde{\theta_0}$ and $\utilde{\theta_0} + n^{-1/2}\utilde{h}.$ Furthermore, $K^{'}, K^{''}$ are the vector of 1st order and matrix of 2nd order partial derivatives.

By element-wise continuity of $\utilde{K}^{''}(.)$, we have that 
$$
\utilde{h}^T\utilde{K}^{''}(\utilde{\theta_n^*})\utilde{h}^T \rightarrow \utilde{h}^T\utilde{K}^{''}(\utilde{\theta_0})\utilde{h}^T 
$$

as $\utilde{\theta_n^*} \rightarrow \utilde{\theta_0}$ in a shrinking neighbourhood.

We can now take this second order Taylor series expansion of the cumulant generating function and plug it back into our log likelihood ratio in (*).

\begin{proposition_exam}{LAN Property of exponential family}{}
Suppose all the conditions we elaborated in this section holds. Therefore, for an exponential family, we have a log likelihood ratio 
$$
L_n(\utilde{h}) = \utilde{h}^T\utilde{S_n} - \frac{1}{2}\utilde{h}^T\utilde{J}\utilde{h} + R_n(\utilde{h})
$$
where the score function vector
$$
\utilde{S_n} = \frac{1}{n^{1/2}}\sum_{i=1}^{n}\bigg[\utilde{s}(\utilde{x_i}) - \utilde{K}^{'}(\utilde{\theta_0} \bigg] \xrightarrow{d} \mathcal{N}(\utilde{0}, \utilde{J}).
$$
Furthermore, $\utilde{J} = \utilde{K}^{''}(\utilde{\theta_0})$ is the 2nd order partial derivatives matrix, which was the covariance matrix of the sufficient statistic. Finally, the remainder term $R_n(\utilde{h}) \xrightarrow{p} 0.$
\end{proposition_exam}

\begin{remark}Recall that $K^{'}(\utilde{\theta_0})$ is the mean-value of the sufficient statistic. Therefore, the difference between the score and $K^{'}(\utilde{\theta_0})$ has mean zero. Then by the central limit theorem, converges to a multivariate normal.
\end{remark}

We will now show that this rescaled, localised log likelihood ratio is similar to that for a multivariate Gaussian normal based on a single observation.

\begin{definition}(Multivariate Normal with shifted location of one observation). Suppose the vector $\utilde{S} \sim \mathcal{N}(\utilde{J}\utilde{h}, \utilde{J})$ for a known $\utilde{J}$ but unknown $\utilde{h}.$ This is a shifted multivariate normal distribution. Then, the density for one observation of $\utilde{S}$ is 
$$
f_{\utilde{h}}(s) = \frac{1}{(2\pi)^{d/2}}\frac{1}{(det\;J)^{1/2}}e^{-\frac{1}{2}\big\{(s - \utilde{J}\utilde{h})^T\utilde{J}^{-1}(s - \utilde{J}\utilde{h}) \big\}}
$$
\end{definition}

\begin{proposition_exam}{Log likelihood ratio for multivariate normal}{}The log likelihood ratio for the multivariate normal distribution between values $\utilde{h}$ and $\utilde{0}$ is given by 
$$
log\{\frac{f_{\utilde{h}}(\utilde{s})}{f_{\utilde{0}}(\utilde{s})}\} = \utilde{h}^T\utilde{s} - \frac{1}{2}\utilde{h}^T\utilde{J}\utilde{h}.
$$
\end{proposition_exam}

Hence, the log likelihood ratio of the multivariate normal with shifted location of one observation is the same as the log likelihood of the exponential family near the true value!

Hence, we have a big takeaway.
\begin{theorem_exam}{LAN Property always hold for exponential families}{}Let $\{\prob_{\utilde{\theta}}: \utilde{\theta} \in \mathcal{N} \}$ be a family of exponential distributions where $\mathcal{N}$ is the natural parameter space. Then, the LAN property holds for all $\utilde{\theta}$ that is an interior point of $\mathcal{N}.$
\end{theorem_exam}

\begin{corollary} The LAN property still holds after exponential families after a smooth change of parameters 
$$
\eta \rightarrow \theta(\eta)
$$
where the smooth change is three times differentiable.
\end{corollary}


\lecture{16}{Le Cam's Third Lemma}
\section{Local Asymptotic Normality}
\subsection{Le Cam's Third Lemma}
\textit{Recall from last lecture that Le Cam's first lemma tells us that supports of nearby alternatives are equal asymptotically. Furthermore, LAN tells us what happens under the true value $\utilde{\theta_0}.$ In this lecture, we will see that Le Cam's third lemma tells us the joint distribution of statistics and nearbly alternatives are asymptotically normal. Furthermore, we will also introduce the concept of $L_2-$differentability which is a condition that will imply the LAN property.}

Le Cam's third lemma tells us that the joint distribution of a nearby alternative $\prob_{n(\utilde{\theta_0} + n^{-\frac{1}{2}}\utilde{h})}$ of both the log likelihood ratio $L_n$ and statistic $Y_n$ is asymptotically normal.

\begin{theorem_exam}{Le Cam's Third Lemma}{}Suppose that the LAN property holds at $\utilde{\theta_0}$. Furthermore, assume that $Y_n$ is a statistic such that under the value at which LAN holds, $\prob_{n\utilde{\theta_0}}$, we have the following limiting behaviour 
\begin{equation}
\begin{pmatrix}
Y_n\\
L_n
\end{pmatrix}
 \xrightarrow{d} \mathcal{N}
\bigg( 
\begin{pmatrix}
0 \\
-\frac{\delta^2}{2}
\end{pmatrix}
,
\begin{pmatrix}
\sigma^2 & \beta \\
\beta & \delta^2
\end{pmatrix}
\bigg)
\tag{*}
\end{equation}
where $Y_n$ has limiting mean $0$ and variance $\sigma^2$, $\delta^2 = \utilde{h}^T\utilde{J}\utilde{h},$ and $\beta$ is the covariance between $Y_n$ and $L_n.$ Then, under a nearby alternative sequence $\prob_{n(\utilde{\theta_0} + n^{-1/2}\utilde{h})}$
\begin{equation}
\begin{pmatrix}
Y_n\\
L_n
\end{pmatrix}
 \xrightarrow{d} \mathcal{N}
\bigg( 
\begin{pmatrix}
\beta \\
+\frac{\delta^2}{2}
\end{pmatrix}
,
\begin{pmatrix}
\sigma^2 & \beta \\
\beta & \delta^2
\end{pmatrix}
\bigg)
\tag{**}
\end{equation}
\end{theorem_exam}

\begin{proof} Let $F_n$ denote the joint CDF of $(Y_n, L_n)^T$ under $\prob_{n \utilde{\theta_0}}.$ Let F and f denote the CDF and PDF of the bivariate normal distribution (*). Let G and g denote the CDF and PDF of the bivariate normal distribution (**). Let $G_n$ denote the CDF of $(Y_n, L_n)^T$ under the nearby sequence $\prob_{n(\utilde{\theta_0} + n^{-1/2}\utilde{h})}$. 

Then, the joint CDF of $G_n(y,l)$ is 
$$
G_n(y,l) = \prob_{n(\utilde{\theta_0} + n^{-1/2}\utilde{h})}\bigg(\{Y_n \leq y, L_n \leq l\} \cap A_n \bigg) + \prob_{n(\utilde{\theta_0} + n^{-1/2}\utilde{h})}\bigg(\{Y_n \leq y, L_n \leq l\} \cap A_n^c \bigg)
$$
where $A_n = \{\utilde{x}: \prob_{n\utilde{\theta_0}}(\utilde{x}) > 0\}$ is the support of $\prob_{n\utilde{\theta_0}}.$ However, by Le Cam's first lemma, we have that 
$$
\prob_{n(\utilde{\theta_0} + n^{-1/2}\utilde{h})}\bigg(\{Y_n \leq y, L_n \leq l\} \cap A_n^c \bigg) \xrightarrow{p} 0.
$$
Therefore, we restrict our attention to the first term. We now want to show that $G_n \rightarrow G.$

$$
\prob_{n(\utilde{\theta_0} + n^{-1/2}\utilde{h})}\bigg(\{Y_n \leq y, L_n \leq l\} \cap A_n \bigg) = \int_{A_n}1\{Y_n \leq y, L_n \leq l\}d\prob_{n(\utilde{\theta_0} + n^{-1/2}\utilde{h})}
$$
$$
= \int_{A_n}e^{L_n}1\{Y_n \leq y, L_n \leq l\}d\prob_{n\utilde{\theta_0}} = \int_{\mathcal{X}_n}e^{L_n}1\{Y_n \leq y, L_n \leq l\}d\prob_{n\utilde{\theta_0}}
$$
$$
= \int_{-\infty}^{\infty}\int_{-\infty}^{\infty}e^v1\{u \leq y, v \leq l\}dF_n(u,v) \rightarrow \int_{-\infty}^{\infty}\int_{-\infty}^{\infty}e^v1\{u \leq y, v \leq l\}dF(u,v)
$$
since $F_n \xrightarrow{d} F.$ 
$$
= \int_{-\infty}^{\infty}\int_{-\infty}^{\infty}1\{u \leq y, v \leq l\}dG(u,v) = G(y, l).
$$
Therefore, we have shown that $G_n(y,l) \rightarrow G(y,l).$
\end{proof}

More succinctly, if a statistic $Y_n$ is asymptotically jointly normal with the log likelihood ratio, then for a nearby alternative, $Y_n$ is still asymptotically jointly normal with the log likelihood ratio with the limiting mean of $Y_n$ now the covariance under $\utilde{\theta_0}$. The nearby limiting sequence only has an effect on altering the limiting means.

\subsection{Conditions implying LAN property}

We are now interested in investigating the conditions for which the LAN property will hold. In particular, classical conditions involving the third order partial derivatives so that we can compute third order Taylor expansions of the log likelihood of $\utilde{\theta}$ are actually too stringent. That is, we can actually relax these classical conditions and the LAN property will still hold. We will soon see that weak conditions involving a first derivative of the square root of the density are all that is needed. We will later see that if a family of densities is $L_2(\nu)$-differentiable at $\utilde{\theta_0}$ then the LAN property holds at $\utilde{\theta_0}.$

\begin{definition}($L_2$-norm and space). Let $\nu$ be a measure. We define the $L_2(\nu)$ class as the class of functions 
$$
L_2(\nu) = \{g: \int g^2d\nu < \infty\}.
$$
Furthermore, for any $g \in L_2(\nu)$, we define the $L_2(\nu)$-norm of g as 
$$
||g|| = \sqrt{\int g^2d\nu}.
$$
\end{definition}

\begin{proposition}The $L_2(\nu)$ space is a Hilbert space.
\end{proposition}



\begin{proposition_exam}{Existence of partial derivatives of log density}{}Suppose we have a parametric family of distributions $\{\prob_{ \utilde{\theta}}: \utilde{\theta} \in \Theta\}$ for $\Theta \subseteq \mathbb{R}^d$ and that each posseses a density $p_{\utilde{\theta}}(.)$ with respect to a $\sigma-$finite measure $\nu(.).$ If the density $p_{\utilde{\theta}}(\utilde{x}) > 0$ and the vector of partial derivatives 
$$
\utilde{p}_{\utilde{\theta}}^{\circ}(\utilde{x}) = \bigg(\frac{\partial}{\partial \theta_1}p_{\utilde{\theta}}(\utilde{x}),...,\frac{\partial}{\partial \theta_d}p_{\utilde{\theta}}(\utilde{x}) \bigg)^T
$$
exists, then the vector of partial derivatives of the log-density $\ell_{\utilde{\theta}}(\utilde{x}) = log\;p_{\utilde{\theta}}(\utilde{x})$ also exist. This is given by 
$$
\utilde{\ell}_{\utilde{\theta}}^{\circ}(\utilde{x}) = \frac{\utilde{p}_{\utilde{\theta}}^{\circ}(\utilde{x})}{\utilde{p}_{\utilde{\theta}}(\utilde{x})}
$$
\end{proposition_exam}

\begin{corollary}Under the same conditions, the square root of the density $\sqrt{p_{\utilde{\theta}}(\utilde{x})}$ has a vector of partial derivatives 
$$
\sqrt{p_{\utilde{\theta}}}^{\circ} = \frac{1}{2}\frac{\utilde{p}_{\utilde{\theta}}^{\circ}(\utilde{x})}{\sqrt{\utilde{p}_{\utilde{\theta}}(\utilde{x})}} = \frac{1}{2}\utilde{\ell}_{\utilde{\theta}}^{\circ}(\utilde{x})\sqrt{p_{\utilde{\theta}}(\utilde{x})}
$$
\end{corollary}

To motivate the definition of $L_2$-derivative, first recall the definition of the Frchet derivative.
\begin{definition}(Frchet derivative). Let V and W be normed vector spaces and $U \subset V$ be an open subset of V. A function $f: U \rightarrow W$ is called Frchet differentiable at $x \in U$ if there exists a bounded linear operator $A: V \rightarrow W$ such that 
$$
\lim_{||h|| \rightarrow 0}\frac{||f(x + h) - f(x) - Ah ||_W}{||h||_V} = 0.
$$
\end{definition}

\begin{definition_exam}{$L_2$-derivative}{}For any $\utilde{h} \in \mathbb{R}^d$, for a value $\utilde{x}$ where $p_{\utilde{\theta}}(\utilde{x}) > 0$ and $p_{\utilde{\theta}}^{\circ}(\utilde{x})$ exists, the $L_2$-derivative at $\utilde{x}$ is 
$$
\frac{\sqrt{p_{\utilde{\theta} + \utilde{h}}(\utilde{x})} - \sqrt{p_{\utilde{\theta}}(\utilde{x})} - \frac{1}{2}\utilde{h}^T\utilde{\ell}_{\utilde{\theta}}^{\circ}(\utilde{x}) }{|\utilde{h}|} \rightarrow 0
$$
as $||h| \rightarrow 0$ where $|\utilde{h}| \sqrt{h_1^2 + ... + h_d^2}$ is the Euclidean norm.
\end{definition_exam}

\begin{proposition}(Square root of densities is in $L_2$). The square of densities $\sqrt{p_{\utilde{\theta}}}$ is square integrable with respect to $\nu(.)$ and hence $\sqrt{p_{\utilde{\theta}}} \in L_2(\nu).$
\end{proposition}

We can now give a different characterisation of $L_2$-differentability based on the $L_2-$norm.

\begin{proposition_exam}{Condition for $L_2-$differentiability}{}The family of densities $\{p_{\utilde{\theta}}(.): \utilde{\theta} \subseteq \Theta\}$ is said to be $L_2(\nu)-$differentiable at $\utilde{\theta_0}$ if there exists a vector of functions $\utilde{\ell}_{\utilde{\theta}}^{\circ}$ such that 
$$
\int \frac{\bigg[\sqrt{p_{\utilde{\theta} + \utilde{h}}} - \sqrt{p_{\utilde{\theta}}} - \frac{1}{2}\utilde{h}^T \utilde{\ell}_{\utilde{\theta}}^{\circ}\sqrt{p_{\utilde{\theta}}} \bigg]^2}{|h|}d\nu \rightarrow 0
$$
as $|h| \rightarrow 0.$
\end{proposition_exam}

\begin{remark}
The product $\utilde{\ell}_{\utilde{\theta}}^{\circ}\sqrt{p_{\utilde{\theta}}}$ is half the $L_2$-derivative of the square root of the density $\sqrt{p_{\utilde{\theta}}}.$
\end{remark}

Here, we have that it is converging to zero in the $L_2(\nu)$ norm instead of pointwise in $\utilde{x}$ in our original definition of $L_2(\nu)$-differentability. We will soon see that $L_2(\nu)-$differentiability is sufficient for LAN to hold.

\newpage
\subsection{Strict Conditions for the LAN property to hold}
We now want to look at what are stricter conditions for the LAN property to hold. They may be stricter but they are also much easier to verify.

\begin{definition}(Cube). Define the parameter vector $\theta_0 = (\theta_{01},...,\theta_{0d})^T.$ Then, the $\epsilon-$neighbourhood (cube) of $\theta_0$ is given by 
$$
C(\theta_0, \epsilon) = \{\theta = (\theta_1,...,\theta_d)^T \in \Theta: \max_{a}|\theta_a - \theta_{0 a}| < \epsilon \}
$$
\end{definition}

We now state the "restrictive" condition for LAN property.
\begin{proposition_exam}{Restrictive Conditions for LAN Property}{}Suppose $\utilde{X_1},...,\utilde{X_n}$ are iid random vectors with common density $p_{\theta_{0}}(.)$ where $\theta_0$ is an interior point of the parameter space $\Theta \subset \mathbb{R}^d$ of the parametric family of densities $\{p_{\theta}(.): \theta \in \Theta \}.$ Define the log density to be $\ell_{\theta}(\utilde{x}) = log\;p_{\theta}(\utilde{x}).$ The 3 conditions needed for the LAN property to hold are as follows.
\begin{enumerate}
\item For some $\epsilon > 0$ and all $\theta \in C(\theta_0, \epsilon)$, the third-order partial derivatives with respect to elements of $\theta$ exists for ($p_{\theta_0}$-almost) all $\utilde{x}$ and satisfy 
$$
\bigg|\frac{\partial^3 \ell_{\theta}(\utilde{x})}{\partial \theta_{a}\partial \theta_{b}\partial \theta_{c}} \bigg| \leq A(\utilde{x})
$$
for a function $A(.)$ satisfying $\mathbb{E}[A(\utilde{X_1})] < \infty$ for all $a,b,c = 1,...,d;$
\item The expectation of the log density is zero 
$$
\mathbb{E}[\ell_{\theta_{0}}^{\circ}(\utilde{X_1})] = \utilde{0};
$$
\item The information matrix 
$$
\utilde{J} = \mathbb{E}[\ell_{\theta_{0}}^{\circ}(\utilde{X_1})\ell_{\theta_{0}}^{\circ}(\utilde{X_1})^T] = -\mathbb{E}[\ell_{\theta_{0}}^{\circ \circ}(\utilde{X_1})]
$$
exists and is positive definite.
\end{enumerate}
Then, the LAN condition holds at $\theta_0$ with score function $\utilde{S_n} = n^{-1/2}\sum_{i=1}^{n}\ell_{\theta_{0}}^{\circ}(\utilde{X_i})$ and information matrix $\utilde{J}$ given above.
\end{proposition_exam}

\begin{proof}(Sketch). As the log density has 3rd-order derivatives, we can take Taylor expansions on the log likelihood under nearby alternatives $
\sum_{i=1}^{n}\ell_{\utilde{\theta_0} + n^{-1/2}\utilde{h}}(\utilde{X_i})$. We then show that the third order term in this expansion is a remainder term $R_n$, which is bounded by $A(\utilde{x})$ and therefore we can show that $R_n \xrightarrow{p} 0.$ Then, the second order term can be shown to converge to the information matrix $\utilde{J}$ and the first order term is the score. Then, we can write out the log likelihood ratio 
$$
L_n(\utilde{X}, \utilde{\theta_0} + n^{-1/2}\utilde{h}; \utilde{\theta_0}) = \sum_{i=1}^{n}\ell_{\utilde{\theta_0} + n^{-1/2}\utilde{h}}(\utilde{X_i}) - \sum_{i=1}^{n}\ell_{\utilde{\theta_0}}(\utilde{X_i}) = \utilde{h}^T\utilde{S_n} - \frac{1}{2}\utilde{h}^T\utilde{J}\utilde{h} + R_n
$$
and hence the LAN property holds.
\end{proof}

\begin{corollary}If the restrictive assumptions for LAN holds, we can also compute the information matrix by taking the negative of the expectation of the Hessian of the score vector.
\end{corollary}

We now want to show that under these restrictive assumptions, that the score vector converges to a normal distribution. First, recall the multivariate central limit theorem.
\begin{proposition} Suppose that $\utilde{X} = (x_1, x_2, ..., x_k)^T \in \mathbb{R}^k$ is a random vector with covariance $\Sigma.$ Assume that $\mathbb{E}[x_i] < \infty.$ Then, if $\utilde{X_1}, \utilde{X_2}, ...$ is a sequence of i.i.d copies of $\utilde{X}$ then 
$$
\frac{1}{\sqrt{n}} \sum_{i=1}^{n} \bigg(\utilde{X_i} - \mathbb{E}[\utilde{X_i}] \bigg) \xrightarrow{d} \mathcal{N}(\utilde{0}, \utilde{J})
$$
\end{proposition}

\begin{proposition_exam}{Score function converges to a normal distribution}{} Suppose that the restrictive conditions for the LAN property hold. Then 
$$
\utilde{S_n} \xrightarrow{d} \mathcal{N}(\utilde{0}, \utilde{J})
$$
\end{proposition_exam}
\begin{proof} By the second assumption, we have that 
$$
\mathbb{E}[\utilde{S_n}] = \mathbb{E}[n^{-1/2}\sum_{i=1}^{n}\ell_{\theta_{0}}^{\circ}(\utilde{X_i})] = \utilde{0}
$$
By the third assumption, we have that $\utilde{J}$ is the covariance matrix of $\utilde{S_n}$. Then, by the multivariate central limit theorem, we have that 
$$
\frac{1}{\sqrt{n}} \sum_{i=1}^{n} \bigg(\ell_{\theta_{0}}^{\circ}(\utilde{X_i}) - \mathbb{E}[\ell_{\theta_{0}}^{\circ}(\utilde{X_i})] \bigg) =\utilde{S_n} - 0 \xrightarrow{d} \mathcal{N}(\utilde{0}, \utilde{J})
$$
\end{proof}



We can actually relax the first assumption in LAN to the following. That is, instead of having a fixed cube, we can now have a shrinking cube, where the speed in which it is shrinking is slower than $n^{-1/2}.$ Additionally, instead of it holding for all $\utilde{x},$ it only holds for all $\utilde{x}$ in a set $B_n$ which is approaching one. That is, the probability of not being in $B_n$ quickly approaches 0. Thirdly, the third derivative is bounded by $A_n(\utilde{x})$ where the function $A_n$ now depends on n and this only applies to $\utilde{x}$ inside the set $B_n.$ Finally, as $A_n$ is no longer fixed, we require the limit superior of $A_n$ is finite.
\begin{proposition_exam}{Relaxation of assumption 1 in restrictive conditions for LAN}{} For some $\epsilon_n \rightarrow 0$ more slowly than $n^{-1/2}$ and all $\theta \in C(\theta_0, \epsilon_n),$ the third-order partial derivatives exists with respect to the elements of $\theta$ for all $\utilde{x}$ in a set $B_n$ with $P_{\theta_{0}}(B_n^c) \rightarrow 0$ faster than $n^{-1}.$ Furthermore, the third-order partial derivatives satisfy 
$$
1\{\utilde{x} \in B_n\}\bigg|\frac{\partial^3 \ell_{\theta}(\utilde{x})}{\partial \theta_{a}\partial \theta_{b}\partial \theta_{c}} \bigg| \leq A_n(\utilde{x})
$$
for functions $\{A_n(.)\}$ satisfying $lim \sup_{n \rightarrow \infty}\mathbb{E}[A_n(\utilde{X_1}) < \infty$ for all $a, b, c = 1,...,d.$
\end{proposition_exam}



\subsection{LAN property for Location and Scale Families}
We now want to apply LAN to location and scale families.
We can now describle location and scale families based on the following theorem.
\begin{theorem}Let f(x) be any probability density function and let $\mu$ and $\sigma > 0$ be any given constants. Then 
$$
g(x|\mu, \sigma) = \frac{1}{\sigma}f(\frac{x - \mu}{\sigma})
$$
is a probability density function.
\end{theorem}

\begin{definition}(Location family). Let f(x) be a probability density function. Then, the family of probability density functions $\{f(x - \mu): \mu \in \mathbb{R}\}$ is called the location family with standard probability density function f(x) and $\mu$ is called the location parameter for the family.
\end{definition}

\begin{proposition}(Properties on standard probability density function). Suppose f(x) is a probability density function on the real line and for some $-\infty \leq a < b \leq \infty$, we have that 
\begin{enumerate}
\item $f(x) > 0$ for all $a < x < b$ and $\int_{a}^{b}f(x)dx = 1$
\item f(.) is twice continuously differentiable at all $a < x < b$
\item $\lim_{x \rightarrow a}f(x) = \lim_{x \rightarrow b}f(x) = \lim_{x \rightarrow a}f^{'}(x) = \lim_{x \rightarrow b}f^{'}(x) = 0$
\item $\int_{a}^{b}\frac{f^{'}(x)^2}{f(x)}dx < \infty$
\end{enumerate}
Then, define the location family $p_{\theta}(x) = f(x - \theta).$ We then have that conditions (2) and (3) for the restrictive conditions for LAN property hold. That is, 
$$
\mathbb{E}[\ell_{\theta_{0}}^{\circ}(\utilde{X_1})] = \utilde{0};
$$
and 
$$
\utilde{J} = \mathbb{E}[\ell_{\theta_{0}}^{\circ}(\utilde{X_1})\ell_{\theta_{0}}^{\circ}(\utilde{X_1})^T] = -\mathbb{E}[\ell_{\theta_{0}}^{\circ \circ}(\utilde{X_1})]
$$
exists and is positive definite.
\end{proposition}



\begin{proposition_exam}{LAN property for Location models}{} Any location models whose standard probability density satisfies the above conditions, will satisfy conditions 2 and 3 in the restrictive conditions for LAN property. That is, a location model will have an information matrix and expectation of the log density is 0.
\end{proposition_exam}
\begin{remark}This means that to show LAN property holds for a location model, we only need to prove condition 1!
\end{remark}


\begin{definition}(Scale family). Let f(x) be a probability density function. Then, the family of probability density functions $\{\frac{1}{\sigma}f(\frac{x}{\sigma}): \sigma \in \mathbb{R}\}$ is called the scale family with standard probability density function f(x) and $\sigma$ is called the scale parameter for the family.
\end{definition}

\begin{definition}(Location-Scale family). Let f(x) be a probability density function. Then, the family of probability density functions $\{\frac{1}{\sigma}f(\frac{x - \mu}{\sigma}): \mu, \sigma \in \mathbb{R}\}$ is called the location-scale family with standard probability density function f(x), $\mu$ is called the location parameter and $\sigma$ is called the scale parameter for the family.
\end{definition}

\begin{proposition_exam}{LAN property for Location-Scale models}{} Any location-scale models whose standard probability density satisfies the above conditions, will satisfy conditions 2 and 3 in the restrictive conditions for LAN property. That is, a location-scale model will have an information matrix and expectation of the log density is 0.
\end{proposition_exam}


\lecture{17}{$L^2$ differentiability implies LAN}
\section{Local Asymptotic Normality}
\subsection{$L^2$ differentiability implies LAN}

\textit{In this lecture, we want to show that we no longer require second or third derivatives to exists in order for the LAN property to hold. We only require $L_2-$differentiability.}


We now state a collection of lemmas which can be used to help prove the main theorem of this section.
\begin{proposition}(Continuity of the inner product). Suppose we have sequences of functions $\{f_n\}$ and $\{g_n\}$ whereby $f_n \rightarrow f$ and $g_n \rightarrow g$ in $L_2(\nu).$ That is, $\int(f_n - f)^2 d\nu \rightarrow 0.$ Then 
$$
\int f_ng_nd\nu \rightarrow \int fgd\nu.
$$
\end{proposition}

\begin{lemma}(Convergence in probability to a constant). Let $X_1, X_2, ...$ be a sequence of random variables where $\mathbb{E}[X_n] \rightarrow \mu$ and $Var[X_n] \rightarrow 0.$ Then 
$$
X_n \xrightarrow{p} \mu.
$$
\end{lemma}

\begin{lemma}We may write 
$$
2log(1 + \frac{x}{2}) = x - \frac{x^2}{4} + x^2R(x)
$$
where $R(x) \rightarrow 0$ as $x \rightarrow 0.$
\end{lemma}

\begin{lemma}Suppose we have a sequence of random variables $\{A_n\}$ and $\{B_n\}$ that have the mean square 
$
\lim_{n \rightarrow \infty}\sup E[A_n^{2}] < \infty
$
and 
$
E((A_n - B_n)^2) \rightarrow 0.
$
Then, we may write $A_n^2 = B_n^2 + C_n$ with 
$$
E(|C_n|) \rightarrow 0.
$$
\end{lemma}

\begin{lemma}For a non-negative random variable X with $E(X) < \infty$, then for any $C_n \rightarrow \infty$, we have that 
$$
E(X.1\{\utilde{X} > C_n\}) \rightarrow 0.
$$
\end{lemma}

\begin{lemma}For identically disitributed random variables $\utilde{X_1},...\utilde{X_n}$, for any real C, 
$$
\prob(\max_{i=1,...,n}\utilde{X_i} > C) \leq n\prob(\utilde{X_1} > C).
$$
\end{lemma}

We now state the important theorem.
\begin{theorem_exam}{$L_2$-differentiability implies LAN}{}Let $\{p_{\utilde{\theta}}(.): \utilde{\theta} \in \Theta\}$ for $\Theta \subseteq \mathbb{R}^d$ be a family of densities with respect to a $\sigma-$finite measure $\nu(.)$ and suppose that the map 

$$
\utilde{\theta} \rightarrow \sqrt{p_{\utilde{\theta}}}
$$

is $L_2(\nu)$-differentiable at $\utilde{\theta_0}$ and that $\utilde{X_1},...,\utilde{X_n}$ are i.i.d random vectors with common density $p_{\utilde{\theta_0}}(.).$ Then, for any fixed vector $\utilde{h} \in \mathbb{R}^d$, one may write 

$$
\int \bigg[\sqrt{n} \bigg(\sqrt{p_{\utilde{\theta} + n^{-1/2}\utilde{h}}} - \sqrt{p_{\utilde{\theta}}} \bigg) - \frac{1}{2}\utilde{h}^T\ell_{\utilde{\theta_0}}^{\circ}\sqrt{p_{\utilde{\theta_0}}} \bigg]^2 d\nu \rightarrow 0.
$$

Then, under these conditions and that there exists a $\ell_{\utilde{\theta_0}}^{\circ}$ which satisfies $L_2-$differentability, we have that 
\begin{enumerate}
\item $E(\ell_{\utilde{\theta_0}}^{\circ}(\utilde{X_i})) = \utilde{0}$
\item The matrix $\utilde{J} = \utilde{J}(\utilde{\theta_0} = E\big[\ell_{\utilde{\theta_0}}^{\circ}(\utilde{X_i}).\ell_{\utilde{\theta_0}}^{\circ}(\utilde{X_i})^T \big]$ exists
\item The LAN property holds at $\utilde{\theta_0}$ with score vector 
$$
S_n = \frac{1}{\sqrt{n}}\sum_{i=1}^{n}\ell_{\utilde{\theta_0}}^{\circ}(\utilde{X_i})
$$
and information matrix $\utilde{J}.$
\end{enumerate}
\end{theorem_exam} 

\begin{remark}Note that the information matrix is not necessarily the expectation of the Hessian matrix of the score vector.
\end{remark}

Hence, in order for the LAN property to hold, we only require that the map of the square root of the family of densities is $L_2$-differentiable. 

\lecture{18}{RAJN Estimators}
\section{Optimality of estimators}
\section{Optimality of estimators}
\textit{In this lecture, we describe what regular and AJN estimators are. We also show additional assumptions we require on top of LAN in order to derive AJN estimators. This restrictive assumption of an estimator being AJN with the scores is the main assumption that will allow us to derive much of theory in the next few sections. This leads us to have a new formulation of Le Cam's third lemma. We then see that RAJN estimators are analogous to unbiased estimators in the Cramr-Rao setting. Finally, we show that we can always decompose a RAJN estimator to its prediction component and extra estimation error.}
\subsection{Regular Estimators}

\begin{definition}(Stochastic convergence). Let $Y_n$ be a random sequence. The random sequence is $o_p(1)$ if $Y_n \xrightarrow{P} 0$ as $n \rightarrow \infty.$ The random sequence is $O_p(1)$ if for every $\epsilon > 0$, there exists a constant M such that $lim_{n \rightarrow \infty}P(|Y_n| > M) < \epsilon$ as $n \rightarrow \infty.$
\end{definition}  

In our local asymptotic framework, we are interested in finding something analogous to unbiased estimators.

\begin{definition}(Translation-invariant property). An estimator $\hat{\theta}_n$ has a translation property if the estimation error $\hat{\theta}_n - \theta$ has a distribution \textbf{not} depending on $\theta.$
\end{definition}

\begin{remark}If an estimator has the translation invariance property then the estimation error is the same no matter what value of $\theta$ is.
\end{remark}

\begin{definition_exam}{Regular Estimator}{}An estimator $\hat{\utilde{\theta_n}}$ is regular if it locally asymptotically behaves like a translation-invariant location parameter estimator. That is if
$$
\sqrt{n}(\hat{\utilde{\theta_n}} - \utilde{\theta_0}) \xrightarrow{d} \mathcal{N}(\utilde{0}, \utilde{\Sigma}(\utilde{\theta_{0}}))
$$
under $\utilde{\theta_0}$, then for any $\utilde{h} \in \mathbb{R}^d$, writing $\utilde{\theta_n}(\utilde{h}) = \utilde{\theta_0} + n^{-1/2}\utilde{h}$, the estimation error for any nearby sequence has the same limiting distribution regardless of $\utilde{h}$ 
$$
\sqrt{n}(\hat{\utilde{\theta_n}} - \utilde{\theta_{n}}(\utilde{h})) \xrightarrow{d} \mathcal{N}(\utilde{0}, \utilde{\Sigma}(\utilde{\theta_0})).
$$
That is, the asymptotic distribution of the estimation error possibly depends on $\utilde{\theta_0}$ but does not depend on the local deviation $\utilde{h}.$ 
\end{definition_exam}

\begin{remark}
As we move the nearby alternative $\utilde{\theta_n}$ around near the true parameter $\utilde{\theta_0}$, the distribution of the estimator error moves with $\utilde{\theta_n}$ but only in its location. The shape and spread does not change.
\end{remark}

\begin{corollary} Moment and quantile estimators are typically regular estimators.
\end{corollary}

Establishing regular estimators allows us to rule out pathological estimators such as Hodge's estimator.

\subsection{Scores version of Le Cam's 3rd Lemma}
We are now interested in restricting our attention to statistics $\utilde{Y_n}$ such that 
$$
\utilde{Y_n} \xrightarrow{d} \mathcal{N}(0, \Sigma_Y).
$$
From this, we can apply Le Cam's 3rd lemma to this after making the extra assumption that $\utilde{Y_n}$ is asymptotically jointly normal with the log likelihood ratio $L_n.$

\begin{proposition}(Alternative limiting distribution of statistic). 
Suppose we have a model where the LAN property holds at $\utilde{\theta_0}$ for some score vector $\utilde{S_n}$ and information matrix $\utilde{J}.$ Suppose a statistic vector $\utilde{Y_n}$ is such that under the true parameter $\utilde{\theta_0}$ for every vector $\utilde{h} \in \mathbb{R}^d$

\begin{equation}
\begin{pmatrix}
\utilde{Y_n}\\
L_n(\utilde{h})
\end{pmatrix}
 \xrightarrow{d} \mathcal{N}
\bigg( 
\begin{pmatrix}
0 \\
-\frac{1}{2}\utilde{h}^T\utilde{J}\utilde{h}
\end{pmatrix}
,
\begin{pmatrix}
\Sigma_Y & \sigma_{YL}(\utilde{h}) \\
\sigma_{YL}^T(\utilde{h}) & \utilde{h}^T\utilde{J}\utilde{h}
\end{pmatrix}
\bigg) \tag{*}
\end{equation}
where $L_n$ is the log likelihood ratio. Now, applying Le Cam's third lemma, we get that under the nearbly alternative sequence $\utilde{\theta_0} + n^{-1/2}\utilde{h}$, the limiting joint distribution is
$$
\begin{pmatrix}
\utilde{Y_n}\\
L_n(\utilde{h})
\end{pmatrix}
 \xrightarrow{d} \mathcal{N}
\bigg( 
\begin{pmatrix}
\sigma_{YL}(\utilde{h}) \\
+\frac{1}{2}\utilde{h}^T\utilde{J}\utilde{h}
\end{pmatrix}
,
\begin{pmatrix}
\Sigma_Y & \sigma_{YL}(\utilde{h}) \\
\sigma_{YL}^T(\utilde{h}) & \utilde{h}^T\utilde{J}\utilde{h}
\end{pmatrix}
\bigg)
$$
\end{proposition}
\begin{remark} Here $\sigma_{YL}(\utilde{h})$ is the vector whose j-th element is the covariance $\beta$ in Le Cam's third lemma. This is a more restrictive assumption than LAN as we now require a $\utilde{Y_n}$ which is asymptotically jointly normal with $L_n.$
\end{remark}

\begin{remark} In fact, under random sampling, statistics of the form 
$$
\utilde{Y_n} = n^{-1/2}\sum k(z_i) + o_p(1)
$$
where k(Z) has mean zero and finite variance will satisfy both the condition of being asymptotically normal and having a joint limiting distribution with $L_n$ of the form of (*). In particular, sample moments, quantiles, and unbiased estimators satisfy this.
\end{remark}

From Le Cam's third lemma, we were able to derive the limiting local-alternative distribution of the statistic $\utilde{Y_n}$ extremely easy just from knowing its limiting distribution under the true parameter of interst. Then, recalling that under $\utilde{\theta_0}$, due to the LAN property, we have that the log likelihood ratio can be expressed as $$L_n(\utilde{h}) = \utilde{h}^T\utilde{S_n} - \frac{1}{2}\utilde{h}^T\utilde{J}\utilde{h} + o_p(1).$$ That is, the likelihood ratio is a linear combination of the scores. We can therefore replace $L_n(\utilde{h})$ with the first 2 terms on the right hand side. 

\begin{proposition}(Limiting joint distribution of likelihood ratio expressed with score vector).
The likelihood ratio is a linear combination of the scores, which implies that the limiting joint distribution of the vector
$$
\begin{pmatrix}
\utilde{Y_n}\\
L_n(\utilde{h}) + \frac{1}{2}\utilde{h}^T\utilde{J}\utilde{h}
\end{pmatrix}
$$
is the same as 
$$
\begin{pmatrix}
\utilde{Y_n}\\
\utilde{h}^T\utilde{S_n}
\end{pmatrix}
$$
\end{proposition}

We can therefore get a different formulation of the LAN property seen in (*) at the beginning of this section in terms of the scores vector that under $\utilde{\theta_0}$
\begin{equation}
\begin{pmatrix}
\utilde{Y_n}\\
\utilde{h}^T\utilde{S_n}
\end{pmatrix}
 \xrightarrow{d} \mathcal{N}
\bigg( 
\begin{pmatrix}
\utilde{0} \\ \utilde{0}
\end{pmatrix}
,
\begin{pmatrix}
\Sigma_Y & \sigma_{YL}(\utilde{h}) \\
\sigma_{YL}^T(\utilde{h}) & \utilde{h}^T\utilde{J}\utilde{h}
\end{pmatrix}
\bigg)
\tag{**}
\end{equation}

since under the LAN assumption, the score vector $\utilde{S_n} \xrightarrow{d} \mathcal{N}(\utilde{0}, \utilde{J}).$


We now make a quick detour. Sometimes, it is better to take transforms of random vectors in order to show convergence.

\begin{definition_exam}{Characteristic Function}{} Let $\utilde{X} \in \mathbb{R}^d$ be a random vector. Then, the characteristic function is defined by
$$
\psi(\utilde{t}) = \mathbb{E}[e^{i \utilde{t}^T\utilde{X}}]
$$
for $\utilde{t} \in \mathbb{R}^d.$
\end{definition_exam}

\begin{lemma}The Characteristic function always exists for a random vector.
\end{lemma}

\begin{lemma}The characteristic function $\psi(\utilde{t})$ is continuous and bounded for every $\utilde{t} \in \mathbb{R}^d.$
\end{lemma}

By the Portmanteau lemma, we can then show that convergence in characteristic function is equivalent to convergence in distribution.

\begin{theorem_exam}{Lvy's Continuity Theorem}{}If $\utilde{X}, \utilde{X_1}, \utilde{X_2}, ...$ are random vectors with respective characteristic functions $\psi, \psi_1, \psi_2, ...$, then $\utilde{X_n} \xrightarrow{d} \utilde{X}$ if and only if 
$$
\psi_n(\utilde{t}) \rightarrow \psi(\utilde{t})
$$
for all $\utilde{t} \in \mathbb{R}^d.$
\end{theorem_exam}

We can use Lvy's continuity theorem to show another important result.

\begin{proposition_exam}{Cramr-Wold Theorem} Let $\utilde{X} \in \mathbb{R}^d$ and $\utilde{X_1},...,\utilde{X_n} \in \mathbb{R}^d$ be random variables. Furthermore, let $\utilde{t} \in \mathbb{R}^d.$ Then 
$$
\utilde{X_n} \xrightarrow{d} \utilde{X}
$$
if and only if 
$$
\utilde{t}^T\utilde{X_n} \xrightarrow{d} \utilde{t}^T\utilde{X}
$$
for all $\utilde{t} \in \mathbb{R}^d.$
\end{proposition_exam}

So now let us revisit 
\begin{equation}
\begin{pmatrix}
\utilde{Y_n}\\
\utilde{h}^T\utilde{S_n}
\end{pmatrix}
 \xrightarrow{d} \mathcal{N}
\bigg( 
\begin{pmatrix}
\utilde{0} \\ \utilde{0}
\end{pmatrix}
,
\begin{pmatrix}
\Sigma_Y & \sigma_{YL}(\utilde{h}) \\
\sigma_{YL}^T(\utilde{h}) & \utilde{h}^T\utilde{J}\utilde{h}
\end{pmatrix}
\bigg)
\tag{**}
\end{equation}

\begin{lemma} The covariance matrix $\sigma_{YL}(\utilde{h})$ between the statistic $\utilde{Y}$ and log likelihood ratio is a linear function of $\utilde{h}.$ 
\end{lemma}

\begin{proof}
Suppose that $\begin{pmatrix}\utilde{Y}\\ \utilde{S} \end{pmatrix}$ is a multivariate normal distribution such that $\begin{pmatrix}\utilde{Y}\\ \utilde{h}^T\utilde{S} \end{pmatrix}$ has the exact multivariate distribution of equation (**) via the Cramer-Wold theorem. Then, we have that
 $$
 \sigma_{YL}(\utilde{h}) = \mathbb{E}[\utilde{Y}\utilde{S}^T\utilde{h}] = \Sigma_{YS}\utilde{h}
 $$
 where $\Sigma_{YS} = \mathbb{E}[\utilde{Y}\utilde{S}^T]$ is the cross-covariance.
\end{proof}

As a result of the Cramr-Wold theorem, the assumptions (*) and (**) are equivalent to the Augmented LAN property, which is where we now impose an additional assumption on the random vector $\utilde{Y_n}.$

\begin{theorem_exam}{Augmented LAN (LAN\#)}{}Suppose that the LAN property holds at $\utilde{\theta_0}$ for some score $\utilde{S_n}$ and information matrix $\utilde{J}$. Furthermore, assume that for some positive semi-definite matrix $\utilde{\Sigma_Y}$, the statistic vector $\utilde{Y_n}$ is jointly asymptotically normal with the scores
$$
\begin{pmatrix}
\utilde{Y_n}\\
\utilde{S_n}
\end{pmatrix}
\xrightarrow{d}
\mathcal{N}\bigg(\utilde{0}, 
\begin{pmatrix}
\utilde{\Sigma_Y} & \utilde{\Sigma_{YS}} \\
\utilde{\Sigma_{SY}} & \utilde{J}
\end{pmatrix}
 \bigg)
$$
under $\utilde{\theta_0}.$
\end{theorem_exam}

\begin{proof} We have shown that the under $\utilde{\theta_0},$ the limiting joint distribution of the statistic $\utilde{Y_n}$ and the shifted score $\utilde{h}^T\utilde{S_n}$ is given by 
$$
\begin{pmatrix}
\utilde{Y_n}\\
\utilde{h}^T\utilde{S_n}
\end{pmatrix}
 \xrightarrow{d} \mathcal{N}
\bigg( 
\begin{pmatrix}
\utilde{0}
\end{pmatrix}
,
\begin{pmatrix}
\Sigma_Y & \utilde{\Sigma_{YS}}\utilde{h} \\
\utilde{\Sigma_{SY}}\utilde{h} & \utilde{h}^T\utilde{J}\utilde{h}
\end{pmatrix}
\bigg)
$$
Let us denote the random vector of the target distribution
$$
\begin{pmatrix}
\utilde{Y}\\
\utilde{S}
\end{pmatrix}
\xrightarrow{d}
\mathcal{N}\bigg(\utilde{0}, 
\begin{pmatrix}
\utilde{\Sigma_Y} & \utilde{\Sigma_{YS}} \\
\utilde{\Sigma_{SY}} & \utilde{J}
\end{pmatrix}
 \bigg)
$$

Suppose that $\utilde{Y}$ has dimension c and $\utilde{S}$ has dimension d. Then, we have that for any vector $\utilde{g} \in \mathbb{R}^c$
$$
\begin{pmatrix}
\utilde{g} & 1
\end{pmatrix}
\begin{pmatrix}
\utilde{Y_n}\\
\utilde{h}^T\utilde{S_n}
\end{pmatrix} = \utilde{g}^T\utilde{Y_n} + \utilde{h^T}\utilde{S_n} \xrightarrow{d} \utilde{g^T}\utilde{Y} + \utilde{h^T}\utilde{S}
$$
However, this is equivalent to 
$$
\utilde{t}^T\begin{pmatrix}
\utilde{Y_n}\\
\utilde{h}^T\utilde{S_n}
\end{pmatrix} \xrightarrow{d}
\utilde{t}^T\begin{pmatrix}
\utilde{Y}\\
\utilde{h}^T\utilde{S}
\end{pmatrix}
$$
for all $\utilde{t} \in \mathbb{R}^{c + d}.$ Then, by the Cramr-Wold theorem, where $\utilde{t}^T\utilde{X_n} \xrightarrow{d} \utilde{t}^T\utilde{X}$ implies that $\utilde{X_n} \xrightarrow{d} \utilde{X}$, we have that 
$$
\begin{pmatrix}
\utilde{Y_n}\\
\utilde{S_n}
\end{pmatrix}
\xrightarrow{d}
\mathcal{N}\bigg(\utilde{0}, 
\begin{pmatrix}
\utilde{\Sigma_Y} & \utilde{\Sigma_{YS}} \\
\utilde{\Sigma_{SY}} & \utilde{J}
\end{pmatrix}
 \bigg)
$$
\end{proof}

\begin{remark}LAN\# is an assumption about the random statistic vector Y. LAN\# is the LAN property with the added condition that the statistic is also asymptotically jointly normal with the scores vector. The original form of Le Cam's third lemma described that the statistic is asymptotically jointly normal with the likelihood ratio. Restricting our analysis to statistics that satisfy LAN\# throughout the rest of this course will allow us to easily develop alot of new theory!
\end{remark}

We have now imposed another condition on top of LAN for the statistic $\utilde{Y_n}.$ It is worthwhile to note that the covariance matrix $\utilde{\Sigma_{Y}}$ does \textbf{not} need to have full-rank.


Using the augmented LAN assumption, we can deduce a new version of scores version of Le Cam's third lemma where we repeat the process we have just done for the nearby sequence $\utilde{\theta_0} + n^{1/2}\utilde{h}$.
\begin{proposition_exam}{Scores Version of Le Cam's Third Lemma}{}Suppose that LAN\# holds for the statistic $\utilde{Y_n}.$ Then, under a nearby alternative $\utilde{\theta_0} + n^{1/2}\utilde{h}$, we have that 
$$
\begin{pmatrix}
\utilde{Y_n}\\
\utilde{S_n}
\end{pmatrix}
\xrightarrow{d}
\mathcal{N}\bigg(
\begin{pmatrix}
\Sigma_{YS}\utilde{h}\\
\utilde{J}\utilde{h}
\end{pmatrix}
  ,
\begin{pmatrix}
\utilde{\Sigma_Y} & \utilde{\Sigma_{YS}} \\
\utilde{\Sigma_{SY}} & \utilde{J}
\end{pmatrix}
 \bigg)
$$
That is, the asymptotic mean of $\utilde{Y_n}$ is now a linear combination of $\utilde{h}$ given by $\utilde{\Sigma_{YS}}\utilde{h}$.
\end{proposition_exam}

\begin{proof} First, recall that from (**), we have that 
\begin{equation}
\begin{pmatrix}
\utilde{Y_n}\\
\utilde{h}^T\utilde{S_n}
\end{pmatrix}
 \xrightarrow{d} \mathcal{N}
\bigg( 
\begin{pmatrix}
\utilde{0} \\ \utilde{0}
\end{pmatrix}
,
\begin{pmatrix}
\Sigma_Y & \sigma_{YL}(\utilde{h}) \\
\sigma_{YL}^T(\utilde{h}) & \utilde{h}^T\utilde{J}\utilde{h}
\end{pmatrix}
\bigg)
\tag{**}
\end{equation}
under $\utilde{\theta_0}.$
\end{proof}

\begin{remark}We have rewritten Le Cam's third lemma in terms of the score function and as a result, we get more information because now, we see that the limiting mean of the statistic $\utilde{Y_n}$ is a linear combination of $\utilde{\Sigma_{SY}}.$
\end{remark}


\subsection{RAJN Estimators}

\begin{definition_exam}{Asymptotically Jointly Normal Estimator}{}We say that an estimator $\hat{\utilde{\theta_n}} = \hat{\utilde{\theta_n}}(\utilde{X_1},...,\utilde{X_n})$ is asymptotically jointly normal (AJN) with the scores $\utilde{S_i}$ at $\utilde{\theta_0}$ if the estimation error
$$
\utilde{Y_n} = \sqrt{n}(\hat{\utilde{\theta_n}} - \utilde{\theta_0})
$$
satisfies LAN\#. That is, under a nearby alternative $\utilde{\theta_0} + n^{1/2}\utilde{h}$, we have that 
$$
\begin{pmatrix}
\utilde{Y_n}\\
\utilde{S_n}
\end{pmatrix}
\xrightarrow{d}
\mathcal{N}\bigg(
\begin{pmatrix}
\Sigma_{YS}\utilde{h}\\
\utilde{J}\utilde{h}
\end{pmatrix}
  ,
\begin{pmatrix}
\utilde{\Sigma_Y} & \utilde{\Sigma_{YS}} \\
\utilde{\Sigma_{SY}} & \utilde{J}
\end{pmatrix}
 \bigg)
$$
\end{definition_exam}

\begin{remark}This essentially says that when the estimator is rescaled, it is asymptotically jointly normal with the scores vector.
\end{remark}

We now want to combine the 2 properties of regularity and AJN to derive a new class of estimators.


\begin{definition_exam}{RAJN Estimator}{} A RAJN estimator is an estimator that is both regular and asymptotically jointly normal with the scores.
\end{definition_exam}

\begin{theorem_exam}{RAJN Estimators are analogous to unbiased estimators}{} An estimator $\hat{\utilde{\theta_n}}$ is a RAJN estimator if and only if its rescaled estimation error has a limiting covariance matrix with the score vector equal to the identity matrix. That is, $\Sigma_{\utilde{Y S}} = \mathbb{I}$ where $\utilde{Y_n} = \sqrt{n}( \hat{\utilde{\theta_n}} - \utilde{\theta_n}) + \utilde{h}$.
\end{theorem_exam}

\begin{proof} Suppose $\hat{\utilde{\theta_n}}$ is a RAJN estimator. Then, due to the fact that is AJN, then under the nearby sequence $\utilde{\theta_n} = \utilde{\theta_0} + n^{-1/2}\utilde{h}$, we have that the estimation error is asymptotically normal 
$$
\sqrt{n}(\hat{\theta_n} - \utilde{\theta_n}) = \utilde{Y_n} - \utilde{h} \xrightarrow{d} \mathcal{N}\big(\utilde{\Sigma_{YS}}\utilde{h} - \utilde{h}, \utilde{\Sigma_Y} \big).
$$
However, as $\hat{\utilde{\theta_n}}$ is a regular estimator, we require that the limiting distribution to be free of $\utilde{h}$ under the alternative $\utilde{\theta_n}.$ This only holds if the cross-covariance of the estimation error and score vector
$$
\utilde{\Sigma_{YS}} = \mathbb{I}
$$
where $\mathbb{I}$ is the d-by-d identity matrix.
\end{proof}

\begin{remark}This property is directly analogous to the Cramer-Rao result that under regularity conditions where any unbiased estimator has covariance with the score function equal to one.
\end{remark}

Now, recall the correlation inequality.
\begin{definition}(Correlation Inequality). The correlation inequality between an unbiased estimator $\hat{\theta}$ and score function $\ell_{\theta}^{\circ}$ is 
$$
Cov_{\theta}[\hat{\theta}(\utilde{x}), \ell_{\theta}^{\circ}(\utilde{x})]^2 \leq Var_{\theta}(\hat{\theta}(\utilde{x})) Var_{\theta}(\ell_{\theta}^{\circ}(\utilde{x}))
$$
with equality if and only if $\hat{\theta}(\utilde{x})$ and $\ell_{\theta}^{\circ}(\utilde{x})$ are linearly related so that 
$$
\ell_{\theta}^{\circ}(\utilde{x}) = a_{\theta} + b_{\theta}\hat{\theta}(\utilde{x}).
$$
\end{definition}

Hence, we can now get an analogous asymptotic multivariate generalisations of the correlation inequality. 

\begin{theorem_exam}{Orthogonal Decomposition Theorem}{}Any estimator which is RAJN at $\utilde{\theta_0}$ has the representation 
$$
\hat{\utilde{\theta_n}} = \utilde{\theta_0} + n^{-1/2}\utilde{J}^{-1}\utilde{S_n} + n^{-1/2}\utilde{Z_n}
$$
under $\utilde{\theta_0}$. Alternatively, we can say that the estimation error for any RAJN estimator can be decomposed into a common component and an added on noise
$$
\sqrt{n}[\hat{\utilde{\theta_n}} - \utilde{\theta_0}] = \utilde{J^{-1}}\utilde{S_n} + \utilde{Z_n}
$$
where the extra estimation error $\utilde{Z_n}$ is asymptotically independent of the scores vector 
$$
\begin{pmatrix}
\utilde{Z_n}\\
\utilde{S_n}
\end{pmatrix}
\xrightarrow{d}
\mathcal{N}\bigg(\utilde{0}, \begin{pmatrix}
\Sigma_Y - \utilde{J}^{-1} & \utilde{0}\\
\utilde{0} & \utilde{I}
\end{pmatrix}
 \bigg)
$$
\end{theorem_exam}

\begin{proof} This follows from the Scores version of Le Cam's 3rd lemma after defining the statistic 
$$
\utilde{Y_n} = \sqrt{n}(\hat{\utilde{\theta_n}} - \utilde{\theta_0})
$$
and $$\utilde{Z_n} = \utilde{Y_n} - \utilde{J}^{-1}\utilde{S_n}$$ where the cross-covariance $\utilde{\Sigma_{YS}} = \mathbb{I}$ due to the RAJN estimator.

\end{proof}
\begin{remark}This result arises due to the estimator being both regular and AJN with the scores vector.
\end{remark}
The significance of the fact that the extra estimation noise is asymptotically independent of the scores is that we can then write 
$$
AVar\bigg( \sqrt{n}(\hat{\utilde{\theta_n}} - \utilde{\theta_0})\bigg) = AVar(\utilde{J^{-1}}\utilde{S_n}) + AVar(\utilde{Z_n})
$$
 So if we want to minimise the variance of the estimation error, we need $AVar(\utilde{Z_n}) = 0.$

In fact, we can see the orthogonal decomposition theorem as an asymptotic version of the Cramr-Rao lower bound 
$$
\utilde{Y_n} = n^{1/2}(\hat{\utilde{\theta_n}} - \utilde{\theta_n}) \xrightarrow{d} \mathcal{N}(\utilde{0}, \utilde{J}^{-1} + \Sigma_Z)
$$
where the best we can do is if $\Sigma_Z = \utilde{0}.$

From this, the best we can do is to not have the $n^{-1/2}\utilde{Z_n}$ term in our estimation error whilst every estimator has $\utilde{J^{-1}}\utilde{S_n}$ component. Hence, the best we can do to minimise the estimation error is to remove this term. This will lead to a new definition of optimality which we will investigate in the next section.

\lecture{19}{Asymptotically Efficient Estimators}
\section{Optimality}
\subsection{Asymptotically Efficient Estimators}
\textit{In this lecture, we now define what we mean by efficient estimators. We then introduce the regular scores assumption which assumes that the LAN property holds in an area and that the scores vectors are "differentiable". From this, we can then expand the class of estimators that are efficient. With this expansion of efficient estimators, we will look at how to construct efficient estimator starting from an arbitrary $\sqrt{n}-$consistent estimators. This will be of a form of a 1-step adjustment to turn our estimator into an asymptotically efficient estimator. That is, (near) roots of score equations can provide efficient estimates.}

We have described the class of RAJN estimators. We now want to know which of these RAJN estimators are the most optimal. This is analogous to what we have seen before whereby RAJN estimators are analogous to unbiased estimators. Furthermore, the estimators that are asymptotically efficient are analogous to unbiased estimators that have minimum variance through attaining the Cramr-Rao lower bound.
\begin{definition_exam}{Asymptotically Efficient Estimators}{}Let $\hat{\utilde{\theta_n}}$ be a RAJN estimator. Then $\hat{\utilde{\theta_n}}$ is asymptotically efficient (AE) at $\utilde{\theta_0}$ if it can be written as 
$$
\sqrt{n}(\hat{\utilde{\theta_n}} - \utilde{\theta_0}) = \utilde{J}^{-1}\utilde{S_n} + o_p(1).
$$
\end{definition_exam}

\begin{remark} Note that this follows from the orthogonal decomposition thereom where the extra noise error $Z_n$ is now $o_p(1)$
$$
\sqrt{n}[\hat{\utilde{\theta_n}} - \utilde{\theta_0}] = \utilde{J^{-1}}\utilde{S_n} + \utilde{Z_n}
$$
\end{remark}

\begin{theorem_exam}{Sufficient condition for RAJN estimator}{}Suppose the LAN property holds at $\utilde{\theta_0}$ with score vector $\utilde{S_n}$ and information matrix $\utilde{J}.$ Then, if we can write an estimator $\hat{\utilde{\theta_0}}$ in this form $$\sqrt{n}(\hat{\utilde{\theta_0}} - \utilde{\theta_0}) = \utilde{J}^{-1}\utilde{S_n} + o_p(1)$$ then $\hat{\utilde{\theta_0}} $ is a RAJN (regular, asymptotically jointly normal with the scores) estimator at $\utilde{\theta_0}$.
\end{theorem_exam}

\begin{proof} First, denote the estimation error $\utilde{Y_n} = \sqrt{n}(\hat{\utilde{\theta_0}} - \utilde{\theta_0}).$ Then, due to the LAN property, the joint behaviour with the scores is 
$$
\begin{pmatrix}
\utilde{Y_n}\\
\utilde{S_n}
\end{pmatrix}
= 
\begin{pmatrix}
\utilde{J^{-1}}\utilde{S_n} + o_p(1)\\
\utilde{S_n}
\end{pmatrix} = 
\begin{pmatrix}
\utilde{J^{-1}}\utilde{S_n}\\
\utilde{S_n}
\end{pmatrix} + o_p(1) \xrightarrow{d} \mathcal{N}\bigg(\utilde{0}, \begin{bmatrix}
\utilde{J^{-1}} & \utilde{I}\\
\utilde{I} & \utilde{J}\\
\end{bmatrix} \bigg)
$$
Hence, we have that $\hat{\utilde{\theta_n}}$ is AJN with the scores. Then, under a nearby sequence $\utilde{\theta_n} = \utilde{\theta_0} + n^{-1/2}\utilde{h},$ we have by the Scores version of Le Cam's third lemma 
$$
\utilde{Y_n} \xrightarrow{d} \mathcal{N}\bigg(\utilde{I}\utilde{h}, \utilde{J^{-1}} \bigg) = \mathcal{N}\bigg(\utilde{h}, \utilde{J^{-1}} \bigg)
$$
However, the estimation error $\utilde{Y_n} = \sqrt{n}(\hat{\utilde{\theta_0}} - \utilde{\theta_0})$ is under $\utilde{\theta_0}.$ Therefore, the estimation error under $\utilde{\theta_n}$ is 
$$
\sqrt{n}(\hat{\utilde{\theta_0}} - \utilde{\theta_n}) = \utilde{Y_n} - \utilde{h} \xrightarrow{d} \mathcal{N}(\utilde{0}, \utilde{J}^{-1})
$$
Hence, $\hat{\utilde{\theta_n}}$ is also a regular estimator.
\end{proof}

\begin{remark}It is AJN as it is asymptotically linear combination of the scores, which means it is AJN with the scores. It is regular because under nearby sequences $\utilde{S_n}$ enjoys a shift of $\utilde{h}.$
\end{remark}

\subsection{Construction of AE Estimators}
We now have a characterisation of optimal estimators for RAJN estimators. However, we can relax the conditions for the estimators if we impose additional assumptions on the model. That is, previously, the LAN property only held at a given point, whereby we will now extend the assumption that \textbf{the LAN property holds in an area near the point} $\utilde{\theta_0}.$

\begin{proposition}(Neighbourhood LAN property). We shall now assume that LAN holds for all $\utilde{\theta}$ in a neighbourhood of $\utilde{\theta_0}$ with scores $\utilde{S_n}(\utilde{\theta})$ and information matrix $\utilde{J} = \utilde{J}(\utilde{\theta})$ which now depends on $\utilde{\theta}.$
\end{proposition}

We now have that the scores $\utilde{S_n}(\utilde{\theta})$ and information $\utilde{J}(\utilde{\theta})$ is a function depending on $\utilde{\theta}.$ We shall now impose a new assumption on the scores vector in order to construct efficient estimators.

\begin{definition_exam}{Regular Scores Assumption}{}Assume that the LAN property holds in a neighbourhood of $\utilde{\theta_0}$. Then, under $\utilde{\theta_0}$ as the parameter value, we assume that we can write the scores vector as a function  $$\utilde{S_n}(\utilde{\theta_0} + n^{-1/2}\utilde{h}) = \utilde{S_n}(\utilde{\theta_0}) - \utilde{J}(\utilde{\theta_0})\utilde{h} + R_n(\utilde{\theta_0},\utilde{h})$$ where for any finite $0 < M < \infty$, under $\utilde{\theta_0}$, we have that
$$
\sup_{|h| \leq M}R_n(\utilde{\theta_0},\utilde{h}) \xrightarrow{p}0.
$$
We can therefore express the score vector as
$$\utilde{S_n}(\utilde{\theta_0} + n^{-1/2}\utilde{h}) = \utilde{S_n}(\utilde{\theta_0}) - \utilde{J}(\utilde{\theta_0})\utilde{h} + o_p(1)
$$
\textbf{uniformly in bounded h}.
\end{definition_exam}

\begin{remark}One way to interpret the regular scores assumption is that it is a smoothness assumption on the scores vector such that the scores vector is differentiabile in a probability sense.
\end{remark}

As we will see many times, the uniformly in bounded h assumption is needed for when we are plugging in a random $\utilde{h}.$ Recall that the ordinary LAN assumption only holds for a fixed $\utilde{h}.$ If we strengthen it to uniformly bounded $\utilde{h},$ then we can plug in a random variable instead of a fixed $\utilde{h}$ and the analogous property still holds. This is tied in to the idea of neighbourhood LAN property as when we start constructing estimators and test statistics, the score vector will be evaluated at a random value of the parameter. When we need to evaluate the scores at a non-fixed parameter, then the LAN assumption alone is not enough. This regular scores assumption allows us to define $\utilde{S_n}$ in a neighbourhood of $\utilde{\theta_0}.$ Therefore, the regular score can be thought of as an expansion of the score vector in the neighbourhood of $\utilde{\theta_0}.$


\begin{corollary}Under the regular scores assumption, the scores vector has derivatives with respect to $\utilde{\theta}$ "in probability" and these are the elements of the information matrix $-\utilde{J}(\utilde{\theta_0}).$
\end{corollary}

Now, under the regular scores assumption, we are actually now able to broaden the class of estimators  from the class of RAJN estimators that are asymptotically efficient.

\begin{definition}(Bounded in probability). An estimator $\tilde{\utilde{\theta_n}}$ is said to be bounded in probability if for all $\epsilon > 0$, there exists $0 < M_{\epsilon} < \infty$ such that 
$$
\lim_{n \rightarrow \infty}\sup \prob_{\utilde{\theta_0}}\bigg(|\sqrt{n}(\tilde{\utilde{\theta_n}} - \utilde{\theta_0})| > M_{\epsilon} \bigg) \leq \epsilon.
$$
\end{definition}

\begin{remark}Having an estimator bounded in probability means that the mass of a distribution does not flow off to $\infty.$
\end{remark}

We define a broader class of estimators.

\begin{definition_exam}{$\sqrt{n}-$consistent estimators}{}An estimator $\tilde{\utilde{\theta_n}}$ is said to be $\sqrt{n}-$consistent at $\utilde{\theta_0}$ if 
$$
\sqrt{n}(\tilde{\utilde{\theta_n}} - \utilde{\theta_0}) = O_p(1)
$$
where $O_p(1)$ is bounded in probability.
\end{definition_exam}

\begin{remark}Recall that consistent estimators are those that converges to the parameter. $\sqrt{n}-$consistent specifies the rate at which it converges to the parameter.
\end{remark}

\begin{proposition_exam}{Sufficient conditions for $\sqrt{n}-$consistent estimators}{}All regular estimators and all AJN estimators are $\sqrt{n}-$consistent.
\end{proposition_exam}

However, a $\sqrt{n}$-consistent estimator need not be regular or AJN.

\begin{theorem_exam}{Expression of the score function for $\sqrt{n}-$consistent estimators}{}Suppose the regular scores assumption holds at $\utilde{\theta_0}.$ Then, any $\sqrt{n}-$consistent estimator $\tilde{\utilde{\theta_n}}$ satisfies 
$$
S_n(\tilde{\utilde{\theta_n}}) = S_n(\utilde{\theta_0}) - J(\utilde{\theta_0})\sqrt{n}(\tilde{\utilde{\theta_n}} - \utilde{\theta_0}) + o_p(1)
$$
under $\utilde{\theta_0}.$
\end{theorem_exam}

\begin{remark}Recall the regular scores assumption
$$\utilde{S_n}(\utilde{\theta_0} + n^{-1/2}\utilde{h}) = \utilde{S_n}(\utilde{\theta_0}) - \utilde{J}(\utilde{\theta_0})\utilde{h} + o_p(1)
$$
We replace $\utilde{h}$ with $\sqrt{n}(\tilde{\utilde{\theta_n}} - \utilde{\theta_0})$ to get 
$$\utilde{S_n}(\utilde{\theta_0} + n^{-1/2}\sqrt{n}(\tilde{\utilde{\theta_n}} - \utilde{\theta_0})) = \utilde{S_n}(\utilde{\theta_0}) - \utilde{J}(\utilde{\theta_0})\sqrt{n}(\tilde{\utilde{\theta_n}} - \utilde{\theta_0}) + o_p(1)
$$
$$
S_n(\tilde{\utilde{\theta_n}}) = S_n(\utilde{\theta_0}) - J(\utilde{\theta_0})\sqrt{n}(\tilde{\utilde{\theta_n}} - \utilde{\theta_0}) + o_p(1)
$$
\end{remark}

We come to an important corollary.
\begin{proposition_exam}{$\sqrt{n}-$consistent estimators are RAJN and A.E. under certain conditions}{}Suppose that the regular scores assumption holds, the estimator $\tilde{\utilde{\theta_n}}$ is $\sqrt{n}-$consistent, and the scores evaluated at that estimator $\tilde{\utilde{\theta_n}}$ has the property that
$$
\utilde{S_n}(\tilde{\utilde{\theta_n}}) \xrightarrow{p} 0.
$$
Then, $\tilde{\utilde{\theta_n}}$ is a RAJN estimator and A.E.
\end{proposition_exam}

\begin{proof} By the theorem for the expression of the score function for $\sqrt{n}-$estimators, we have that under $\utilde{\theta_0}$
$$
S_n(\tilde{\utilde{\theta_n}}) = S_n(\utilde{\theta_0}) - J(\utilde{\theta_0})\sqrt{n}(\tilde{\utilde{\theta_n}} - \utilde{\theta_0}) + o_p(1)
$$

$$
\sqrt{n}(\tilde{\utilde{\theta_n}} - \utilde{\theta_0}) = J(\utilde{\theta_0})^{-1}\bigg[S_n(\utilde{\theta_0}) - S_n(\tilde{\utilde{\theta_n}}) \bigg] + o_p(1)
$$
Then, as $\utilde{S_n}(\tilde{\utilde{\theta_n}}) \xrightarrow{p} 0$
$$
\sqrt{n}(\tilde{\utilde{\theta_n}} - \utilde{\theta_0}) = J(\utilde{\theta_0})^{-1}S_n(\utilde{\theta_0}) + o_p(1)
$$
where recall this expression by definition is the meaning for an estimator to be asymptotically efficient and a sufficient condition for an estimator to be a RAJN estimator.
\end{proof}

\begin{proposition_exam}{All roots to score equations are asymptotically efficient}{}Under the regular scores assumption, any solution $\hat{\utilde{\theta_n}}$ to the score equation 
$$
\utilde{S_n}(\hat{\utilde{\theta_n}}) = \utilde{0}
$$
is asymptotically efficient.
\end{proposition_exam}

\begin{remark}Maximum likelihood estimators are not always optimal. However, if the regular scores assumption holds, which implies that LAN holds, then MLE is optimal. That is, the scores function evaluated at the MLE estimate is 0. Therefore, this shows that the MLE estimate is asymptotically efficient.
\end{remark}

Now, we have the question of what to do if the regular scores assumption holds, we have a $\sqrt{n}-$consistent estimator $\tilde{\utilde{\theta_n}}$ \textbf{but} the score equation evaluated at $\tilde{\utilde{\theta_n}}$ is not zero, i.e. $
\utilde{S_n}(\tilde{\utilde{\theta_n}}) \neq \utilde{0}.
$

What we can do is, under certain conditions, take our $\sqrt{n}-$consistent estimator $\tilde{\utilde{\theta_n}}$ and transform it such that the score equation will be zero and therefore the estimator will be RAJN and asymptotically efficient.

We first describe the condition needed to do this.

\begin{proposition_exam}{Continuous Information Condition}{} The LAN property holds in a neighbourhood of $\utilde{\theta_0}$ with information matrix $J(\utilde{\theta})$ being continuous at $\utilde{\theta_0}.$ That is, $\utilde{J}^{-1}(\utilde{\theta_0})$ exists.
\end{proposition_exam}

\begin{remark} Recall that $X_n \xrightarrow{p} \mu$ and if g(.) is a continuous function, then $g(X_n) \xrightarrow{p} g(\mu).$ Hence, if we have that $\tilde{\utilde{\theta_n}} \xrightarrow{p} \utilde{\theta_0}$ and if $J(.)$ is continuous at $\utilde{\theta_0}$ then we have that 
$$
J(\tilde{\utilde{\theta_n}}) \xrightarrow{p} J(\utilde{\theta_0})
$$
 This will allow for us to justify our estimates of the information matrix.
\end{remark}

We come to the main theorem of the lecture on how to construct asymptotically efficient estimators from $\sqrt{n}-$consistent estimators.
\begin{theorem_exam}{A.E Construction Theorem}{}Suppose that the regular scores assumption and the continuous information condition both hold at $\utilde{\theta_0}.$ Then, if $\tilde{\utilde{\theta_n}}$ is a $\sqrt{n}-$consistent estimator, the new estimator 
$$
\hat{\utilde{\theta_n}} = \tilde{\utilde{\theta_n}} + n^{-1/2}\utilde{J}^{-1}(\tilde{\utilde{\theta_n}})\utilde{S_n}(\tilde{\utilde{\theta_n}})
$$
is asymptotically efficient.
\end{theorem_exam}
\begin{remark} As the estimator is asymptotically efficient, it is also a RAJN estimator.
\end{remark}

\begin{proof} Assume that the regular scores assumption holds. We have that every asymptotically efficient estimator $\hat{\utilde{\theta_n}}$ satisfies 
$$
\hat{\utilde{\theta_n}} = \utilde{\theta_0} + n^{-1/2}\bigg(\utilde{J}^{-1}(\utilde{\theta_0})\utilde{S_n}(\utilde{\theta_0}) + o_p(1)  \bigg)
$$
As $\tilde{\utilde{\theta_n}}$ is a $\sqrt{n}-$consistent estimator, we can express any $\sqrt{n}-$consistent estimator as 
$$
\tilde{\utilde{\theta_n}} = \utilde{\theta_0} + n^{-1/2}\bigg(\utilde{J}(\utilde{\theta_0})^{-1}[\utilde{S_n}(\utilde{\theta_0}) - \utilde{S_n}(\tilde{\utilde{\theta_n}})] \bigg)
$$
Plugging this into our expression for the asymptotically efficient estimator expression, we get that 
$$
\hat{\utilde{\theta_n}} = \tilde{\utilde{\theta_n}} + n^{-1/2}\bigg(\utilde{J}^{-1}(\utilde{\theta_0})\utilde{S_n}(\tilde{\utilde{\theta_n}}) + o_p(1)  \bigg)
$$

Then, under the continuous information condition, we can replace $\utilde{\theta_0}$ by $\tilde{\utilde{\theta_n}}$ and therefore get that 
$$
\hat{\utilde{\theta_n}} = \tilde{\utilde{\theta_n}} + n^{-1/2}\utilde{J}^{-1}(\tilde{\utilde{\theta_n}})\utilde{S_n}(\tilde{\utilde{\theta_n}})
$$
\end{proof}

That is, if we have any $\sqrt{n}-$consistent estimator that is not optimal, we can turn it into an optimal estimator through a 1-step transformation process.

\lecture{20}{Newton-Raphson Algorithm}
\section{Optimality}
\subsection{Newton-Raphson Algorithm}
\textit{In this lecture, we descibe the Newton-Raphson algorithm as a method to optimise an intractible log likelihood. We then show that a one-step update using the Newton-Raphson algorithm under certain conditions yields an asymptotically efficient estimator of the parameter. We then describe the process for identifying whether an estimator is RAJN by checking whether is it an asymptotically linear estimator. Finally, we look at estimators based on moments and quantiles and see such methods are asymptotically linear and hence RAJN estimators.}


We are now interested in making the link between maximum likelihood estimators and our current framework of LAN. In particular, this relates to the Newton-Raphson method.

\begin{definition}
Let $p_{\utilde{\theta}}$ be a density function. Then, the log likelihood is defined to be 
$$
\Lambda_n(\utilde{\theta}) = \sum_{i=1}^{n}log\;p_{\utilde{\theta}}(\utilde{X_i})
$$
\end{definition}

Unfortunately, for many models in practice, the maximiser of $\Lambda_n$ is not available in closed form. Therefore, we need to maximize  $\Lambda_n$ numerically using an optimisation algorithm. The Newton-Raphson algorithm is one way to do this.

\begin{proposition_exam}{Newton-Raphson Method}{}Let $\Lambda_n(\utilde{\theta})$ be the log likelihood of the density of interest. The Newton-Raphson method looks for a solution to the score equations 
$$
\utilde{\Lambda_n}^{'}(\utilde{\theta}) = \utilde{0}
$$
where $\utilde{\Lambda_n}^{'}(\utilde{\theta})$ is a vector of partial derivatives with respect to $\utilde{\theta}.$

Then, the method requires an initial starting value $\utilde{\theta_0}$. Then, our update rule from $\utilde{\theta_{i}}$ to $\utilde{\theta_{i+1}}$ is given by 
$$
\utilde{\theta_{i+1}} = \utilde{\theta_{i}} - \utilde{\Lambda_{n}}^{''}(\utilde{\theta_i})^{-1}\utilde{\Lambda_{n}}^{'}(\utilde{\theta_{i}})
$$
where $\utilde{\Lambda_{n}}^{''}$ is the matrix of second order partial derivatives with respect to $\utilde{\theta}.$
\end{proposition_exam}

Therefore, in the Newton-Raphson method, we have a score function $\utilde{\Lambda_n}^{'}(\utilde{\theta})$ and we seek to find the root of the score function. In the 1D case, we update the rule based on the tangent line at the current point we are at and see where does the tangent line intersect the x-axis.

Now, it is interesting to note that the Newton-Raphson method looks similar to our 1-step update construction of asymptotically efficient estimator except that instead of the inverse of the information matrix, we have the second derivative of the log likelihood.

However, in nice smooth models, the second derivatives of the log likelihood is close to the inverse of the information matrix. This gives us the connection between the Newton-Raphson method and 1-step update rule to construct asymptotically efficient estimators.

\begin{theorem_exam}{Newton-Raphson One-Step Theorem}{}Assume that for all $\utilde{\theta}$ in a neighbourhood of $\utilde{\theta_0}$
\begin{enumerate}
\item $\Lambda_n(.)$ is twice-differentiable;
\item The LAN property holds with the scores 
$$
\utilde{S_n}(\utilde{\theta}) = n^{-1/2}\utilde{\Lambda_n}^{'}(\utilde{\theta})
$$
\item The information matrix $\utilde{J}(\utilde{\theta})$ is such that 
$$
n^{-1}\utilde{\Lambda_n}^{''}(\utilde{\theta_0} + n^{-1/2}\utilde{h}) = -\utilde{J}(\utilde{\theta_0}) + o_p(1)
$$
uniformly bounded in $\utilde{h}.$
\end{enumerate}
Then, the regular score assumption holds. Furthermore, the one-step Newton-Raphson update to any RAJN estimator $\tilde{\utilde{\theta_n}}$ given by the Newton-Raphson update 
$$
\hat{\utilde{\theta_n}} = \tilde{\utilde{\theta_n}} - \utilde{\Lambda_n}^{''}(\tilde{\utilde{\theta_n}})^{-1}\utilde{\Lambda_n}^{'}(\tilde{\utilde{\theta_n}})
$$
is asymptotically efficient.
\end{theorem_exam}
\begin{remark}
What we have shown is that we can replace the $ \utilde{\Lambda_n}^{''}$ with $-\utilde{J}(\utilde{\theta_{0}})$, which gives us the 1-step update for asymptotically efficient estimator formula.
\end{remark}

\begin{remark}It can be quite tricky to verify these assumptions. However, if we are able to show the restrictive conditions for LAN property to hold, which is alot easier to show, then all the assumptions required for the Newton-Raphson One-step theorem holds too.
\end{remark}

Note that the Newton-Raphson one step theorem \textbf{does not say} that we only need one step to be at the maximum. Instead, it says that for large samples, taking one step gives us an estimator that is asymptotically efficient, that is, asymptotically, it has the smallest variance. Therefore, we don't have to be at the maximum to be asymptotically efficient estimator, we just need to be near the maximum.


\subsection{Identifying RAJN Estimators}
We have introduced the class of regular and asymptotically joint normal with the scores estimators. Now, we are interested in how can we verify that a given estimator is regular or AJN?

We will now introduce a more restrictive class of estimators known as asymptotically linear estimators.

\begin{definition_exam}{Asymptotically Linear Estimators}{}Suppose $\utilde{X_1},...,\utilde{X_n}$ are i.i.d random vectors with common distribution $\prob_{\utilde{\theta_0}}$ for some family of densities $\{p_{\utilde{\theta}}: \utilde{\theta} \in \utilde{\Theta}\}$ for $\utilde{\Theta} \subseteq \mathbb{R}^d.$ An estimator $\tilde{\utilde{\theta_n}}(\utilde{X_1},...,\utilde{X_n})$ is said to be \textbf{asymptotically linear (A.L)} if there exists a vector of functions $\utilde{g}(\utilde{x}; \utilde{\theta})$ such that under $\utilde{\theta_0}$ 
\begin{enumerate}
\item The function has mean zero $\mathbb{E}[\utilde{g}(\utilde{x}; \utilde{\theta_0})] = 0;$
\item The function has finite variance $\mathbb{E}[\utilde{g}(\utilde{x}; \utilde{\theta_0})^2] < \infty;$
\item We can express the estimation error of the estimator $\tilde{\utilde{\theta_n}}$ as a sum of the function $$\utilde{Y_n} = \sqrt{n}(\tilde{\utilde{\theta_n}} - \utilde{\theta_0}) = \frac{1}{\sqrt{n}}\sum_{i=1}^{n}\utilde{g}(\utilde{x_i}; \utilde{\theta_0}) + o_p(1)$$
\end{enumerate}
where $\utilde{g}(\utilde{x}; \utilde{\theta_0})$ is called the \textbf{influence function} of the estimator. 
\end{definition_exam}
\begin{remark}
In condition 3, we can interpret the asymptotic behaviour of the estimator is dominated by the sum of the influence function.
\end{remark}

Now, suppose that $\tilde{\utilde{\theta_n}}$ is an asymptotically linear estimator. Then, if the LAN property holds and the score vector is of the form 
$$
\utilde{S_n}(\utilde{\theta_0}) = n^{-1/2}\sum_{i=1}^{n}\utilde{\ell_{\utilde{\theta_0}}}^{\circ}(\utilde{X_i})
$$
then, we have that 
$$
\begin{pmatrix}
\utilde{Y_n}\\
\utilde{S_n}
\end{pmatrix}
= n^{-1/2}
\sum_{i=1}^{n}
\begin{pmatrix}
\utilde{g}(\utilde{x}; \utilde{\theta_0})\\\\
\utilde{\ell}_{\utilde{\theta_{0}}}^{\circ}(\utilde{x_i}; \utilde{\theta_0})
\end{pmatrix}
+
o_p(1)
$$
is an asymptotically normal random-vector using the multivariate central limit theorem. That is, $\tilde{\utilde{\theta_n}}$ is a RAJN estimator. Furthermore, it is important to note that a statistic that is asymptotically linear satisfies Scores version of Le Cam's third lemma.

From this, we have the big takeaway.

\begin{proposition_exam}{A.L. estimators are RAJN}{}An estimator that is asymptotically linear is a RAJN estimator.
\end{proposition_exam}



\begin{proposition}Method of moment estimators are RAJN estimators.
\end{proposition}

\subsection{Estimators based on moments and quantiles}
Many estimators can be written as smooth functions of sample quantiles or sample averages. We can use the delta method in probability and other techniques to show that estimators based on averages, under smoothness conditions, are RAJN by showing that the estimator is asymptotically linear.

We can use similar techniques that estimators based on quantiles are also regular. However, it can be difficult to show that estimators based on quantiles are AJN. Therefore, we will introduce tools to help us show that quantiles are asymptotically linear.


These tools are revolve around the osallations of the uniform empirical CDF.

\begin{definition}(Empirical CDF). Suppose that $U_1,...,U_n$ are i.i.d $U(0,1)$ random variables. Define the empirical CDF as 
$$
G_n(u) = \frac{1}{n}\sum_{i=1}^{n}1\{U_i \leq u\}.
$$
\end{definition}

\begin{definition_exam}{Empirical Process}{}Let $G_n(u)$ be the empirical CDF. Then, the \textbf{empirical process} is defined as 
$$
H_n(u) = \sqrt{n}(G_n(u) - u).
$$
\end{definition_exam}

\begin{remark}The empirical process is a centered version of the empirical CDF.
\end{remark}

The empirical process will be our influence function to show that quantile estimators are asymptotically linear.

The empirical CDF $G_n(u)$ can be interpreted as a step function with jumps of height $\frac{1}{n}$ which gets smaller and smoother as $n \rightarrow \infty.$

\begin{lemma}Let $G_n$ be the empirical CDF. Then, for a fixed u, we have that
$$
n.G_n(u) = \sum_{i=1}^{n}1\{U_i \leq u\} \sim Bin(n,u).
$$
\end{lemma}

\begin{corollary}Let $G_n$ be the empirical CDF and $H_n$ the corresponding empirical process. Then 
$$
\mathbb{E}[H_n(u)] = 0
$$
$$
Var[H_n(u)] = u(1 - u)
$$
not depending on n.
\end{corollary}

As the empirical CDF gets smoother as we increase n, we are now interested in measuring the smoothness of function. We define a measure of how to measure the smoothness of a function.

\begin{definition_exam}{Modulus of continuity (osallation)}{}The modulus of continuity is a measure of smoothness for a given empirical process $H_n$ defined as 
$$
\omega_n(\Delta) = \sup_{|u - v| = \Delta}|H_n(u) - H_n(v)|
$$
for a fixed window of width $\Delta.$
\end{definition_exam}

\begin{remark}The intuition behind the modulus of continuity is that if we have a fixed window and we move it over the function, what is the biggest difference that we see? In particular, if our function is smooth. the modulus of continuity should tend to zero as the window width $\Delta \rightarrow 0.$
\end{remark}

However, it may be tricky to analyse our empirical CDF as it is a random function and it has steps. Therefore, we let both $n \rightarrow \infty$ but shrink the window size $\Delta \rightarrow 0$ at a certain rate.

\begin{proposition}For any $0 < C < \infty$, 
$$
\omega_n(Cn^{-1/2}) \xrightarrow{p} 0.
$$
That is, the modulus of continuity of the sequence $Cn^{-1/2}$ tends to probability in zero if we let the $\Delta_n$ shrink to zero at the rate of $n^{-1/2}.$
\end{proposition}

\begin{corollary}Define the remainder of 2 nearby values of the empirical CDFs
$$
R_n(h;u) = \sqrt{n}\bigg[G_n(u + n^{-1/2}h) - G_n(u) \bigg] - h.
$$
For any fixed u, we have that 
$$
\sup_{|h| \leq M}|R_n(h;u)| \xrightarrow{p} 0.
$$
That is,
$$
\sqrt{n}(G_n(u + n^{-1/2}h) - G_n(u)) = h + O_p(1)
$$
uniformly in bounded h.
\end{corollary}

We now state that we can approximate an order statistic by the value of the empirical process.

\begin{theorem_exam}{Rescaled order statistic}{}Let $U_{(A_{n})}$ be an order statistic. Then 
$$
\sqrt{n}\bigg[U_{(A_{n})} - p \bigg] = H_n(p) + O_p(1).
$$
\end{theorem_exam}
We can now state that the order statistic is an asymptotically linear estimator.

\begin{corollary}If $\sqrt{n}(\frac{a_n}{n + 1} - p) \rightarrow 0$, then the order statistic $U_{(a_{n})}$ is an A.L. estimator of p with influence function 
$$
g(u) = 
\begin{cases}
p - 1 \quad u \leq p \\
p \quad u > p
\end{cases}
$$
\end{corollary}

\begin{remark}If we do a transformation to another distribution, the order statistic from any other distribution is an A.L. estimator of that population's p-th quantile using the delta method.
\end{remark}

Now, we will state the Delta method. In particular, the Delta method consists of using a Taylor expansion to approximate the random vector $f(X_n)$ with a polynomial. 

\begin{proposition}(Delta method). If we have that $\sqrt{n}(X_n - c) \xrightarrow{d} Y$ then we have that 
$$
\sqrt{n}(f(X_n) - f(c)) \xrightarrow{d} f^{'}(c)Y.
$$
\end{proposition}

\begin{proposition_exam}{Delta Method in probability}{}Let $X_n \xrightarrow{p} C$ and $\lim_{x \rightarrow C}g(x) = \ell.$ Then, we have that 
$$
g(X_n) \xrightarrow{p} \ell.
$$
\end{proposition_exam}

\lecture{21}{Efficient Influence Function}
\section{Optimality}
\subsection{Efficient Influence Function}
\textit{In this lecture, we analyse asymptotically linear estimators through their influence functions. From this, we can define what an efficient influence function is. We then introduce parameter estimation when we have nuisance parameters involved in the model. We then revisit previous results on Scores Version of Le Cam's third lemma involving nuisance parameters. From this, we can see that RAJN estimators are asymptotically independent of the nuisance parameters. Additionally, we can also see that asymptotically efficient estimators involving nuisance parameters can be constructed through a 1-step rule.}


We have shown that an estimator that is asymptotically linear is a way to show that an estimator is a RAJN estimator. In particular, an estimator is asymptotically linear if it is dominated by the sum of influence functions. Hence, understanding how the influence functions behave gives insights into the asymptotically linear estimators.

First, let us assume that the LAN property holds at $\utilde{\theta_0}$ with the scores function $\utilde{S_n}(\utilde{\theta_0}) = n^{-1/2}\sum_{i=1}^{n}\utilde{\ell}_{\utilde{\theta_0}}^{\circ}$ and information matrix $\utilde{J}(\utilde{\theta_0}).$  Furthermore, assume that we have an estimator $\hat{\utilde{\theta_n}}$ that satisfies 
$$
\sqrt{n}(\hat{\utilde{\theta_n}} - \utilde{\theta_0}) = \utilde{J}^{-1}(\utilde{\theta_0})\utilde{S_n}(\utilde{\theta}) + o_p(1).
$$

Then, we can conclude that $\hat{\utilde{\theta_n}}$ is asymptotically efficient estimator, and also a RAJN estimator at $\utilde{\theta_0}.$ Furthermore, it is also asymptotically linear estimator. 

\begin{definition_exam}{Efficient Influence Function}{}
We define the efficient influence function
$$
g = \utilde{J}^{-1}\utilde{\ell}_{\utilde{\theta_{0}}}^{\circ}
$$
for estimating $\utilde{\theta}$ at $\utilde{\theta_0}.$
\end{definition_exam}
\begin{proof} Recall condition 3 needed for the influence function $\utilde{g}(\cdot, \utilde{\theta})$ that
$$
\utilde{Y_n} = \sqrt{n}(\tilde{\utilde{\theta_n}} - \utilde{\theta_0}) = \frac{1}{\sqrt{n}}\sum_{i=1}^{n}\utilde{g}(\utilde{X_i}; \utilde{\theta_0}) + o_p(1)
$$
However, if $\hat{\utilde{\theta_n}}$ is asymptotically efficient 
$$
\sqrt{n}(\hat{\utilde{\theta_n}} - \utilde{\theta_0}) = \utilde{J}^{-1}(\utilde{\theta_0})\utilde{S_n}(\utilde{\theta}) + o_p(1)
$$
we can conclude that 
$$
\sqrt{n}(\hat{\utilde{\theta_n}} - \utilde{\theta_0}) = \utilde{J}^{-1}(\utilde{\theta_0})\utilde{S_n}(\utilde{\theta}) + o_p(1) = \utilde{J}^{-1} n^{-1/2}\sum_{i=1}^{n}\utilde{\ell}_{\utilde{\theta_{0}}}^{\circ} = \frac{1}{\sqrt{n}}\sum_{i=1}^{n}\utilde{g}(\utilde{X_i}; \utilde{\theta_0}) + o_p(1)
$$
\end{proof}

Once we know the efficient influence function, we can figure out whether is an estimator asymptotically efficient.
\begin{theorem_exam}{Test for asymptotically efficient estimator}{}Suppose the efficient influence function is given by $\tilde{\utilde{\ell_{\theta_{0}}}}(\utilde{X}).$ Then suppose we can express our estimator of interest $\hat{\utilde{\theta_n}}$ in the form 
$$
\sqrt{n}\bigg(\hat{\utilde{\theta_n}} - \utilde{\theta_0} \bigg) = n^{-1/2}\sum_{i=1}^{n}\tilde{\utilde{\ell_{\theta_{0}}}}(\utilde{X_i}) + o_p(1).
$$
Then, the estimator $\hat{\utilde{\theta_n}}$ is asymptotically efficient.
\end{theorem_exam}

\subsection{Scalar Nuisance Parameter Model}
Up until now, we have been interested in estimating the full parameter of the model. What if we are only interested in estimating a subvector? That is, we now have nuisance parameters in our model which we do not care about but must account for.

We now describe the basic setup involving scalars for the parameter of interest and nuisance parameter. Consider a model $\{\prob_{\utilde{\gamma}}\}$ where the full parameter vector $\utilde{\gamma} = {\theta \choose \eta}$ has \textbf{dimension 2}. Furthermore, assume that the LAN property holds at $\utilde{\gamma_{0}} = {\theta_0 \choose \eta_0}$ with scores vector
$$
S_n = S = {S_{\theta} \choose S_{\eta}} = n^{-1/2}\sum_{i=1}^{n}
\begin{pmatrix}
\ell_{\theta}^{\circ}(\utilde{X_i})\\
\ell_{\eta}^{\circ}(\utilde{X_i})
\end{pmatrix}
$$
and the information matrix 
$$
J = \begin{pmatrix}
J_{\theta \theta} & J_{\theta \eta}\\
J_{\eta \theta} & J_{\eta \eta}
\end{pmatrix}
$$

\begin{proposition}(Efficient Influence Function for scalar parameters).
The efficient influence function for estimating $\utilde{\gamma}$ at $\utilde{\gamma_0}$ is $$J^{-1}\utilde{\ell}_{\utilde{\gamma}}^{\circ}.$$
\end{proposition}

Recall that explicitly, the inverse of the information matrix is given by
$$
J^{-1} = \frac{1}{J_{\theta \theta}J_{\eta \eta} - J_{\theta \eta}^2}
\begin{bmatrix}
J_{\eta \eta} & - J_{\theta \eta}\\
-J_{\eta \theta} & - J_{\theta \theta}\\
\end{bmatrix}
$$

We will now explicitly write out the efficient influence function. We have that the efficient influence function written out is 
$$
J^{-1}\utilde{\ell}_{\utilde{\gamma}}^{\circ} = 
\begin{bmatrix}
\frac{J_{\eta \eta}\ell_{\theta}^{\circ} - J_{\theta \eta}\ell_{\eta}^{\circ}}{J_{\theta \theta}J_{\eta \eta} - J_{\theta \eta}^2} &
\frac{J_{\theta \theta}\ell_{\eta}^{\circ} - J_{\theta \eta}\ell_{\theta}^{\circ}}{J_{\theta \theta}J_{\eta \eta} - J_{\theta \eta}^2}
\end{bmatrix}^T
$$

However, we are only interested in estimating the parameter of interest $\theta.$ Therefore, we only care about the first component of the efficient influence function
$$
\frac{J_{\eta \eta}\ell_{\theta}^{\circ} - J_{\theta \eta}\ell_{\eta}^{\circ}}{J_{\theta \theta}J_{\eta \eta} - J_{\theta \eta}^2}
$$

Now, multiplying the efficient influence function for $\utilde{\theta}$ by $J_{\eta \eta}^{-1}$, we get the following proposition.
\begin{proposition_exam}{Efficient influence function for scalar parameter of interest}{} The efficient influence function for estimating the parameter of interest $\theta$ is given by 
$$
\frac{\ell_{\theta_{0}}^{\circ *}}{J_{\theta \theta}^{*}} = \frac{\ell_{\theta}^{\circ} - J_{\theta \eta}J_{\eta \eta}^{-1}\ell_{\eta}^{\circ}}{J_{\theta \theta} - J_{\theta \eta}J_{\eta \eta}^{-1}J_{\eta \theta}}
$$
\end{proposition_exam}

\begin{remark}Looking at the efficient influence function, if the nuisance parameter $\eta$ was known, then we would use $\ell_{\theta}^{\circ}$ and $J_{\theta \eta}.$ However, if $\eta$ is unknown, we have a loss of information and therefore we replace $J_{\theta \theta}$ with $J_{\theta \theta}^*$, which is now a reduction in the information. Now, as the asymptotic variance is the inverse of the information, this means that the asymptotical variance increases if $\eta$ is unknown.
\end{remark}

We can then define important quantities from the efficient influence function.

\begin{definition_exam}{Scalar Effective Score and scalar effective information}{}Let $\frac{\ell_{\theta_{0}}^{\circ *}}{J_{\theta \theta}^{*}}$ be the efficient influence function. We define the effective score as 
$$
S_{\theta}^{*} = n^{-1/2}\sum_{i=1}^{n}\ell_{\theta}^{\circ *}(\utilde{X_i}).
$$
We call $J_{\theta \theta}^{*}$ the effective information.
\end{definition_exam}

\begin{remark} The effective information can be thought of as the asymptotic variance of the effective score.
\end{remark}

\subsection{General Setting Nuisance Parameter}

Now, in contrast to our last section, we are in the general case where the dimension $d = d_{\theta} + d_{\eta} \geq 2.$ We now have the same quantities defined in the last section but in terms of matrices.

\begin{definition_exam}{Efficient influence function for parameter of interest}{} The efficient influence function for estimating the parameter of interest $\utilde{\theta}$ is given by 
$$
(\utilde{J}_{\theta \theta}^{*})^{-1}\utilde{\ell_{\theta_{0}}}^{\circ *}
$$
\end{definition_exam}

\begin{definition_exam}{Effective Score and effective information matrix}{}Let $(\utilde{J}_{\theta \theta}^{*})^{-1}\utilde{\ell_{\theta_{0}}}^{\circ *}$ be the efficient influence function. We define the effective score as 
$$
\utilde{S_{\theta}}^{*} = n^{-1/2}\sum_{i=1}^{n}\utilde{\ell}_{\utilde{\theta}}^{\circ *}(\utilde{X_i}).
$$
We call $\utilde{J}_{\theta \theta}^{*}$ the effective information matrix.
\end{definition_exam}

Hence, everything follows from the last section by using the block-matrix inverse formulae.

\begin{proposition}(Block-matrix inverse formulae). Suppose that $\utilde{J}$ is an invertible square matrix
$$
\utilde{J} = 
\begin{bmatrix}
J_{11} & J_{12}\\
J_{21} & J_{22}
\end{bmatrix}
$$
where $J_{11}, J_{22}$ are invertible block matrices. Let 
$$
\begin{cases}
J_{11.2} = J_{11} - J_{12}J_{22}^{-1}J_{21}\\
J_{22.1} = J_{22} - J_{21}J_{11}^{-1}J_{12}
\end{cases}
$$
Then, the inverse $\utilde{J}^{-1}$ is given by 
$$
\utilde{J}^{-1} = 
\begin{bmatrix}
J_{11.2}^{-1} & -J_{11.2}^{-1}J_{12}J_{22}^{-1}\\\\
-J_{22.1}^{-1}J_{21}J_{11}^{-1} & J_{22.1}^{-1}
\end{bmatrix}
$$
\end{proposition}

\begin{proof} It is simple to verify that 
$$
\utilde{J}^{-1}\utilde{J} = \mathbb{I}
$$
where $\mathbb{I}$ is the identity matrix.
\end{proof}

\begin{proposition_exam}{Effective Information}{}The inverse of the effective information is given by 
$$
(\utilde{J}_{\theta \theta}^{*})^{-1} = \bigg(J_{\theta \theta} - J_{\theta \eta}J_{\eta \eta}^{-1}J_{\eta \theta} \bigg)^{-1}
$$
where $J_{\theta \theta}, J_{\theta \eta}, J_{\eta \theta}$ are terms from the information matrix $\utilde{J}.$
\end{proposition_exam}

\subsection{Regularity in the presence of nuisance parameters}


We are now interested in defining something analogous to the decomposition theorem when estimating $\utilde{\theta}$ in the presence of nuisance parameters $\utilde{\eta}.$ Before that, we first need to define regularity in the presence of nuisance parameters $\utilde{\eta}.$.

\begin{definition_exam}{Regular Estimators in the presence of nuisance parameters}{}A regular estimator is one where the estimation error has the same limiting distribution under the nearby sequence 
$$
\begin{pmatrix}
\utilde{\theta_0}\\
\utilde{\eta_0}
\end{pmatrix}
 + n^{-1/2}
\begin{pmatrix}
\utilde{h_{\theta}}\\
\utilde{h_{\eta}}
\end{pmatrix}
$$
as it has under the fixed center
$$
\begin{pmatrix}
\utilde{\theta_0}\\
\utilde{\eta_0}
\end{pmatrix}
$$
\end{definition_exam}

Now, after this definition of regularity, we can then apply Scores version of Le Cam's third lemma to get the following proposition.

\begin{proposition_exam}{RAJN Estimators are independent of nuisance parameters}{}Suppse that the LAN property holds at the true parameter value $\utilde{\gamma_0} = {\utilde{\theta_0} \choose \utilde{\eta_0}}$. Suppose that the estimator $\utilde{\tilde{\theta_n}}$ is a RAJN estimator. That is, the estimator $\utilde{\tilde{\theta_n}}$ is regular at $\utilde{\theta_0}$ and that the rescaled estimation error $Y_n = \sqrt{n}(\utilde{\tilde{\theta_n}} - \utilde{\theta_0})$ is such that 
$$
\begin{pmatrix}
\utilde{Y_n} \\
\utilde{S_n}
\end{pmatrix}
=
\begin{pmatrix}
\utilde{Y_n}\\
\utilde{S_{\theta}}\\
\utilde{S_{\eta}}
\end{pmatrix}
\xrightarrow{d}
\mathcal{N}
\bigg( 
\begin{pmatrix}
\utilde{0}\\
\utilde{0}\\
\utilde{0}
\end{pmatrix}
,
\begin{pmatrix}
\Sigma_Y & \Sigma_{Y \theta} & \Sigma_{Y\eta}\\
\Sigma_{\theta Y} & J_{\theta \theta} & J_{\theta \eta}\\
\Sigma_{\eta Y} & J_{\eta \theta} & J_{\eta\eta}\\
\end{pmatrix}
\bigg)
= 
\mathcal{N}
\bigg( 
\begin{pmatrix}
\utilde{0}\\
\utilde{0}
\end{pmatrix}
,
\begin{pmatrix}
\Sigma_Y & \Sigma_{Y S}\\
\Sigma_{S Y} & J
\end{pmatrix}
\bigg)
$$
which means that the estimator $\utilde{\tilde{\theta_n}}$ is asymptotically jointly normal with the scores vector. 

Then, the cross covariance of the estimation error with the scores vector for the parameters of interest $\utilde{\theta}$ is given by
$$
\Sigma_{Y \theta} = \utilde{I}
$$
and the cross covariance of the estimation error with the scores vector for the nuisance parameters $\utilde{\eta}$ is given by
$$
\Sigma_{Y \eta} = \utilde{0}
$$
\end{proposition_exam}

\begin{proof} By the Scores version of Le Cam's third lemma, we have that under the nearby alternative $$
\begin{pmatrix}
\utilde{\theta_0}\\
\utilde{\eta_0}
\end{pmatrix}
 + n^{-1/2}
\begin{pmatrix}
\utilde{h_{\theta}}\\
\utilde{h_{\eta}}
\end{pmatrix}
$$
that the estimation error under the true value $Y_n = \sqrt{n}(\utilde{\tilde{\theta_n}} - \utilde{\theta_0})$ has the distribution
$$
\utilde{Y_n} \xrightarrow{d} \mathcal{N}\bigg(\Sigma_{YS}\utilde{h}, \Sigma_Y \bigg) = \mathcal{N}\bigg(\Sigma_{Y\theta}\utilde{h_{\theta}} + \Sigma_{Y\eta}\utilde{h_{\eta}}, \Sigma_Y \bigg)
$$
where we decomposed the mean into the parameter of interest and the nuisance parameter. Then, we have that the estimation error under the nearby sequence $\utilde{\gamma_n}$
$$
\sqrt{n}(\utilde{\tilde{\theta_n}} - \utilde{\theta_n}) = \utilde{Y_n} - \utilde{h_{\theta}} \xrightarrow{d} \mathcal{N}\bigg([\Sigma_{Y\theta} - \utilde{I}]\utilde{h_{\theta}} + \Sigma_{Y \eta}\utilde{h_{\eta}}, \Sigma_Y \bigg)
$$
However, by assumption, the estimator $\utilde{\tilde{\theta_n}}$ was assumed to be RAJN. Therefore, in order for the limiting distribution to be free of $\utilde{h},$ we therefore require that 
$$
\Sigma_{Y \theta} = \utilde{I}
$$
$$
\Sigma_{Y \eta} = \utilde{0}
$$
\end{proof}

\begin{remark}Any RAJN estimator is asymptotically independent of the nuisance scores $\utilde{S}_{\utilde{\eta}}.$ That is, the estimator is unaffected by changing $\eta$ whilst keeping $\theta$ fixed.
\end{remark}

We now revisit some concepts we have seen already.

\begin{proposition}Any asymptotically efficient estimator $\hat{\utilde{\theta_n}}$ can be written in the form
$$
\sqrt{n}(\hat{\utilde{\theta_n}} - \utilde{\theta_0}) = (J_{\theta \theta}^{*})^{-1}\utilde{S_{n\theta}}^{*} + o_p(1)
$$
\end{proposition}

Additionally, we can also see that the effective scores $S_{n \theta}^{*}$ are asymptotically independent of the nuisance scores $\utilde{S_{\utilde{\eta}}}.$ That is, the effective scores are the precise linear combinations of the scores $\utilde{S}_{\utilde{\theta}}$ and $\utilde{S}_{\utilde{\eta}}$ which is asymptotically uncorrelated with the score of the nuisance parameter $\utilde{S}_{\utilde{\eta}}$.

\begin{proposition_exam}{Effective score is the linear combination of the scores}{}The effective score $S_{\theta}^{*}$ is given by the linear combination of scores of the parameter of interest $\utilde{S}_{\utilde{\theta}}$ and of the nuisance parameter $\utilde{S}_{\utilde{\eta}}$
$$
S_{\theta}^{*} = \utilde{S}_{\utilde{\theta}} - \utilde{J_{\theta \eta}}\utilde{J_{\eta \eta}}^{-1}\utilde{S}_{\utilde{\eta}}
$$
\end{proposition_exam}

\begin{remark} We can interpret the effective score as the residuals from regressing the scores of the parameter of interest on the nuisance parameter scores. Furthermore, we can interpret the effective information as the asymptotic variance of the effective score.
\end{remark}

\begin{remark} When the co-information matrix $J_{\theta \eta} = 0,$ we have that the effective scores is identical to the ordinary scores. That is, $\eta$ does not matter and the performance of estimates and tests for $\theta$ will be the same regardless if $\eta$ is known or not. This is described as that we can \textbf{adapt} for $\eta.$
\end{remark}

\begin{corollary}(Limiting distribution of the effective score) Assuming LAN, we have that 
$$
S_{\theta}^{*} \xrightarrow{d} \mathcal{N}(J_{\theta \theta}^{*}h_{\theta}, J_{\theta \theta}^{*})
$$
\end{corollary}

\begin{proposition}(Effective score is asymptotically uncorrelated). The asymptotic covariance of the effective score and score of the nuisance parameter is zero 
$$
\mathbb{E}[\utilde{S_{\theta}}^*\utilde{S_{\eta}}^T] \rightarrow \utilde{0}.
$$
where $J_{\theta \theta}^{*}$ is the effective information.
\end{proposition}

The final remark we make is that asymptotically efficient estimators can be constructed as before by updating a $\sqrt{n}-$consistent estimator of the whole vector $\utilde{\gamma}/$ In fact, only the $\utilde{\theta}$ component of the estimators are updated. Hence, we have the same process of constructing asymptotically efficient estimators.
\lecture{22}{Estimating Smooth functions of parameters}
\section{Optimality}
\subsection{Estimating Smooth functions of parameters}
\textit{In this lecture, we now generalise the previous lectures on estimation of parameters. In particular, we want to estimate smooth function of parameters. We define regular estimators, asymptotically efficient estimators, and orthogonal decomposition theorem for smooth function of parameters.}


We have seen two forms of estimations of the parameter. The first is where are interested in estimating the full parameter vector $\utilde{\theta}.$ The second case is when we have a nuisance parameter involved $\utilde{\eta}.$ 


Now, we are interested in a generalisation. Suppose we have a parametetric model $\{P_{\utilde{\gamma}}\}$, where we are now estimating a smooth function $\utilde{\theta}(\utilde{\gamma})$ of dimension $d_{\theta}$  of the d-dimensional parameter $\utilde{\gamma}.$

We now give the definition for a regular estimator of a smooth function of the parameters.
\begin{definition_exam}{Regular Estimator}{}A regular estimator $\tilde{\utilde{\theta_n}}$ at $\utilde{\gamma_0}$ is such that for any nearby sequence $\utilde{\gamma_n} = \utilde{\gamma_0} + n^{-1/2}\utilde{h}$, the estimation error satisfies 
$$
\sqrt{n}(\tilde{\utilde{\theta_n}} - \utilde{\theta}(\utilde{\gamma_n})) \xrightarrow{d} \mathcal{N}(\utilde{0}, \utilde{\Sigma}(\utilde{\gamma_0}))
$$
\end{definition_exam}

\begin{remark}As always, a regular estimator is one where the distribution of the estimation error does not depend on $\utilde{h}$ for any nearby sequence. The only thing that changes is the covariance matrix, which only depends on the centered true value.
\end{remark}

We now repeat a procedure that we have seen when estimating nuisance parameters.

Suppose that the LAN property holds at the trule value $\utilde{\gamma_0}$ with the scores vector $\utilde{S_n}$ and information matrix $\utilde{J}.$ Suppose further, that the rescaled estimation error at $\utilde{\gamma_0}$
$$
\utilde{Y_n} = \sqrt{n}(\tilde{\utilde{\theta_n}} - \utilde{\theta}(\utilde{\gamma_0}))
$$
satisfies the LAN\# property. That is, the rescaled estimation error is asymptotically joint normal with the scores vector 
$$
\begin{pmatrix}
\utilde{Y_n} \\
\utilde{S_n}
\end{pmatrix}
= 
\mathcal{N}
\bigg( 
\begin{pmatrix}
\utilde{0}\\
\utilde{0}
\end{pmatrix}
,
\begin{pmatrix}
\Sigma_Y & \Sigma_{Y S}\\
\Sigma_{S Y} & J
\end{pmatrix}
\bigg)
$$
under the true value $\utilde{\gamma_0}$. Then, under the nearby sequence $\utilde{\gamma_n} = \utilde{\gamma_0} + n^{-1/2}\utilde{h}$, we can apply Scores version of Le Cam's third lemma to get 
$$
\begin{pmatrix}
\utilde{Y_n} \\
\utilde{S_n}
\end{pmatrix}
= 
\mathcal{N}
\bigg( 
\begin{pmatrix}
\Sigma_{Y S} \utilde{h}\\
\utilde{J}\utilde{h}
\end{pmatrix}
,
\begin{pmatrix}
\Sigma_Y & \Sigma_{Y S}\\
\Sigma_{S Y} & J
\end{pmatrix}
\bigg)
$$

Note that what we just did was for the estimation error at the true value $\utilde{\gamma_0}.$ We now write the general estimation error for a nearby sequence 
$$
\sqrt{n}(\tilde{\utilde{\theta_n}} - \utilde{\theta}(\utilde{\gamma_n})) = \sqrt{n}[\tilde{\utilde{\theta_n}} - \utilde{\theta}(\utilde{\gamma_0}) - \utilde{\theta}^{\circ}(\utilde{\gamma_n}^{*})n^{-1/2}\utilde{h}] = \utilde{Y_n} - \utilde{\theta_0^{\circ}}\utilde{h} + o(1)
$$
where we applied a 1-term Taylor expansion and that $\utilde{\theta}^{\circ}$ is the $d_{\theta}$ by d matrix of partial derivatives (the Jacobian matrix) and $\utilde{\theta_0^{\circ}} = \utilde{\theta^{\circ}}(\utilde{\gamma_0})$ is the Jacobian evaluated at the true parameter of interest.


Then, by Le Cam's third lemma, we see that the general estimation error under $\utilde{\gamma_n}$ is
$$
\sqrt{n}[\tilde{\utilde{\theta_n}} - \utilde{\theta}(\utilde{\gamma_n})] \xrightarrow{d} \mathcal{N}(\Sigma_{YS}\utilde{h} - \utilde{\theta}_0^{\circ}\utilde{h}, \Sigma_Y)
$$
However, as the estimator was assumed to be regular, we require this distribution to be free of $\utilde{h}$, which only occurs if the cross-covariance matrix in the mean is zero, which is when $\Sigma_{YS} = \utilde{\theta}_0^{\circ}.$

\begin{proposition_exam}{Covariance of general estimation error and score}{}Suppose that $\tilde{\utilde{\theta}}$ is a RAJN estimator. Then, under a nearby sequence, we have that the cross-covariance of the general estimation error $Y$ and the score vector is the Jacobian of the transformation of the parameters evaluated at the true value 
$$\Sigma_{YS} = \utilde{\theta}_0^{\circ} = \utilde{\theta}^{\circ}(\utilde{\gamma_0})$$
\end{proposition_exam}

\begin{remark}Note that this generalises our earlier 2 results when deducing the cross-covariance matrix.

In the case where we are estimating the whole vector $\utilde{\theta}(\utilde{\gamma}) = \utilde{\gamma}$, the cross-covariance matrix was $\Sigma_{YS} = \utilde{I}$.

In the case where we were only estimating the parameters of interest and ignoring the nuisance parameters, that is, $\utilde{\theta}(\utilde{\gamma})$ was the first $d_{\theta}$ elements of $\utilde{\gamma}$, the cross covariance was given by 
$$
\Sigma_{YS} = (\Sigma_{Y \theta},\Sigma_{Y \eta}) = (\utilde{I}, \utilde{0})
$$
where $\Sigma_{Y \theta},\Sigma_{Y \eta}$ was the cross-covariance with the parameter of interest and nuisance parameter respectively.
\end{remark}

Hence, all our earlier results on the cross-covariance actually depends on the Jacobian of the transformation.

This will now lead to generalised definitions of asymptotically efficient estimators and orthogonal decomposition theorem.

\begin{proposition_exam}{Orthogonal Decomposition Theorem}{}Let $\tilde{\utilde{\theta_n}}$ be a RAJN estimator of $\utilde{\theta}(\utilde{\gamma}).$ Then, define 
$$
\utilde{Z_n} = \sqrt{n}(\tilde{\utilde{\theta_n}} - \utilde{\theta}(\utilde{\gamma_0})) - \utilde{\theta}^{\circ}\utilde{J}^{-1}\utilde{S} = \utilde{Y_n} - \utilde{\theta}^{\circ}\utilde{J}^{-1}\utilde{S}
$$
where $\utilde{Y_n} = \tilde{\utilde{\theta_n}} - \utilde{\theta}(\utilde{\gamma_0})$ is the estimation error. 
Then, the limiting distribution under the null $\utilde{\gamma_0}$ is given by
$$
\begin{bmatrix}
\utilde{Z_n}\\
\utilde{S_n}
\end{bmatrix}
\xrightarrow{d}
\mathcal{N}
\bigg( 
\utilde{0},
\begin{bmatrix}
\Sigma_Y - \utilde{\theta^{\circ}}\utilde{J}^{-1}\utilde{\theta}^{\circ T} & \utilde{0}\\
\utilde{0} & \utilde{J}
\end{bmatrix}
\bigg)
$$
Therefore, any estimator is made up of two parts 
$$
\utilde{Y_n}  = \utilde{\theta}^{\circ}\utilde{J}^{-1}\utilde{S} + \utilde{Z_n}
$$
Then, the best that we can do is for $\utilde{Z_n} = \utilde{0}$ which occurs when the covariance matrix 
$$
\Sigma_Y = \utilde{\theta^{\circ}}\utilde{J}^{-1}\utilde{\theta}^{\circ T}
$$
\end{proposition_exam}

\begin{remark}Here, $\utilde{Z_n}$ is AJN with the scores as the estimator was assumed to be AJN.
\end{remark}

Hence, if we choose an estimator $\tilde{\utilde{\theta_n}}$ which has a covariance matrix $\Sigma_Y = \utilde{\theta^{\circ}}\utilde{J}^{-1}\utilde{\theta}^{\circ T}$, that is the best that we can do. This brings us to our definition of asymptotically efficeint estimators.

\begin{definition_exam}{Asymptotically Efficient Estimator}{}An estimator $\hat{\utilde{\theta_n}}$ is asymptotically efficient if we can write the estimation error 
$$
\sqrt{n}(\hat{\utilde{\theta_n}} - \utilde{\theta}(\utilde{\gamma_0})) = \utilde{\theta}^{\circ}\utilde{J}^{-1}\utilde{S} + o_p(1)
$$
under the true value $\utilde{\gamma_0}$.
\end{definition_exam}

\begin{remark}Note that this form is what we stated in the orthogonal decomposition theorem except that the extra estimation error $\utilde{Z_n}$ now converges to 0 in probability.
\end{remark}

\newpage
Now recall, that we can view asymptotically efficient estimators from the perspective of it being an asymptotically linear function and therefore it has an associated efficient influence function.

\begin{definition_exam}{Efficient Influence Function, Effective Score and information}{}Let $\hat{\utilde{\theta_n}}$ be an asymptotically linear estimator. Then, the efficient influence function is 
$$
\utilde{\theta^{\circ}}\utilde{J}^{-1}\utilde{\ell}_{\utilde{\gamma}}^{\circ}
$$
The asymptotic covariance matrix of $\utilde{\theta}^{\circ}\utilde{J}^{-1}\utilde{S}$ is given by 
$$
\utilde{\theta}^{\circ}\utilde{J}^{-1}\utilde{\theta^{\circ T}}
$$
The effective score is given by 
$$
S_n^{*} = J^*\utilde{\theta^{\circ}}\utilde{J}^{-1}\utilde{S}
$$
where the effective information is given by 
$$
J^* = (\utilde{\theta}^{\circ}\utilde{J}^{-1}\utilde{\theta}^{\circ T})^{-1}
$$
\end{definition_exam}

\begin{remark}Recall that the effective scores is the score associated to the parameters of interest. These 2 forms of the effective score and effective information generalises from yesterday.
\end{remark}

We are now interested in constructing asymptotically efficeint estimators. We can in fact construct them by applying smooth transformations of efficient estimators of the original parameter.

\begin{proposition_exam}{Smooth function of efficient estimators are efficient}{}Suppose that $\hat{\utilde{\gamma_n}}$ is an asymptotically efficient estimator for the full parameter vector $\utilde{\gamma}.$ Then, by the delta method in probability, the new estimator defined by taking a smooth function $\utilde{\theta}$ of our estimator, denoted by $\tilde{\utilde{\theta_n}} = \utilde{\theta}(\hat{\utilde{\gamma_n}})$ is also an asymptotically efficient estimator of $\utilde{\theta}(\utilde{\gamma})$ at $\utilde{\gamma_0}.$
\end{proposition_exam}

Hence, taking a smooth function of an efficient estimator gives you an efficient estimator of a smooth function.

\newpage
However, we can now incorporate the ideas of one-step estimators whereby we do not necessarily need to start off with an asymptotically efficient estimator of the whole vector. In fact, just a $\sqrt{n}-$consistent estimator is enough.
\begin{proposition_exam}{Constructing efficient estimators through one step update}{}Suppose that we have the following conditions holding at $\utilde{\gamma_0}$
\begin{enumerate}
\item LAN property
\item Regular scores 
\item Continuous information
\end{enumerate}
Furthermore, suppose that 
\begin{enumerate}
\item The Jacobian $\utilde{\theta}^{\circ}(\utilde{\gamma})$ is continuous at $\utilde{\gamma_0}$
\item $\utilde{\tilde{\gamma_n}}$ is a $\sqrt{n}-$consistent estimator of $\utilde{\gamma}$ at $\utilde{\gamma_0}$
\end{enumerate}
Then, the one-step estimator given by 
$$
\utilde{\hat{\theta_n}} = \theta(\utilde{\tilde{\gamma_n}}) + n^{-1/2}\utilde{\theta^{\circ}}(\utilde{\tilde{\gamma}})\utilde{J}^{-1}(\utilde{\tilde{\gamma_n}})S_n(\utilde{\tilde{\gamma_n}})
$$
is an asymptotically efficient estimator for $\utilde{\theta}(\utilde{\gamma})$ at $\utilde{\gamma_0}.$
\end{proposition_exam}

\begin{remark}We can think of the one step update as that we take a smooth function of a $\sqrt{n}-$consistent estimator and then we apply a correction term to it. This is a generalisation of the one-step estimators we have seen so far.
\end{remark}

In fact, there is an even nicer way of expressing one-step estimators.

\begin{proposition_exam}{Concise form of one-step estimators}{}All one-step estimators can be written as 
$$
\hat{\utilde{\theta_n}} = \utilde{\theta}(\tilde{\utilde{\gamma_n}}) + \frac{1}{n}\sum_{i=1}^{n}\tilde{\utilde{\ell_{\theta}}}(\utilde{X_i}; \tilde{\utilde{\gamma_n}})
$$
where $\tilde{\utilde{\ell_{\theta}}}(.; \tilde{\utilde{\gamma_n}}) = \utilde{\theta}^{\circ}\utilde{J}^{-1}(\utilde{\gamma})\utilde{\ell_{\utilde{\gamma}}}^{\circ}$ is the efficient influence function for estimating $\utilde{\theta}(\utilde{\gamma})$ at $\utilde{\gamma}.$
\end{proposition_exam}

\lecture{23}{Asymptotically Optimal Parametric Testing}
\section{Hypothesis Testing}
\section{Hypothesis Testing}
\subsection{Asymptotically Optimal Parametric Testing}

\textit{In this lecture, we describe the set up of hypothesis testing. We then describe what it means to look at local alternatives of a test. Finally, we introduce 4 classical tests.}

Suppose we model data as values taken by i.i.d random vectors $\utilde{X_1},...,\utilde{X_n}$ with common density in a parametric family $\{p_{\utilde{\gamma}}\}$ indexed by a d-dimensional parameter vector $\utilde{\gamma}.$

Now, a hypothesis test is when we are trying to determine whether the observed data constitutes evidence \textbf{against} a null hypothesis $H_0$, which states that a certain function $\utilde{\theta}(\utilde{\gamma})$ of the parameters is equal to a reference value $\utilde{\theta}^{\circ}.$

In particular, the function of the parameters $\utilde{\gamma}$, will be the special case where $\utilde{\theta}(\utilde{\gamma})$ is the first $d_{\theta}$ components of $\utilde{\gamma}$ where $d_{\theta} \leq d.$ Then, if we define a nuisance parameter mapping 
$$
\utilde{\gamma} \rightarrow \utilde{\eta}(\utilde{\gamma})
$$
we can therefore define a function of the parameter vector to be 
$$
\utilde{\gamma} \rightarrow 
\begin{pmatrix}
\utilde{\theta}(\utilde{\gamma})\\
\utilde{\eta}(\utilde{\gamma})\\
\end{pmatrix}
$$
where this mapping is smoothly invertible. Therefore, we define 
$$
\utilde{\gamma} = 
\begin{pmatrix}
\utilde{\theta}\\
\utilde{\eta}
\end{pmatrix}
$$
with $d_{\utilde{\theta}} + d_{\utilde{\eta}} = d$ where $\utilde{\theta}$ is the parameter of interest and $\utilde{\eta}$ is the nuisance parameter.

We now assume that the LAN property holds in at least a neighbourhood of the true value $\utilde{\gamma^{\circ}} = \begin{pmatrix}\utilde{\theta^{\circ}}\\\utilde{\eta^{\circ}} \end{pmatrix}$. This will allow us to define the scores vector 
$$
\utilde{S_n} = \utilde{S_n}(\utilde{\theta}, \utilde{\eta}) = \begin{pmatrix}S_{\theta}\\S_{\eta} \end{pmatrix}
$$
and the information matrix 
$$
\utilde{J} = \utilde{J}(\utilde{\theta}, \utilde{\eta}) = 
\begin{bmatrix}
\utilde{J}_{\theta \theta} & \utilde{J}_{\theta \eta}\\
\utilde{J}_{\eta \theta} & \utilde{J}_{\eta \eta}
\end{bmatrix}
$$

\begin{proposition_exam}{Block form of inverse information matrix}{}Suppose that the information matrix $\utilde{J}$ is partitioned according to 
$$
\utilde{J} = \utilde{J}(\utilde{\theta}, \utilde{\eta}) = 
\begin{bmatrix}
\utilde{J}_{\theta \theta} & \utilde{J}_{\theta \eta}\\
\utilde{J}_{\eta \theta} & \utilde{J}_{\eta \eta}
\end{bmatrix}
$$
Then, we may write the corresponding inverse information matrix $\utilde{J}^{-1}$ as 
$$
\utilde{J}^{-1} = 
\begin{bmatrix}
\utilde{J}^{\theta \theta} & \utilde{J}^{\theta \eta}\\
\utilde{J}^{\eta \theta} & \utilde{J}^{\eta \eta}
\end{bmatrix}
$$

where 
$$
\utilde{J}^{\theta \theta} = \bigg(\utilde{J}_{\theta \theta} - \utilde{J}_{\theta \eta}\utilde{J}_{\eta \eta}^{-1}\utilde{J}_{\eta \theta} \bigg)^{-1}
$$
$$
\utilde{J}^{\eta \eta} = \bigg(\utilde{J}_{\eta \eta} - \utilde{J}_{\eta \theta}\utilde{J}_{\theta \theta}^{-1}\utilde{J}_{\theta \eta} \bigg)^{-1}
$$
$$
\utilde{J}^{\theta \eta} =  -\utilde{J}^{\theta \theta}\utilde{J}_{\theta \eta}\utilde{J}_{\eta \eta}^{-1}
$$
$$
\utilde{J}^{\eta \theta} =  -\utilde{J}^{\eta \eta}\utilde{J}_{\eta \theta}\utilde{J}_{\theta \theta}^{-1}
$$

\end{proposition_exam}

Now, as our mapping is just the first $d_{\theta}$ components of the parameter $\utilde{\gamma}$, the Jacobian of our transformation will be the identity matrix. Then, recall that for an asymptotically efficient estimator, its estimation error has the form 
$$
\utilde{J}^{-1}\utilde{S} = J^{\theta \theta}S_{\theta} + J^{\theta \eta}S_{\eta} = (J^*)^{-1}S_{\theta}^{*}
$$


where again, we define the effective score to be
$$
S_{\theta}^{*} = S_{\theta} - J_{\theta \eta}J_{\eta \eta}^{-1}S_{\eta}
$$
which is the linear combination of the scores $S_{\theta}, S_{\eta}$ that is uncorrelated with $S_{\eta}.$ Additionally, we define the effective information 
$$
J_{\theta}^{*} = J_{\theta \theta} - J_{\theta \eta}J_{\eta \eta}^{-1}J_{\eta \theta}
$$
Additionally, recall that the effective information $J_{\theta}^{*} = (J^{\theta \theta})^{-1}.$
\subsection{Local Alternatives}
We will now develop theory for analysing and comparing the power of tests.

\begin{definition}(Power of a test). The power of a binary hypothesis test is the probability that the test rejects the null hypothesis $H_0$ when a specific alternative hypothesis $H_1$ is true. That is, the power is given by
$$
\mathbb{P}(\text{reject }H_0: H_1 \text{ is true})
$$
\end{definition}

So the size of a test is the probability of rejecting a true hypothesis. If the size of a test is bounded by $\alpha$ for all values in the null hypothesis, we say that the level of the test is $\alpha.$

The results which we will soon show are asymptotic. That is, as $n \rightarrow \infty,$ the power of our tests will go to 1.

We shall study cases the true value $\utilde{\theta} = \utilde{\theta}_n \neq \utilde{\theta}_0$ but $\utilde{\theta}_n \rightarrow \utilde{\theta}_0$ as $n \rightarrow \infty$ at just the right speed. 
\begin{definition_exam}{Local Alternative}{}The local alternative is a pertubation of both the parameter of interest and nuisance parameter by a local shift.
$$
\utilde{\gamma_n}^{\circ} = \utilde{\gamma}^{\circ} + n^{-1/2}\utilde{h} 
= \begin{pmatrix}\utilde{\theta}^{\circ}\\\utilde{\eta}^{\circ}\end{pmatrix} + n^{-1/2}\begin{pmatrix}\utilde{h_{\theta}}\\\utilde{h_{\eta}} \end{pmatrix}
$$
\end{definition_exam}

We shall write 
$$
\hat{\utilde{\gamma_n}} = 
\begin{pmatrix}
\hat{\utilde{\theta_n}}\\
\hat{\utilde{\eta_n}}
\end{pmatrix}
$$
for an asymptotically efficient estimator of the full parameter vector. Likewise, we write 
$$
\tilde{\utilde{\gamma_n}} = 
\begin{pmatrix}
\tilde{\utilde{\theta_n}}\\
\tilde{\utilde{\eta_n}}
\end{pmatrix}
$$
for a $\sqrt{n}-$consistent estimator of the full parameter vector. We now introduce a new concept.

\begin{definition_exam}{Constrained Estimators}{}Hold the parameter of interest fixed at the null value $\utilde{\theta} = \utilde{\theta}^{\circ}.$ Then, we respectively define the constrained asymptotically efficient estimator and $\sqrt{n}$-consistent estimator of the nuisance parameter $\utilde{\eta}$ as 
$$
\hat{\utilde{\gamma_n}}^{\circ} = 
\begin{pmatrix}
\utilde{\theta}^{\circ}\\
\hat{\utilde{\eta_n}}^{\circ}
\end{pmatrix}
$$
$$
\tilde{\utilde{\gamma_n}} = 
\begin{pmatrix}
\utilde{\theta}^{\circ}\\
\tilde{\utilde{\eta_n}}^{\circ}
\end{pmatrix}
$$
That is, $\hat{\utilde{\eta_n}}^{\circ}$ and $\tilde{\utilde{\eta_n}}^{\circ}$ are (respectively) asymptotically efficient and $\sqrt{n}-$consistent estimators of the nuisance parameter under the extra assumption that the null hypothesis $H_0$ is true.
\end{definition_exam}


\subsection{Classical Tests}
We will now introduce classical tests we have seen before.

\begin{definition_exam}{Likelihood Ratio Test}{}First, denote the log likelihood function at $\utilde{\gamma}$ as 
$$
\Lambda_n(\utilde{\gamma}) = \sum_{i=1}^{n}log \; p_{ \utilde{\gamma}}(\utilde{x_i}).$$
Then, the likelihood ratio test statistic is given by 
$$
LR = 2[\Lambda_n(\utilde{\hat{\gamma}_n}) - \Lambda_n(\utilde{\hat{\gamma}_n}^{\circ})]
$$
where $\utilde{\hat{\gamma}_n}$ and $\utilde{\hat{\gamma}_n}^{\circ}$ are (respectively) unconstrained and constrained asymptotically efficient estimators.
\end{definition_exam}

\begin{remark}To interpret this, $\utilde{\hat{\gamma}_n}^{\circ}$ can be thought of as MLE under the constrained assumption of $H_0.$
\end{remark}

The subsequent tests require a consistent estimate under the null hypothesis $H_0$ of the effective information $\utilde{J}_{\theta}^{*}$ or its inverse $\utilde{J}^{\theta \theta}$, which we will shall denote the estimations (respectively) as $\hat{J}_{\theta}^{*}$ and $\hat{J}^{\theta \theta}.$

\begin{proposition}(Estimates of the effective information and its inverse). Let $\utilde{J}_{\theta}^{*}$ be the effective information. Denote $\hat{J}_{\theta}^{*}$ as the estimator of the effective information. Two particular forms of the effective information estimator are 
$$
\hat{J}_{\theta}^{*} = \utilde{J}_{\theta}^{*}(\tilde{\utilde{\gamma_n}})
$$
$$
\hat{J}_{\theta}^{*} = -\Lambda_n^{''}(\tilde{\utilde{\gamma_n}})
$$
Let $\utilde{J}^{\theta \theta}$ be the inverse of the effective information. Denote $\hat{J}^{\theta \theta}$ as the estimator of the inverse of the effective information. Two particular forms of the inverse of the effective information estimators are 
$$
\hat{J}^{\theta \theta} = \utilde{J}^{\theta \theta}(\tilde{\utilde{\gamma_n}})
$$
$$
\hat{J}^{\theta \theta} = -\Lambda_n^{''}(\tilde{\utilde{\gamma_n}})^{-1}
$$
under suitable regularity conditions.
\end{proposition}

\begin{definition_exam}{Rao-Score Test}{}The Rao Score test has the test statistic 
$$
R = S_{\theta}(\hat{\utilde{\gamma_n}}^{\circ})^T\hat{J}^{\theta \theta}S_{\theta}(\hat{\utilde{\gamma_n}}^{\circ})
$$
where $\hat{\utilde{\gamma_n}}^{\circ}$ is a constrained asymptotically efficient estimator of the nuisance parameter with the parameter of interest fixed at the hypothesised value $\utilde{\theta} = \utilde{\theta}^{\circ}.$
\end{definition_exam}
\begin{remark}In Econometrics, this is known as the Lagrange multiplier test.
\end{remark}

\begin{definition_exam}{Wald Test}{}The Wald test has the test statistic 
$$
W = n(\hat{\utilde{\theta_n}} - \utilde{\theta_n})^T\hat{\utilde{J}_{\theta}}^{*}(\hat{\utilde{\theta_n}} - \utilde{\theta_n})
$$
where $\hat{\utilde{\theta_n}}$ is an asymptotically efficient estimator of the parameter of interest.
\end{definition_exam}

\begin{definition_exam}{Neyman-Rao Test}{}The Neyman-Rao test has the test statistic 
$$
NR = S_{\theta}^{*}(\tilde{\utilde{\gamma_n}}^{\circ})^T\hat{J}^{\theta \theta}S_{\theta}^{*}(\tilde{\utilde{\gamma_n}}^{\circ})
$$
where $\tilde{\utilde{\gamma_n}}^{\circ}$ is a constrained $\sqrt{n}$-consistent estimator of the nuisance parameter with the parameter of interest fixed at the hypothesised value $\utilde{\theta} = \utilde{\theta}^{\circ}.$
\end{definition_exam}

\begin{remark}The Neyman-Rao test evaluates the effective scores of a $\sqrt{n}-$consistent estimator of the nuisance parameter whereas the Rao-Score test evaluates the ordinary score of an asymptotically efficient estimator of the nuisance parameter.
\end{remark}

\begin{proposition}The Rao-Score test and the Neyman-Rao test are equivalent when the regular scores of the asymptotically efficient estimator is equal to the effective score of the $\sqrt{n}-$estimator. This occurs when the information matrix is a diagonal matrix.
\end{proposition}

\begin{remark} When there is no nuisance parameter $\eta,$ then the effective score is the same as the ordinary score. Therefore, the Rao test is equivalent to the Neyman-Rao test.
\end{remark}

\lecture{24}{Classical Tests are equivalent}
\section{Hypothesis Testing}
\subsection{Classical Tests are asymptotically equivalent}
\textit{We shall show in this lecture that under certain conditions, all 4 classical test statistics are asymptotically equivalent. First, we relax the assumption of regular scores. Then, we introduce the quadratic form random variable with which all our tests converge to. We then state a new strengthened LAN property.}

We will first require a proposition to show us that evaluating scores of asymptotically efficient estimators and $\sqrt{n}-$consistent estimators are equivalent to evaluating effective scores.
\begin{proposition_exam}{Expression for the effective score at true values}{}Suppose that for a parameteric model, the LAN property holds in a neighbourhood of the true values $\utilde{\gamma}^{\circ} = \begin{pmatrix}\utilde{\theta}^{\circ}\\ \utilde{\eta}^{\circ}  \end{pmatrix}$. Furthermore, assume that the regular scores assumption and the continuous information matrix assumption holds. Let $\hat{\utilde{\eta_n}}^{\circ}$ and $\tilde{\utilde{\eta_n}}^{\circ}$ be the constrained asymptotically efficient estimator and constrained $\sqrt{n}-$consistent estimator of the nuisance parameter when the parameter of interest is fixed at the hypothesised value $\utilde{\theta} = \utilde{\theta}^{\circ}.$ Then 
\begin{enumerate}
\item $\utilde{S}_{\theta}(\utilde{\theta}^{\circ};\hat{\utilde{\eta_{n}}}^{\circ}) = \utilde{S}_{\theta}^{*}(\utilde{\theta}^{\circ};\utilde{\eta_{n}}^{\circ}) + o_p(1)$
\item $\utilde{S}_{\theta}^{*}(\utilde{\theta}^{\circ};\tilde{\utilde{\eta_{n}}}^{\circ}) = \utilde{S}_{\theta}^{*}(\utilde{\theta}^{\circ};\utilde{\eta_{n}}^{\circ}) + o_p(1)$
\end{enumerate}
where $\utilde{S_{\theta}}^{*}$ is the effective score for $\utilde{\theta}.$
\end{proposition_exam}


\begin{proof}(Sketch). By the Regular scores assumption and the fact that any $\sqrt{n}-$consistent estimator $\tilde{\utilde{\theta_n}}$ satisfies under $\utilde{\theta_0}$
\begin{equation}
S_n(\tilde{\utilde{\theta_n}}) = S_n(\utilde{\theta_0}) - J(\utilde{\theta_0})\sqrt{n}(\tilde{\utilde{\theta_n}} - \utilde{\theta_0}) + o_p(1)
\tag{*}
\end{equation}
we can rewrite the score $\utilde{S}(\utilde{\theta}^{\circ};\hat{\utilde{\eta_{n}}}^{\circ})$ using (*).
\end{proof}

\begin{remark}This is useful for us as we can use it to show that the Rao-Score test, which uses the ordinary score, is equal to the Neyman-Rao test, which uses the effective score are equal under certain conditions.
\end{remark}



\newpage
However, the regular scores assumption in the previous proposition can in fact be weakened to the following assumption. This is because we only need local deviations of $\utilde{h}$ in the nuisance parameter $\utilde{\eta}$ only.

\begin{definition_exam}{Null-Regular Scores Assumption}{}Define the null values $\utilde{\gamma}^{\circ} = \begin{bmatrix}\utilde{\theta}^{\circ}\\ \utilde{\eta}^{\circ}\end{bmatrix}$ and $\utilde{h} = \begin{bmatrix}\utilde{h}_{\theta}\\\utilde{h}_{\eta} \end{bmatrix}.$ Then, define the remainder $R_n(\utilde{\gamma}^{\circ};\utilde{h})$ via 
$$
\utilde{S_n}(\utilde{\gamma}^{\circ} + n^{-1/2}\utilde{h}) = \utilde{S_n}(\utilde{\gamma}^{\circ}) - \utilde{J}(\utilde{\gamma}^{\circ})\utilde{h} + R_n(\utilde{\gamma}^{\circ};\utilde{h})
$$
Then, for any finite $0 < M < \infty$
$$
\sup_{|\utilde{h}_{\eta}| \leq M}|R_n(\utilde{\gamma}^{\circ};\utilde{h})| \xrightarrow{p} 0
$$
where $\utilde{h}_{\theta} = \utilde{\theta}^{\circ}$ is fixed.
\end{definition_exam}

\begin{remark}This is a weakened version of the Regular scores assumption as we now hold $\utilde{\theta} = \utilde{\theta}^{\circ}.$ Recall that in regular scores, we required that 
$$
\sup_{|\utilde{h}| \leq M}|R_n(\utilde{\gamma}^{\circ};\utilde{h})| \xrightarrow{p} 0
$$
but now we only require it to hold for the nuisance parameter $\utilde{h}_{\eta}$ component.
\end{remark}

We now define a random variable that will be extremely important for us.
\begin{definition_exam}{Quadratic Form}{}We define the quadratic form 
$$
Q_n = (\utilde{S}_{\theta}^{*})^T(\utilde{J}_{\theta}^{*})^{-1}\utilde{S}_{\theta}^{*} = (\utilde{S}_{\theta}^{*})^T\utilde{J}^{\theta \theta}\utilde{S}_{\theta}^{*} 
$$
where $\utilde{S}_{\theta}^{*}$ is the effective score and $\utilde{J}_{\theta}^{*}$ is the effective information. That is $
\utilde{J}^{\theta \theta} = \bigg(\utilde{J}_{\theta \theta} - \utilde{J}_{\theta \eta}\utilde{J}_{\eta \eta}^{-1}\utilde{J}_{\eta \theta} \bigg)^{-1}
$
\end{definition_exam}

Now, we state the proposition that our classical test statistics are asymptotically equivalent to this quadratic form random variable.
\newpage
\begin{theorem_exam}{Classical Test Equivalence Part 1}{}Suppose that the LAN property holds in the neighbourhood of the true value $\utilde{\gamma}^{\circ} = \begin{bmatrix} \utilde{\theta}^{\circ} \\ \utilde{\eta}^{\circ} \end{bmatrix}$ and both the null-regular scores and continuous information also hold at $\utilde{\gamma}^{\circ}.$ Then 
\begin{enumerate}
\item The Rao-Score Statistic $R = Q_n + o_p(1)$
\item The Wald-Score Statistic $W = Q_n + o_p(1)$
\item The Neyman-Rao Statistic $NR = Q_n + o_p(1)$
\end{enumerate}
\end{theorem_exam}

\begin{proof} First, recall the Rao Score test which has the test statistic 
$$
R = S_{\theta}(\hat{\utilde{\gamma_n}}^{\circ})^T\hat{J}^{\theta \theta}S_{\theta}(\hat{\utilde{\gamma_n}}^{\circ})
$$
where $\hat{\utilde{\gamma_n}}^{\circ}$ is a constrained asymptotically efficient estimator of the nuisance parameter with the parameter of interest fixed at the hypothesised value $\utilde{\theta} = \utilde{\theta}^{\circ}.$ Then, by first part of the theorem on the expression of the effective score

$$\utilde{S}_{\theta}(\utilde{\theta}^{\circ};\hat{\utilde{\eta_{n}}}^{\circ}) = \utilde{S}_{\theta}^{*}(\utilde{\theta}^{\circ};\utilde{\eta_{n}}^{\circ}) + o_p(1)$$

and by continuity of information, we have that the Rao Score test
\begin{equation}
R = S_{\theta}(\hat{\utilde{\gamma_n}}^{\circ})^T\hat{J}^{\theta \theta}S_{\theta}(\hat{\utilde{\gamma_n}}^{\circ}) = \utilde{S}_{\theta}^{*}(\utilde{\gamma_n}^{\circ})^T\utilde{\hat{J}}^{\theta \theta}\utilde{S}_{\theta}^{*}(\utilde{\gamma_n}^{\circ}) = Q_n
\tag{1}
\end{equation}



Now, recall that the Neyman-Rao test has the test statistic 
$$
NR = S_{\theta}^{*}(\tilde{\utilde{\gamma_n}}^{\circ})^T\hat{J}^{\theta \theta}S_{\theta}^{*}(\tilde{\utilde{\gamma_n}}^{\circ})
$$
where $\tilde{\utilde{\gamma_n}}^{\circ}$ is a constrained $\sqrt{n}$-consistent estimator of the nuisance parameter with the parameter of interest fixed at the hypothesised value $\utilde{\theta} = \utilde{\theta}^{\circ}.$ Now, recall the second part of the theorem on the expression of the effective score

$$\utilde{S}_{\theta}^{*}(\utilde{\theta}^{\circ};\tilde{\utilde{\eta_{n}}}^{\circ}) = \utilde{S}_{\theta}^{*}(\utilde{\theta}^{\circ};\utilde{\eta_{n}}^{\circ}) + o_p(1)$$

and by continuity of the information assumption, we have that the Neyman-Rao test 
\begin{equation}
NR = S_{\theta}^{*}(\tilde{\utilde{\gamma_n}}^{\circ})^T\hat{J}^{\theta \theta}S_{\theta}^{*}(\tilde{\utilde{\gamma_n}}^{\circ}) = S_{\theta}^{*}({\utilde{\gamma_n}}^{\circ})^T\hat{J}^{\theta \theta}S_{\theta}^{*}({\utilde{\gamma_n}}^{\circ}) = Q_n
\tag{2}
\end{equation}

Finally, recall that the Wald test has the test statistic 
$$
W = n(\hat{\utilde{\theta_n}} - \utilde{\theta}^{\circ})^T\hat{\utilde{J}_{\theta}}^{*}(\hat{\utilde{\theta_n}} - \utilde{\theta}^{\circ})
$$
where $\hat{\utilde{\theta_n}}$ is an asymptotically efficient estimator of the parameter of interest. Now, recall that an asymptotically efficient estimator $\hat{\utilde{\theta_n}}$ can have its estimation error written as 
$$
\sqrt{n}\bigg[\hat{\utilde{\theta_n}} - \utilde{\theta^{\circ}} \bigg] = (\utilde{J_{\theta}^{*}})^{-1}\utilde{S_{\theta}}^{*} + o_p(1)
$$

Hence, we can rewrite the Wald test statistic 
\begin{equation}
W = n(\hat{\utilde{\theta_n}} - \utilde{\theta}^{\circ})^T\hat{\utilde{J}_{\theta}}^{*}(\hat{\utilde{\theta_n}} - \utilde{\theta}^{\circ}) = (\utilde{S_{\theta}}^{*})^T ((\utilde{J_{\theta}^{*}})^{-1})^T  \utilde{J}_{\theta}^{*} ((\utilde{J_{\theta}^{*}})^{-1}) \utilde{S_{\theta}}^{*} = S_{\theta}^{*}({\utilde{\gamma_n}}^{\circ})^T\hat{J}^{\theta \theta}S_{\theta}^{*}({\utilde{\gamma_n}}^{\circ}) = Q_n
\tag{3}
\end{equation}

\end{proof}

Now, in order to handle the likelihood ratio test, we need to strengthen the LAN assumption where we replace the pertubation $\utilde{h}$ with a random version $\sqrt{n}[\hat{\utilde{\gamma}^n} - \utilde{\gamma}^{\circ}].$ That is, recall that in the LAN assumption, we have that for each fixed $\utilde{h}$, the remainder term goes to zero in probability. 

\begin{definition_exam}{Uniform LAN Condition}{}Define the log likelihood ratio of two nearby values 
$$
L_n(\utilde{\gamma}^{\circ} + n^{-1/2}\utilde{h}; \utilde{\gamma}^{\circ}) = \sum_{i=1}^{n}log\;p_{\utilde{\gamma}^{\circ} + n^{-1/2}\utilde{h}}(\utilde{X_i}) - \sum_{i=1}^{n}log\;p_{\utilde{\gamma}^{\circ}}(\utilde{X_i}) 
$$
We say that the Uniform LAN propety (ULAN) holds at $\utilde{\gamma}^{\circ}$ if there exists a score vector $\utilde{S_n}$ and a symmetric positive definite information matrix $\utilde{J}$ such that the remainder defined by 
$$
L_n(\utilde{\gamma}^{\circ} + n^{-1/2}\utilde{h}; \utilde{\gamma}^{\circ}) = \utilde{h}^T\utilde{S_n} - \frac{1}{2}\utilde{h}\utilde{J}^T\utilde{h} + R_n(\utilde{\gamma}^{\circ}; \utilde{h})
$$
satisfies a uniformly bounded $\utilde{h}$ where for any $0 < M < \infty$
$$
\sup_{|h| \leq M}|R_n(\utilde{\gamma}^{\circ};\utilde{h})| \xrightarrow{p} 0.
$$
In other words, LAN holds uniformly in bounded $\utilde{h}.$
\end{definition_exam}

\begin{remark}First, note that in the normal LAN, we had that the remainder goes to zero for a fixed h. Now, it goes to zero for a range of bounded h, that is, we can now plug in a random $\utilde{h}$ given by 
$$
\utilde{h} = \sqrt{n}[\hat{\utilde{\gamma_n}} - \utilde{\gamma}^{\circ}].
$$
\end{remark}

\begin{proposition_exam}{Conditions for ULAN}{}The restrictive conditions for the LAN property implies that the ULAN property holds.
\end{proposition_exam}

\begin{proof} Under the restrictive assumptions for LAN, we can do a third order Taylor expansion of the log likelihood ratio. From that, we can show that the linear term converges in distribution to a normal distribution, the quadratic term converges in probability to $-\utilde{J}$ and the cubic term is the remainder that goes to zero. 
\end{proof}


We can now write the expression of log likelihood ratios under ULAN, which we will need in the proof of the limiting distribution of the likelihood ratio statistic.

\begin{lemma}(Expression of likelihood-ratio under ULAN). Suppose that the ULAN property holds at $\utilde{\gamma}^{\circ} = \begin{pmatrix}\utilde{\theta}^{\circ}\\ \utilde{\eta}^{\circ} \end{pmatrix}$. Denote $L_n(.)$ to be the log likelihood ratio.
\begin{enumerate}
\item If $\hat{\utilde{\gamma}_n}$ is an unconstrained asymptotically efficient estimator for the whole vector, then 
$$
L_n(\hat{\utilde{\gamma}_n};\utilde{\gamma}^{\circ}) = \frac{1}{2}\utilde{S}^{T}(\utilde{\gamma}^{\circ})^T\utilde{J}(\utilde{\gamma}^{\circ})^{-1}\utilde{S}(\utilde{\gamma}^{\circ}) + o_p(1)
$$
where $\utilde{S}$ is the score vector.
\item If $\hat{\utilde{\gamma}_n}^{\circ} = \begin{pmatrix}\utilde{\gamma}^{\circ} \\ \hat{\utilde{\eta}_n}^{\circ} \end{pmatrix}$  is a constrained asymptotically efficient estimator of the nuisance parameter $\eta$, then 
$$
L_n(\hat{\utilde{\gamma}_n}^{\circ};\utilde{\gamma}^{\circ}) = \frac{1}{2}\utilde{S_{\eta}}^{T}(\utilde{\gamma}^{\circ})^T\utilde{J_{\eta \eta}}(\utilde{\gamma}^{\circ})^{-1}\utilde{S_{\eta}}(\utilde{\gamma}^{\circ}) + o_p(1)
$$
\end{enumerate}
\end{lemma}

\begin{remark}Note that the second case is a special case of the first case whereby we are now only estimating the nuisance parameter.
\end{remark}

\begin{theorem_exam}{Classical Test Equivalence Part 2}{}Suppose that the ULAN property holds at $\utilde{\gamma}^{\circ},$ we then have that the likelihood-ratio statistic
$$
LR = Q_n^2 + o_p(1).
$$
\end{theorem_exam}

Hence, we see that all 4 classical tests are asymptotically equivalent as they all converge to the same quadratic form random variable $Q_n.$

\lecture{25}{Properties of test statistics}
\section{Hypothesis Testing}
\subsection{Properties of test statistics}
\textit{In this lecture, we look at local alternatives for hypothesis testing. We first introduce the central and non-central Chi-squared distributions. Then, we show that the limiting behaviour of classical test statistics under the null alternative is a $\chi^2$-distribution under $H_0$ for any value of the nuisance parameter due to asymptotic similarity and a non-central $\chi^2$-distribution under the alternative hypothesis.}

First, recall that we have shown that all classical tests are asymptotically equivalent to the quadratic form 
$$
Q_n = (\utilde{S_{\theta}}^{*})^T\utilde{J}^{\theta \theta}(\utilde{S_{\theta}}^{*}).
$$

Therefore, we can deduce various properties of the classical tests by analysing the properties of $Q_n.$

\subsubsection{Limiting Distribution Under Null Hypothesis}
\begin{proposition_exam}{Limiting distribution of $Q_n$ under null hypothesis}{}If the parameter of interest has dimension $d_{\theta},$ then, when $H_0$ is true, we have that the limiting distribution of $Q_n$ is 
$$
Q_n \xrightarrow{d} \chi_{d_{\theta}}^2.
$$
\end{proposition_exam}

We will now prove why is this proposition true. First, recall a fact from linear algebra.

\begin{definition}(Eigendecomposition of a matrix). Let $\utilde{\Sigma}$  be a matrix of full rank. We can then express it in terms of its eigendecomposition
$$
\utilde{\Sigma} = \utilde{U}\utilde{D}\utilde{U}^T
$$
where $\utilde{U}$ is an orthogonal matrix which contains eigenvectors and $\utilde{D}$ is a diagonal matrix containing eigenvalues, whose diagonal elements are all positive.
\end{definition}

\begin{lemma}If $\utilde{U}$ is an orthogonal matrix, then 
$$
\utilde{U}\utilde{U}^T = \mathbb{I}.
$$
\end{lemma}

We can now state the proposition that will help us prove that the quadratic form has a $\chi^2-$distribution.

\begin{proposition}Suppose that we have the multivariate normal 
$$
\utilde{X} \sim \mathcal{N}(\utilde{0}, \utilde{\Sigma})
$$
where $\utilde{X}$ has dimension d and the covariance matrix $\utilde{\Sigma}$ has full rank d, then 
$$
\utilde{X}^T\utilde{\Sigma}^{-1}\utilde{X} \sim \chi_d^2.
$$
\end{proposition}

\begin{proof} First, due to the eigendecomposition of a full rank vector, we have that we can express the covariance matrix as 
$$
\utilde{\Sigma}^{-1/2} = \utilde{U}\utilde{D}^{-1/2}\utilde{U}
$$
where $\utilde{D}^{-1/2}$ is the inverse square root of the diagonal entries of $\utilde{D}.$ Then, we can do a change of variables where for $\utilde{X} \sim \mathcal{N}(\utilde{0}, \utilde{\Sigma})$, we can write the rescaled random variable 
$$
\utilde{Z} = \utilde{\Sigma}^{-1/2}\utilde{X}.
$$
This new random variable has mean zero 
$$
\mathbb{E}[\utilde{Z}] = \utilde{\Sigma}^{-1/2}\mathbb{E}[\utilde{X}] = \utilde{0}
$$
and its variance is given by 
$$
\mathbb{E}[\utilde{Z}\utilde{Z}] = \utilde{\Sigma}^{-1/2}\mathbb{E}[\utilde{X}\utilde{X}]\utilde{\Sigma}^{-1/2}
$$
$$
= \utilde{\Sigma}^{-1/2}\utilde{\Sigma}\utilde{\Sigma}^{-1/2}
$$
$$
= \utilde{U}\utilde{D}^{-1/2}\utilde{U}^T\utilde{U}\utilde{D}\utilde{U}^T\utilde{U}\utilde{D}^{-1/2}\utilde{U}^T
$$
$$
= \utilde{U}\utilde{D}^{-1/2}\utilde{D}\utilde{D}^{-1/2}\utilde{U}^T = \utilde{U}\utilde{U}^T = \mathbb{I}
$$
Therefore, $\utilde{Z}$ consists of d i.i.d $\mathcal{N}(\utilde{0}, \mathbb{I})$ random variables and therefore, the sum of squares of $\utilde{Z}$ is a $\chi^2$-distribution. Therefore, we have that
$$
\utilde{Z}^T\utilde{Z} = \utilde{X}^T\utilde{\Sigma}^{-1/2}\utilde{\Sigma}^{-1/2}\utilde{X}
$$
$$
= \utilde{X}^T\utilde{\Sigma}^{-1}\utilde{X} \sim \chi_{d}^2.
$$
\end{proof}

We can therefore apply the above proposition to our quadratic form!
\begin{corollary}Recall that the effective score $(\utilde{S_{\theta}}^{*})$ is an asymptotically normal distribution with the effective information matrix as its variance and the inverse covariance matrix is $\utilde{J}^{\theta \theta}$. Therefore, we have that the limiting distribution is

$$(\utilde{S_{\theta}}^{*})^T\utilde{J}^{\theta \theta}(\utilde{S_{\theta}}^{*}) \sim \chi_{d_{\theta}}^{2}$$
\end{corollary}

\begin{definition_exam}{Asymptotic Similarity}{}Suppose that the null hypothesis is true $\utilde{\theta} = \utilde{\theta}_0.$ Then, asymptotic similarity is when the limiting distribution of the test statistic is the same for any nuisance parameter $\utilde{\eta}.$
\end{definition_exam}

\begin{corollary}The Quadratic form $Q_n$ has the property of asymptotic similarity.
\end{corollary}

\subsubsection{Limiting Distribution Under Nearby Alternatives}
Recall that Le Cam's third lemma tells us what happens to the limiting distribution when we perturb the true value. We now want to investigate the limiting distribution of the quadratic form under nearby alternatives. First of all, recall that Le Cam's third lemma gives the limiting distribution under local alternatives of the form 
$$
\utilde{\gamma_n}^{\circ} = \utilde{\gamma}^{\circ} + n^{-1/2}\utilde{h} = \begin{pmatrix} \utilde{\theta^{\circ}} \\ \utilde{\eta^{\circ}} \end{pmatrix} + n^{-1/2}\begin{pmatrix} \utilde{h_{\theta}} \\ \utilde{h_{\eta}}
\end{pmatrix}
$$

So, first of all, recall that the score vector 
$$
\utilde{S} = \begin{pmatrix}\utilde{S_{\theta}}\\\utilde{S_{\eta}} \end{pmatrix}
$$
has the limiting distribution under the true value $\utilde{\gamma}^{\circ}$
$$
\utilde{S} \xrightarrow{d} \mathcal{N}(\utilde{0}, \utilde{J})
$$
where $\utilde{J}$ is the information matrix and under the nearby sequence $\utilde{\gamma_n}^{\circ}$
$$
\utilde{S} \xrightarrow{d} \mathcal{N}(\utilde{J}\utilde{h}, \utilde{J})
$$
where 
$$
\utilde{h} = \begin{pmatrix}\utilde{h_{\theta}}\\\utilde{h_{\eta}} \end{pmatrix}
$$

\begin{lemma}Let $\utilde{S}$ be the full score vector. Then, for any matrix $\utilde{M}$ with $d = d_{\theta} + d_{\eta}$ columns, we have that 
$$
\utilde{M}\utilde{S} \xrightarrow{d}
\begin{cases}
\mathcal{N}(\utilde{0}, \utilde{M}\utilde{J}\utilde{M}^T) \quad \text{under } \utilde{\gamma}^{\circ}  \\\\

\mathcal{N}(\utilde{M}\utilde{J}\utilde{h}, \utilde{M}\utilde{J}\utilde{M}^T) \quad \text{under } \utilde{\gamma_n}^{\circ}
\end{cases}
$$
\end{lemma}

We are now interested in the case of the limiting distribution of the effective score, which can be written as $\utilde{M}\utilde{S}$ where $\utilde{M} = (\utilde{I}, -\utilde{J_{\theta \eta}}\utilde{J_{\eta \eta}^{-1}}).$

\begin{proposition_exam}{Limiting distribution of effective score under alternative}{} The limiting distribution of the effective score under the alternative $\utilde{\gamma_n}^{\circ}$ is given by 
$$
\utilde{S_{\theta}}^{*} \xrightarrow{d} \mathcal{N}(\utilde{J_{\theta}}^{*} \utilde{h_{\theta}}, \utilde{J_{\theta}}^*)
$$
where $\utilde{J_{\theta}}^*$ is the effective information.
\end{proposition_exam}

Note that this distribution is free of $\utilde{h_{\eta}}$, which is an important property.

\begin{definition_exam}{Regularity}{}If the limiting distribution is free of the nuisance parameter $\utilde{h_{\eta}}$, then it is known as the property of regularity.
\end{definition_exam}

In hypothesis testing, we specify a value of $\utilde{\theta}$ for our null hypothesis. Therefore, if we change $\utilde{\theta},$ we expect the test statistic to change and depend on $\utilde{h_{\theta}}.$ However, we do not want to detect a change in $\utilde{\eta}$ and in fact, to ignore any changes from $\utilde{h_{\eta}}.$ This is what regularity guarantees for us. 

\begin{corollary}For $\utilde{h_{\theta}} = \utilde{0},$ the limiting distribution is $\chi_{d_{\theta}}^{2}$ regardless of the value of $\utilde{h_{\eta}}$.
\end{corollary}
\begin{remark}This can be thought of as a local version of asymptotic similarity.
\end{remark}

Therefore, we can conclude from this section that if we have a regular model, we always will have a limiting distribution of $$\chi_{d_{\theta}}^{2}$$ regardless of the nuisance parameter $\utilde{h_{\eta}}.$

Now, we are interested in what happens when we shift $\utilde{h_{\theta}}.$ First, we introduce a distribution which we will need later.
\begin{definition_exam}{Non-central Chi-squared distribution}{}Let $X_1,...,X_d$ be independent random variables with $X_i \sim \mathcal{N}(\mu_i, 1)$. Then, the random variable 
$$
S = \sum_{i=1}^{d}X_i^2 \sim \chi_d^2(\delta)
$$
where $\delta = \sum_{i=1}^{d}\mu_i^2$ is said to have a non-central Chi-squared distribution with d degrees of freedom and \textbf{noncentrality parameter} $\delta.$
\end{definition_exam}

Now, recall that under the local alternative $\utilde{\gamma_n}^{\circ}$, we have that the effective score 
$$
\utilde{S_{\theta}}^{*} \xrightarrow{d} \mathcal{N}(\utilde{J_{\theta}}^{*} \utilde{h_{\theta}}, \utilde{J_{\theta}}^*)
$$
where $\utilde{J_{\theta}}^*$ is the effective information. We are now interested in what is the limiting distribution under the alternative for the quadratic form 
$$
Q_n = (\utilde{S_{\theta}}^{*})^T (\utilde{J_{\theta}}^{*})^{-1} (\utilde{S_{\theta}}^{*}) = (\utilde{S_{\theta}}^{*})^T (\utilde{J}^{\theta \theta}) (\utilde{S_{\theta}}^{*})
$$

First, let us define the random variable 
$$
\utilde{Z} = (\utilde{J}^{\theta \theta})^{1/2}\utilde{S_{\theta}}^{*} = (\utilde{J}_{\theta}^{*})^{-1/2}\utilde{S_{\theta}}^{*}
$$

Then, we can show that 
$$
\mathbb{E}[\utilde{Z}] = (\utilde{J}_{\theta}^{*})^{-1/2}\utilde{J_{\theta}}^{*}\utilde{h_{\theta}}
$$
and the limiting covariance matrix is 
$$
\mathbb{E}[\utilde{Z}\utilde{Z}^T] = \mathbb{I}.
$$

Therefore, $\utilde{Z}$ consists of asymptotically normal random variables with variance $\mathbb{I}.$ Therefore, the sum of squares $\utilde{Z}^T\utilde{Z}$ is a $\chi^2$-distribution. Finally, we can show that 
$$
\utilde{Z}^T\utilde{Z} = Q_n
$$
and hence is equal to our quadratic form.

\begin{proposition_exam}{Limiting distribution of $Q_n$ under alternative hypothesis}{}If the parameter of interest has dimension $d_{\theta},$ then, under a local alternative, we have that the limiting distribution of $Q_n$ is 
$$
Q_n \xrightarrow{d} \chi_{d_{\theta}}^2(\delta_{\theta}).
$$
where $\delta_{\theta} = \utilde{h}_{\theta}^T \utilde{J}_{\theta}^* \utilde{h}_{\theta}$ is the non-centrality parameter.
\end{proposition_exam}

This non-centrality parameter $\delta_{\theta} = \utilde{h}_{\theta}^T \utilde{J}_{\theta}^* \utilde{h}_{\theta}$ is the biggest that the non-centrality can be. We will investigate this further in the next lecture.


Under null hypothesis, we have Chi-squared regardless of the nuisance parameter due to asymptotic similarity.
\lecture{26}{Regular Quadratic Form Test Statistics}
\section{Hypothesis Testing}
\subsection{Regular Quadratic Form Test Statistics}

\textit{In this lecture, we first define the equivalence of RAJN estimators in the context of testing, which are regular quadratic form test statistics. That is, within this class of quadratic form tests, which are based on test statistics constructed from statistics that are AJN with the scores vector, we derive the efficiency of all classical tests within this class. We then derive the limiting distribution of regular quadratic form test statistics, which is a non-central chi-squared distribution. Finally, we show that if we have a test statistic with $K > d_{\theta}$ variables, we can get a more powerful test by transforming our test statistic to only use $d_{\theta}$ variables.}

First, we define the equivalence of a regular estimator in the context of testing.
\begin{definition_exam}{Regular Test Statistic}{}An asymptotically similar test statistic $T_n$ is regular at $\utilde{\gamma_0}$ if under the nearby sequence 
$$
\utilde{\gamma_n}^{\circ} = \begin{pmatrix}\utilde{\theta}^{\circ}\\\utilde{\eta}^{\circ} \end{pmatrix} + n^{-1/2}\begin{pmatrix}
\utilde{h}_{\theta}\\
\utilde{h}_{\eta}
\end{pmatrix}
$$
the limiting distribution satisfies the 2 conditions 
\begin{enumerate}
\item The limiting distribution possibly depends on $\utilde{\gamma_0}$, $\utilde{h_{\theta}}$ but not $\utilde{h_{\eta}}$
\item For any $\utilde{h_{\theta}} \neq \utilde{0}$, this differs from that under the null hypothesis $\utilde{\gamma_0}$
\end{enumerate}
\end{definition_exam}

\begin{remark}Notice that for regularity, we require that the distribution changes if we shift in the $\utilde{\theta}$ direction.
\end{remark}

The reason that we require the second condition for a regular test statistic is to assure local power in every direction of $\utilde{h_{\theta}}.$ That is, for tests with smooth power functions, this is akin to requiring partial derivatives of the power function with respect to $\theta$ to be non-zero and partial derivatives with respect to $\eta$ to be zero.

We now define the equivalence of an AJN estimator in the context of testing. In fact, we will restrict our test statistics to be of the following class.

\begin{definition_exam}{Quadratic Form Test Statistic}{}A test statistic $T_n$ for testing $H_0$ is a quadratic form test statistic if under the null hypothesis $\utilde{\gamma}_0 = \begin{pmatrix}\utilde{\theta}_0 \\ \utilde{\eta}_0 \end{pmatrix}$ can be written as 
$$
T_n = \utilde{Y_n}^T\utilde{\Sigma}_Y^{-1}\utilde{Y_n} + o_p(1)
$$
for some K-vector $\utilde{Y_n}$ ($K \geq d_{\theta}$) satisfying LAN\# with a non-singular asymptotic covariance matrix $\Sigma_Y.$
\end{definition_exam}

\begin{remark} Recall that under LAN\#, we have that $\utilde{Y_n}$ is AJN with the scores vector. The reason we require $\utilde{Y_n}$ to satisfy LAN\# is to ensure asymptotic similarity.
\end{remark}

We now state the limiting distribution of a regular quadratic form test statistic.

\begin{proposition_exam}{Non-Centrality of a regular quadratic form test statistic}{}Suppose that $T_n$ is a regular quadratic form test statistic. 

Now, as $T_n$ is a quadratic form test statistic, then under the local alternative $\utilde{\gamma_n}^{\circ} = \utilde{\gamma}^{\circ} + n^{-1/2}\utilde{h}$, the limiting distribution is 
$$
T_n \xrightarrow{d} \chi_k^2(\delta)
$$
with the non-centrality parameter being $\delta = \utilde{h}^T\utilde{\Sigma}_{SY}\utilde{\Sigma}_{Y}^{-1}\utilde{\Sigma}_{YS}\utilde{h}$ and is asymptotically similar.

Now, as $T_n$ is a regular statistic, then the cross covariance with the scores of interest $\Sigma_{Y S_{\theta}}$ is of rank $d_{\theta}$ and the cross covariance with the nuisance parameter is 0
$
\Sigma_{Y S_{\eta}} = \utilde{0}
$
in which case, the non-centrality parameter simplifies as it now only depends on $\theta$
$$
\delta = \utilde{h_{\theta}}^T\Sigma_{S_{\theta}^{*}Y}\Sigma_{Y}^{-1}\Sigma_{YS_{\theta}^{*}}\utilde{h_{\theta}}
$$
as $\Sigma_{Y S_{\theta}} = \Sigma_{Y S_{\theta}^{*}}$.
\end{proposition_exam}

\begin{remark}What this proposition state is that because $T_n$ is a quadratic form test statistic, then we have a non-central $\chi^2$-distribution under the local alternative. Furthermore, because $T_n$ is regular, then the cross-covariance with the score of the nuisance parameter is zero and therefore the non-centrality parameter simplifies.
\end{remark}

We will later show that the non-centrality parameter of the classical test statistics under the alternative hypothesis can be no bigger than $\delta = \utilde{h_{\theta}}^T\Sigma_{S_{\theta}^{*}Y}\Sigma_{Y}^{-1}\Sigma_{YS_{\theta}^{*}}\utilde{h_{\theta}}.$

First, we recall another fact from linear algebra.
\begin{lemma}Suppose that the quadratic form test statistic $T_n = \utilde{Y_n}^{T}\utilde{\Sigma_Y}^{-1}\utilde{Y_n}$ for $\utilde{Y_n}$ satisfying LAN\# with asymptotic covariance matrix $\utilde{\Sigma_Y}.$ Then 
$$
T_n = \utilde{Z_n}^T\utilde{Z_n}
$$
where $\utilde{Z_n} = \utilde{\Sigma_Y}^{-1/2}\utilde{Y_n}$ where now $\utilde{Z_n}$ satisfies LAN\# with limiting covariance matrix $\mathbb{I}.$
\end{lemma}

Our next proposition shows that if our statistic has dimension $K > d_{\theta}$, we should restrict it to transform it to only look at $K = d_{\theta}$ in order to gain power for our test.

\begin{proposition_exam}{Power in a test is in first $d_{\theta}$ components}{}Suppose that the test statistic 
$$
T_n = \utilde{Y_n}^T\utilde{Y_n}
$$
is a regular quadratic form test statistic for a K-dimensional vector $\utilde{Y_n}$ where $K > d_{\theta}.$ Then, there exists an orthogonal K x K matrix $(A , B)$ where A has $d_{\theta}$ columns such that we can construct 2 new vectors 
$$
\begin{pmatrix}
U_n\\
V_n
\end{pmatrix}
= 
\begin{pmatrix}
A^T\\
B^T
\end{pmatrix}Y_n.
$$
Then, under a nearby sequence $\utilde{\gamma_n}^{\circ} = \utilde{\gamma^{\circ}} + n^{-1/2}\begin{pmatrix}\utilde{h_{\theta}}\\\utilde{h_{\eta}} \end{pmatrix}$, we can rewrite the original statistic 
$$
T_n = \utilde{Y_n}^T\utilde{Y_n} = \utilde{U_n}^T\utilde{U_n} + \utilde{V_n}^T\utilde{V_n}
$$
where we have that 
$$
\utilde{U_n}^T\utilde{U_n} \xrightarrow{d} \chi_{d_{\theta}}^{2}(\delta)
$$
$$
\utilde{V_n}^T\utilde{V_n} \xrightarrow{d} \chi_{K - d_{\theta}}^{2}(0)
$$
where $\chi_{d_{\theta}}^{2}(\delta)$ is a non-central chi-squared distribution and $\chi_{K - d_{\theta}}^{2}(0)$ is a central chi-squared distribution.

Furthermore, $\utilde{U_n}^T\utilde{U_n}$ and $\utilde{V_n}^T\utilde{V_n}$ are asymptotically independent, which implies that 
$$
\utilde{U_n}^T\utilde{U_n} + \utilde{V_n}^T\utilde{V_n} \sim \chi_{K}^{2}(\delta)
$$
with non-centrality parameter $\delta  = \utilde{h_{\theta}}^T\Sigma_{S_{\theta}^{*}Y}\Sigma_{Y}^{-1}\Sigma_{YS_{\theta}^{*}}\utilde{h_{\theta}}.$
\end{proposition_exam}

\begin{remark}Any regular quadratic form test statistic in K variables $(K > d_{\theta})$ may be characterised as the sum of $d_{\theta}$ variables that carries all the signal and another $(K - d_{\theta})$ which carries only added noise. Therefore, using only $\utilde{U_n}^T\utilde{U_n}$ instead of $\utilde{Y_n}^T\utilde{Y_n}$ increases the power of our test as the non-centrality parameter is the signal. That is, the non-centrality is the signal, the characteristic that makes it differ from its null hypothesis behaviour.
\end{remark}

\begin{corollary}We will restrict attention to regular quadratic form statistics in $d_{\theta}$ variables.
\end{corollary}
\begin{remark}If we have more than $d_{\theta}$ variables, we can reduce it using the orthogonal matrix and therefore get a more powerful test.
\end{remark}


\lecture{27}{Orthogonal Decomposition Of Tests}
\section{Hypothesis Testing}

In this lecture, will do an analogue of the orthogonal decomposition theorem whereby we will show that in the class of regular quadratic form test statistics, we can't get better power than the classical statistics.

\subsection{Positive Definite Matrices}
We first recall some things from linear algebra.
\begin{definition_exam}{Positive Definite Matrix}{}A d-by-d matrix M is positive definite if for all $\utilde{h} \in \mathbb{R}^d$ where $\utilde{h} \neq \utilde{0},$ we have that 
$$
\utilde{h}^T\utilde{M}\utilde{h} > 0.
$$
We then write that $\utilde{M} > 0.$
\end{definition_exam}

\begin{remark}We say that M is positive semi-definite if for all $\utilde{h} \in \mathbb{R}^d$ where $\utilde{h} \neq \utilde{0}$ if
$$
\utilde{h}^T\utilde{M}\utilde{h} \geq 0
$$
\end{remark}

\begin{lemma}If $\utilde{M} > 0$, then $\utilde{M}$ is invertible.
\end{lemma}

Now, note that if 
$$
\utilde{M} - \utilde{N} \geq 0
$$
we can write $\utilde{M} \geq \utilde{N}.$

\begin{claim}If $\utilde{M} \geq \utilde{N} > \utilde{0}$ and $\utilde{M} > \utilde{0}$. Then 
$$
\utilde{N}^{-1} \geq \utilde{M}^{-1} > 0.
$$
\end{claim}

\subsection{Orthogonal Decomposition Of Tests}
Recall that we can restrict our attention to $d_{\theta}$ variables for regular quadratic form test statistics. We now will develop an analogue for orthogonal decomposition in the context of hypothesis testing.

Suppose that $T_n$ is a regular quadratic form statistic in $\utilde{Y_n}$ of length $d_{\theta}$ such that it has the LAN\# property, which means that
$$
\begin{pmatrix}
Y_n\\
S_{\theta}\\
S_{\eta}
\end{pmatrix}
\xrightarrow{d}
\mathcal{N}(\utilde{0}, \begin{pmatrix} \Sigma_Y & \Sigma_{Y S_{\theta}} & \utilde{0}\\ \Sigma_{S_{\theta}Y} & J_{\theta \theta} & J_{\theta \eta}\\ \utilde{0} & J_{\eta \theta} & J_{\eta \eta})\\
\end{pmatrix})
$$
where $\Sigma_{Y S_{\theta}}$ is of rank $d_{\theta}$ (full-rank) and is invertible. We can do an implicit transformation and assume that $\Sigma_{Y S_{\theta}} = \utilde{I}.$

\begin{lemma}We can always express a regular quadratic test statistic $T_n$ with a cross-covariance with the score 
$$
\Sigma_{Y S_{\theta}} = \utilde{I}.
$$
\end{lemma}

We will illustrate on why is this the case. First, define the new variable
$$
\utilde{Z_n} = \Sigma_{Y S_{\theta}}^{-1}\utilde{Y_n}.
$$
Now, we can express the test statistic 
$$
T_n = \utilde{Y_n}^T\utilde{\Sigma_{Y_{n}}}^{-1}\utilde{Y_n} + o_p(1) = \utilde{Z_n}^T\utilde{\Sigma_{YS_{\theta}}}\utilde{\Sigma_{Y}}^{-1}\utilde{\Sigma_{S_{\theta}Y}}\utilde{Z_n}
$$

From this, $\utilde{Z_n}$ also satisfies the LAN\# property whereby
$$
\begin{pmatrix}
\utilde{Z_n}\\
S_{\theta}\\
S_{\eta}
\end{pmatrix}
\xrightarrow{d}
\mathcal{N}(\utilde{0}, \begin{pmatrix} \Sigma_Y & \utilde{I} & \utilde{0}\\ \utilde{I} & J_{\theta \theta} & J_{\theta \eta}\\ \utilde{0} & J_{\eta \theta} & J_{\eta \eta})\\
\end{pmatrix})
$$


Finally, we can now define the remainder as 
\begin{equation}
\utilde{R_n} = \utilde{Z_n} - (J_{\theta}^{*})^{-1}S_{\theta}^{*}
\tag{*}
\end{equation}
where $(J_{\theta}^{*})^{-1}$ is the inverse of the effective information and  $S_{\theta}^{*}$ is the effective score. 

\begin{lemma}The asymptotic covariance of the effective score and regular of $\theta$ is 
$$
\mathbb{E}[(S_{\theta}^*)S_{\theta}^T] = J_{\theta}^*
$$
The asymptotic covariance of the effective score of $\theta$ and the score of the nuisance parameter is 
$$
\mathbb{E}[(S_{\theta}^*)S_{\eta}^T] = \utilde{0}
$$
\end{lemma}

Additionally, we have the remainder $\utilde{R_n}$ also satisfies the LAN\# property
$$
\begin{pmatrix}
\utilde{R_n}\\
S_{\theta}\\
S_{\eta}
\end{pmatrix}
\xrightarrow{d}
\mathcal{N}(\utilde{0}, \begin{pmatrix} \Sigma_R & \Sigma_{R S_{\theta}} & \utilde{0}\\ \Sigma_{S_{\theta}R} & J_{\theta \theta} & J_{\theta \eta}\\ \utilde{0} & J_{\eta \theta} & J_{\eta \eta})\\
\end{pmatrix})
$$

where we have that $\Sigma_{R S_{\theta}} = \utilde{0}.$ That is, this remainder $\utilde{R_n}$ is uncorrelated with $S_{\theta}.$

From equation (*), we re-arrange the equation to get 
$$
\utilde{Z_n} = (J_{\theta}^{*})^{-1}S_{\theta}^{*} + \utilde{R_n}
$$

\begin{lemma}We can interpret our test statistic $\utilde{Z_n}$ to be the decomposition of a linear combination of the effective score and an asymptotically independent remainder $\utilde{R_n}.$
\end{lemma}

\begin{remark}This is significant as every regular quadratic form test statistic can be decomposed into the optimal variables associated with the classical test statistics and some noise.
\end{remark}

Since we shown that $\Sigma_{R S_{\theta}} = \utilde{0}$, we get the following proposition.

\begin{proposition}Define the random variable $
\utilde{Z_n} = (J_{\theta}^{*})^{-1}S_{\theta}^{*} + \utilde{R_n}.
$ Then, we have that the covariance matrix of $\utilde{Z_n}$ satisfies the following relationship
$$
\Sigma_{Z} = (J_{\theta}^{*})^{-1} + \Sigma_R \geq (J_{\theta}^{*})^{-1}.
$$
where $J_{\theta}^{*}$ is the effective information matrix.
\end{proposition}
\begin{remark}Recall that if X and Y are uncorrelated, then $Var(X+Y) = Var(X) + Var(Y).$
\end{remark}

Then, using the relationship $\Sigma_{Z} \geq (J_{\theta}^{*})^{-1}$, we have that 
$$
J_{\theta}^{*} - \Sigma_{Z}^{-1} \geq \utilde{0}.
$$
Then, by definition of positive semi-definite, for any $\utilde{h_{\theta}} \in \mathbb{R}^d$, we have that 
$$
\utilde{h_{\theta}}^T[J_{\theta}^{*} - \Sigma_{Z}^{-1}]\utilde{h_{\theta}} \geq \utilde{0}.
$$
We have a following result from this.
\begin{theorem}The non-centrality of the regular quadratic form test statistic $T_n$ is given by 
$$
 \utilde{h_{\theta}}^T\Sigma_{Z}^{-1}\utilde{h_{\theta}} \leq  \utilde{h_{\theta}}^TJ_{\theta}^{*}\utilde{h_{\theta}}
$$
with equality only if 
$$
\Sigma_{Z} = (J_{\theta}^{*})^{-1} + o_p(1).
$$
If this is the case, we can then express the test statistic 
$$
T_n = (J_{\theta}^{*})^{-1}S_{\theta}^* + o_p(1) = Q_n + o_p(1)
$$
where $Q_n$ is the quadratic form associated with the classical test statistics.
\end{theorem}

\begin{remark}Recall that the power of a test only depends on the non-centrality of the parameter of the non-central $\chi^2$-distribution. That is, the bigger the non-centrality parameter, the more power in the test.
\end{remark}

Now, regular quadratic form test statistics are the analogue to RAJN estimators and tests that can be expressed in the quadratic form of the classical test statistics is analogous to asymptotically efficient estimators.

\begin{proposition_exam}{Orthogonal Decomposition of Tests}{}For any $d_{\theta}$-dimensional regular quadratic form statistic $T_n$ with an associated vector $\utilde{Y_n},$ we can first express it as $\utilde{Z_n} = \Sigma_{Y S_{\theta}}^{-1}\utilde{Y_n}.$ Then, we can decompose our regular quadratic form test statistic 
$$
\utilde{Z_n} = (J_{\theta}^{*})^{-1}S_{\theta}^{*} + \utilde{R_n}
$$

Then, for under any $\utilde{\gamma_n}^{\circ} = \begin{pmatrix} \utilde{\theta_0} \\ \utilde{\eta_0} \end{pmatrix} + n^{-1/2}\begin{pmatrix}\utilde{h_{\theta}}\\\utilde{h_{\eta}} \end{pmatrix}$, the noncentrality parameter is 
$$
\delta_{\theta} = \utilde{h_{\theta}}^T\utilde{J_{\theta}}^{*}\utilde{h_{\theta}}
$$
with equality only if 
$$
T_n = Q_n + o_p(1).
$$
\end{proposition_exam}

\begin{remark} The power of our test associated with $\utilde{Z_n}$ is the non-centrality parameter $\utilde{h_{\theta}}^T\Sigma_{Z}^{-1}\utilde{h_{\theta}}$, where this achieves the maximal power 
$$
\utilde{h_{\theta}}^T\Sigma_{Z}^{-1}\utilde{h_{\theta}} =  \utilde{h_{\theta}}^TJ_{\theta}^{*}\utilde{h_{\theta}}
$$
when the test statistic can be expressed as the quadratic form of the classical test statistics. Therefore, the noncentrality parameter of our original test statistic now have the same noncentrality parameter of the classical test statistic.
\end{remark}

\begin{corollary}The four classical test statistics has the maximal power, i.e, the highest non-centrality parameter term.
\end{corollary}

In fact, the Neyman-Pearson lemma can be applied to verify that there are in fact the most powerful test statistics.

\begin{definition_exam}{Asymptotically Efficient Test}{} A quadratic form test statistic $T_n$ is asymptotically efficient if it is regular and has noncentrality parameter $
\delta_{\theta} = \utilde{h_{\theta}}^T\utilde{J_{\theta}}^{*}\utilde{h_{\theta}}.
$
\end{definition_exam}


The limiting (local) power is determined by the non-centrality. Thus, the classical tests provides various options for constructing regular quadratic form test statistics, that are optimal according to the decomposition theorem. That is, we have 4 different ways of constructing optimal tests.

The Rao Score statistic R requires a constrained asymptotically efficient estimator of the nuisance parameter $\utilde{\eta}$ and a consistent estimator of the inverse of the effective information $(J_{\theta}^{*})^{-1}.$

The Wald statistic W requires an asymptotically efficient estimator of the parameter of interest $\utilde{\theta}$ and a consistent estimator of the effective information $(J_{\theta}^{*}).$

The Neyman-Rao statistic NR requires a $\sqrt{n}-$consistent estimator of the nuisance parameter $\utilde{\eta}$ and consistent estimators of the various sublocks of the information matrix $J_{\theta \eta}, J_{\eta \eta}^{-1}, J^{\theta \theta}.$

The Likelihood-Ratio statistic needs both an asymptotically efficient estimator $\hat{\utilde{\gamma_n}}$ of the full parameter and a constrained asymptotically efficient estimator 
$$
\hat{\utilde{\gamma}^{\circ}} = 
\begin{pmatrix}
\utilde{\theta}^{\circ}\\
\hat{\utilde{\eta_{n}}^{\circ}}
\end{pmatrix}
$$

In different situations, we use different tests depending on whether can we obtain an asymptotically efficient estimator.

\lecture{28}{Optimality of Bayesian Methods}
\section{Optimality of Bayesian Methods}
\section{Optimality of Bayesian Methods}
\subsection{Introduction to Bayesian Methods}

\textit{In this lecture, we revisit some concepts from Bayesian decision theory and introduce the set up.}

\begin{definition}(Loss function). Let $\utilde{X}$ be the data and $\tilde{\utilde{\theta}}(\utilde{X})$ be our estimator. We define the loss function to be $$D(\tilde{\utilde{\theta}}(\utilde{X})$$.
\end{definition}

\begin{definition}(Risk). Let $D(\tilde{\utilde{\theta}}(\utilde{X})$ be the loss function associated to the estimator $\tilde{\utilde{\theta}}(\utilde{X})$. Then, the Bayes risk is the expectation of the loss function 
$$
R(\utilde{\theta}|\tilde{\utilde{\theta}}(\utilde{X})) = \mathbb{E}_{\utilde{\theta}}[D(\tilde{\utilde{\theta}}(\utilde{X})|\utilde{\theta}].
$$
\end{definition}

\begin{definition_exam}{Conditional Bayes Risk}{} Let $w(.) \geq 0$ be a weight function defined on the parameter space. The conditional Bayes risk is defined as 
$$
B_w(\tilde{\utilde{\theta}}(\utilde{X})) = \int_{\Theta}w(\utilde{\theta})R(\utilde{\theta}|\tilde{\utilde{\theta}}(\utilde{X}))d\utilde{\theta}
$$
\end{definition_exam}

\newpage
\begin{definition_exam}{Bayesian Method}{} Given a prior of weight function $w(.) \geq 0$ defined on the parameter space. A Bayesian method $\hat{\utilde{\theta_B}}$ is one which minimises the conditional Bayes Risk
$$
\int ... \int D(\tilde{\utilde{\theta}}(\utilde{X}); \utilde{\theta})q_n(\utilde{\theta}|\utilde{X})d\utilde{\theta}
$$
where $$q_n(\utilde{\theta}|\utilde{X}) = \frac{w(\utilde{\theta})p(\utilde{X};\utilde{\theta})}{\int ... \int w(\utilde{\theta})p(\utilde{X};\utilde{\theta})}d\utilde{\theta}$$ is the posterior density.
\end{definition_exam}
\begin{remark}Note that we do not require that the weight function $w(.)$ is in $L^1$ but we do require that the posterior density $q_n(\utilde{\theta}|\utilde{X}) \in L^1.$
\end{remark}


\begin{proposition_exam}{Bayes estimator is the posterior mean}{}When the loss function is the squared error loss $(\utilde{\theta_1} - \utilde{\theta_2})^T\utilde{M}(\utilde{\theta_1} - \utilde{\theta_2})$ for a positive definite matrix $\utilde{M}$, then the Bayes estimator is the posterior mean 
$$
\hat{\utilde{\theta_B}} = \int \utilde{\theta}q_n(\utilde{\theta}|\utilde{X})d\utilde{\theta}.
$$
\end{proposition_exam}

We will show in the next sections that if we strengthen the ULAN condition, we can show that the posterior mean $\hat{\utilde{\theta_B}}$ is an asymptotically efficient estimator.

\lecture{29}{Hellinger Distance}
\section{Optimality of Bayesian Methods}
\subsection{Hellinger Distance}


\textit{In this lecture, we will introduce the Hellinger distance. From this, we state propositions which bounds the likelihood ratio as we move away from the true value. We can then introduce the Bayesian ULAN assumption, which we require in order to take integrals on the parameter space.}

\begin{definition_exam}{Hellinger Distance}{}Suppose that $\utilde{X_1},...,\utilde{X_n}$ are i.i.d with density function p(.) that is absolutely continuous with respect to a measure $\nu(.)$, and let $q(.)$ be another density function absolutely continuous with respect to $\nu(.).$ Then, the Hellinger distance is defined as 
$$
H(p,q) = \sqrt{\int \big(\sqrt{p} - \sqrt{q} \big)^2d\nu}.
$$
\end{definition_exam}
\begin{remark}The Hellinger distance is a proper metric.
\end{remark}
\begin{proposition}(Large deviation on likelihood ratio). Suppose $\utilde{X_1},...,\utilde{X_n}$ are i.i.d with density $p(.)$ with respect to a measure $\nu(.)$ and let $q(.)$ be another density such that the $L_2(\nu)-$distance 
$$
\sqrt{\int[\sqrt{p} - \sqrt{q}]^2d\nu} = \epsilon > 0.
$$
Then, the likelihood ratio 
$$
\mathbb{P}\bigg(\prod_{i=1}^{n}\frac{q(\utilde{X_i})}{p(\utilde{X_i})} \geq e^{-\frac{n\epsilon^2}{3}} \bigg) \leq e^{-\frac{n\epsilon^2}{3}}.
$$
\end{proposition}

\begin{remark}This proposition states that if we look at the likelihood ratio away from the true density, then it is exponentially small with an exponentially high probability.
\end{remark}

From the above proposition, if we have a fixed density q, where $q \neq p,$ then it becomes trivially small really quickly as $n \rightarrow \infty.$ Therefore, we require the density q to depend on n. We now want to look at densities that are essentially like a $n^{-1}$ distance away from the true density p(.) as anything further than that goes to zero. Therefore, we can also state an uniform version of the large deviation proposition.
\begin{proposition_exam}{Uniform bound of large deviations of likelihood ratio}{}Suppose that a family of probability densities 
$$
\mathcal{P} = \{p_{\utilde{\theta}}\}
$$
is indexed by a d-dimensional parameter $\utilde{\theta}$ is such that $\sqrt{p_{\utilde{\theta}}}$ is $L_2(\nu)-$differentiable at $\utilde{\theta_0}.$ Then, there exists positive universal constants $A, C_1, C_2, C_3 = C_3(\mathcal{P})$ such that for sufficiently large n, if $\epsilon > C_3n^{-1/2}$ where $C_3n^{-1/2}$ is a threshold value
$$
\mathbb{P}\bigg\{
  \sup_{\substack{q \in \mathcal{P}\\\\ \sqrt{\int[\sqrt{q} - \sqrt{p_{\theta_0}}]^2}  \geq \epsilon}} \prod_{i=1}^{n}\frac{q(\utilde{X_i})}{p_{\utilde{\theta_{0}}}(\utilde{X_i})} \geq e^{-C_1n\epsilon^2} \bigg\} \leq Ae^{-C_2n\epsilon^2}
$$
\end{proposition_exam}

\begin{remark}Note that this is the same as our previous proposition on the large deviation of the likelihood ratio. However, we are now expanding from a fixed density q to now that the likelihood ratio is small for any density q outside a ball of $\epsilon$ using the Hellinger distance.
\end{remark}

The reason we have this proposition on the uniform bound of large deviations of the likelihood ratio is that in our Bayesian methods, we need to integrate over the entire parameter space, and therefore we need to control the likelihood-ratio for when we are far away from the true value. This proposition will help us disregard anything that is "far away" from the true value.

However, it may be difficult in working with Hellinger distance. Therefore, the following lemma shows how we can convert between Hellinger distance and distance in the parameter space.

\begin{lemma}Suppose that a family of probability densities 
$$
\mathcal{P} = \{p_{\utilde{\theta}}\}
$$
is indexed by a d-dimensional parameter $\utilde{\theta}$ is such that $\sqrt{p_{\utilde{\theta}}}$ is $L_2(\nu)-$differentiable at $\utilde{\theta_0}.$ Furthermore, assume that for a vector $\utilde{\ell}^{\circ}$ of functions 
$$
\frac{\int\bigg[\sqrt{p_{\utilde{\theta_0} + \utilde{h}}} - \sqrt{p_{\utilde{\theta_0}}} - \frac{1}{2}\utilde{h}^T\utilde{\ell}^{\circ}\sqrt{p_{\utilde{\theta_0}}}\bigg]^2 }{|h|^2} \leq g(|h|)
$$
for a function $g(x) \downarrow 0$ as $x \rightarrow 0$. Furthermore, assume that the covariance of the score functions
$$
\utilde{J} = \int \utilde{\ell}^{\circ}\utilde{\ell}^{\circ T}p_{\utilde{\theta_0}}d\nu
$$
is positive definite. Then, there exists constants $0 < \delta < \infty$ and $0 < K_1 < K_2 < \infty$ such that for $|h| \leq \delta$, 
$$
K_1|h|^2 \leq \int \bigg[\sqrt{p_{\utilde{\theta_{0}} + \utilde{h}}} - \sqrt{p_{\utilde{\theta_0}}} \bigg]^2 \leq K_2|h|^2.
$$
\end{lemma}

\begin{remark}This lemma tells us that we can convert between the Hellinger distance and the usual Euclidean distance in the parameter space as long as the distances are small enough. That is, if we have a ball in Hellinger distance bounded by a small h, then we can approximate it with a ball in Euclidean distance.
\end{remark}

First, we state a lemma which we will need for the Bayesian ULAN condition.

\begin{lemma}Suppose that $J_n \xrightarrow{p} J$ and $S_n \xrightarrow{d} \mathcal{N}(0, J).$ Then, with probability $\rightarrow 1$, the ellipsoid 
$$
E_1 = \{\utilde{h}: (\utilde{h} - J_n^{-1}S_n)J_n(\utilde{h} - J_n^{-1}S_n) \leq n^{\epsilon}\}
$$
is included in the ball $\{\utilde{h}: |\utilde{h}| \leq n^{\epsilon}\}.$
\end{lemma}

\begin{remark}This is an ellipsoid centered at $J_n^{-1}S_n$ with size $n^{\epsilon}.$
\end{remark}

We can now strengthen the ULAN condition for it to work in our Bayesian set up where we now still require the remainder to go to 0 but at a slower rate.
\begin{theorem_exam}{Bayesian ULAN}{}Let us denote the likelihood-ratio 
$$
e^{L_n(\utilde{\theta_0} + n^{-1/2}\utilde{h}; \utilde{\theta_0})} = \prod_{i=1}^{n}\frac{p_{\utilde{\theta_0} + n^{-1/2}\utilde{h}}(\utilde{X_i})}{p_{\utilde{\theta_0}}(\utilde{X_i})}.
$$
Then, assume that 
\begin{enumerate}
\item A positive definite symmetric matrix $\utilde{J}$
\item A score vector $\utilde{S_n} \xrightarrow{d} \mathcal{N}(\utilde{0}, \utilde{J})$ under $\utilde{\theta_0}$
\item $\utilde{J_n} \xrightarrow{p} \utilde{J}$ under $\utilde{\theta_0}$
\item There exists $0 < \epsilon < \frac{1}{2}$ such that the remainder $R_n$ given by 
$$
L_n(\utilde{\theta_0} + n^{-1/2}\utilde{h}; \utilde{\theta_0}) = \utilde{h}^T\utilde{S_n} - \frac{1}{2}\utilde{h}^T\utilde{J_n}\utilde{h} + R_n(\utilde{h})
$$
which satisfies that 
$$
\sup_{|h| \leq n^{\epsilon}}|R_n(\utilde{h})| \xrightarrow{p} 0.
$$
\end{enumerate}
\end{theorem_exam}
\begin{remark}So note that condition 4 of the Bayesian rate is no longer for bounded h but for h that goes to infinity at a slow rate.
\end{remark}

\lecture{30}{Bayes Posterior Mean}
\section{Optimality of Bayesian Methods}
\subsection{Bayes Posterior Mean}

\begin{theorem_exam}{Bayesian Posterior Mean Theorem}{}Assume that $\utilde{X_1},...,\utilde{X_n}$ are i.i.d with common density $p_{\theta_0}.$ Furthermore, assume that the family $\{p_{\theta}\}$ is $L_2(\nu)-$differentiable at $\theta_0$ and that the Bayesian ULAN conditions hold at $\theta_0.$ Finally, assume that the prior $w(\theta)$ is integrable, $\int ... \int |\theta|w(\theta)d\theta  < \infty$ and $w(.)$ is continuous at $\theta_0.$ 

Then, if $\hat{\theta}_B$ is the corresponding posterior mean, then we have that 
$$
\sqrt{n}(\hat{\theta}_B - \theta_0) = \utilde{J_n}^{-1}\utilde{S_n} + o_p(1)
$$
\end{theorem_exam}

\lecture{31}{Expectation-Maximization Algorithm}
\section{Optimality of Bayesian Methods}
\subsection{Expectation-Maximization Algorithm}
The EM algorithm is useful for finding out the maximum likelihood estimates or the maximum a posteriori (MAP) estimates of parameters in a latent variable model. Many existing approaches to this kind of problem can be unified as a special case of the EM algorithm.

We first recall some concepts we will need.

\begin{definition}(Convex Function). A convex function $f: \mathbb{R}^d \rightarrow \mathbb{R} \cup \{\infty\}$ is such that for all $\utilde{x}, \utilde{y} \in \mathbb{R}^d$ and all $0 \leq w \leq 1$ where 
$$
f((1 - w)\utilde{x} + w\utilde{y}) \leq (1 - w)f(\utilde{x}) + wf(\utilde{y}).
$$
\end{definition}

We now state that every convex function has tangent lines to points of the function.

\begin{proposition}(Tangent line). A property of convex function as that at every $\utilde{x_0}$ where $f(\utilde{x_0}) < \infty,$ there exists a linear function
$$
g(\utilde{x}) = f(\utilde{x_0}) + \utilde{v}^T(\utilde{x} - \utilde{x_0})
$$
which satisfies 
\begin{enumerate}
\item $g(\utilde{x_0}) = f(\utilde{x_0})$
\item $g(\utilde{x}) \leq f(\utilde{x})$ for all $\utilde{x} \in \mathbb{R}^d$
\end{enumerate}
\end{proposition}

\begin{remark}Such a linear function g(.) need not be unique.
\end{remark}

\begin{corollary}Suppose that the convex function f(.) is differentiable. Then, we can take the gradient vector $\utilde{f}^{\circ}$ to construct the linear function 
$$
g(\utilde{x}) = f(\utilde{x_0}) + \utilde{f}^{\circ T}(\utilde{x} - \utilde{x_0})
$$
\end{corollary}

\begin{proposition_exam}{Jensen's Inequality}{}Suppose $\utilde{X}$ is a d-dimensional random vector such that $\utilde{\mu} = \mathbb{E}[\utilde{X}]$ exists. If f(.) is a convex function, then 
$$
\mathbb{E}[f(\utilde{X})] \geq f(\mathbb{E}[\utilde{X}]) = f(\utilde{\mu})
$$
\end{proposition_exam}

\begin{corollary}Using Jensen's inequality, we can show that 
$$
\mathbb{E}[X^2] \geq \mathbb{E}[X]^2
$$
for a random variable $X \in L^2(\Omega).$
\end{corollary}

We now introduce a measure of the difference between two density functions.

\begin{definition_exam}{Kullback-Leibler Divergence}{}Suppose that $p(.)$ is the density with respect to a $\sigma-$finite measure $\nu(.)$ of a probability distribution over $\mathbb{R}^d.$ Let $\mathcal{X}$ denote the support of the density $p(.)$ and suppose $q(.)$ is another probability density with respect to the measure $\nu(.)$ with the same support $\mathcal{X}.$ Then, the Kullback-Leibler divergence is given by 
$$
\int_{\mathcal{x}}log \bigg\{\frac{p(\utilde{x})}{q(\utilde{x})} \bigg\}p(\utilde{x})d\nu(\utilde{x})
$$
which equals 0 if $p = q$ almost everywhere.
\end{definition_exam}

\begin{remark}The KL-divergence is not symmetric nor does it necessarily satisfy the triangle-inequality. Therefore, it is not a proper metric.
\end{remark}

The KL-divergence from q(.) to the reference density p(.) measures how different q(.) is to p(.).

We can now describe the EM algorithm. First, we describe the setup.

Suppose we have 2 measurable spaces $(\mathcal{X},\mathcal{A})$ and $(\mathcal{Y}, \mathcal{B})$. Let $\nu(.)$ and $\lambda(.)$ be $\sigma-$finite measures on $(\mathcal{X}, \mathcal{A})$ and $(\mathcal{Y}, \mathcal{B})$ respectively. 

Let $p(\utilde{x}, \utilde{y}|\utilde{\theta})$ be a parametric family of joint probability densities with respect to the product measure, which assigns to the product set $A \times B$, the measure $\nu(A)\lambda(B)$, where $A \in \mathcal{A}$ and $B \in \mathcal{B}.$ 

We model $\utilde{y}$ as the observed values of $\utilde{Y}$ and let $\utilde{X}$ be the unobserved variables. $\utilde{X}$ is also known as \textbf{latent variables}.

\begin{definition_exam}{Marginal density of observed data}{}
The marginal density of the observed data $\utilde{Y}$ is 
$$
f(\utilde{Y}|\utilde{\theta}) = \int p(\utilde{X},\utilde{Y}|\utilde{\theta})d\nu(\utilde{X})
$$
\end{definition_exam}

\begin{definition_exam}{Conditional density of latent variable}{}
The conditional density of the latent variable on the observed data, $\utilde{X}$ given $\utilde{Y} = \utilde{y}$ is 
$$
q(\utilde{X}|\utilde{y}, \utilde{\theta}) = \frac{p(\utilde{X}, \utilde{Y}| \utilde{\theta})}{f(\utilde{Y}|\utilde{\theta})}
$$
which assigns to the set $A \in \mathcal{A}$ the probability
$$
\int_Aq(\utilde{X}|\utilde{y},\utilde{\theta})d\nu(\utilde{X}).
$$
\end{definition_exam}

The goal of the EM algorithm is that there parameters $\utilde{\theta}$ which we wish to infer.

Suppose we wish to compute the maximum likelihood estimate 
$$
\hat{\utilde{\theta}} = \max_{\utilde{\theta}}f(\utilde{y}|\utilde{\theta})
$$

However, this is an issue with this.
\begin{proposition}Computing the maximum likelihood estimate for the marginal density of the observed data 
$$
\hat{\utilde{\theta}} = \max_{\utilde{\theta}}f(\utilde{y}|\utilde{\theta})
$$
is NP-hard.
\end{proposition}

However, maximizing the complete data likelihood is relatively easy to do. That is, it is hard to maximize the marginal density of the observed data $f(\utilde{y}|\utilde{\theta})$ but it is alot easier to maximize the complete data density $p(\utilde{X},\utilde{Y}|\utilde{\theta}),$ however, we do not know what $\utilde{X}$ is which is what the EM algorithm tries to solve!

\begin{definition_exam}{EM Log Likelihood}{}The conditional expectation of the complete data log likelihood is known as the EM log likelihood
$$
\ell_{EM}(\utilde{\theta}|\utilde{\theta_0})  = \int log\;p(\utilde{x},\utilde{y}|\utilde{\theta})q(\utilde{x}|\utilde{y}, \utilde{\theta_0})d\nu(\utilde{x})
$$
where $\utilde{\theta_0}$ is a guess. That is, it is taking the conditional expectation of the log likelihood of the joint density under the conditional density of the latent variable on the observed data. Equivalently, we can express it as
$$
\mathbb{E}_{q(\utilde{x}|\utilde{y}, \utilde{\theta_0})}[log\; p(\utilde{X},\utilde{y}|\utilde{\theta})|\utilde{Y} = \utilde{y}]
$$
\end{definition_exam}

We can now state an importat theorem that guarantees why does the EM algorithm work.

\begin{theorem_exam}{Fundamental EM-Algorithm Lemma}{}Suppose that $\utilde{\theta_1}$ is such that for the EM log likelihood, we have that 
$$
\ell_{EM}(\utilde{\theta_1}|\utilde{\theta_0}) \geq \ell_{EM}(\utilde{\theta_0}|\utilde{\theta_0}).
$$
Then, the marginal density of the observed data has the relationship
$$
f(\utilde{y}|\utilde{\theta_1}) \geq f(\utilde{y}|\utilde{\theta_0})
$$
\end{theorem_exam}

\begin{proof} First, note that we can express the log complete data density as  
$$
log\;p(\utilde{x}, \utilde{y}|\utilde{\theta}) = log\;f(\utilde{y}|\utilde{\theta}) + log\;q(\utilde{x}|\utilde{y},\utilde{\theta})
$$
Then, we have that 
$$
\ell_{EM}(\utilde{\theta}|\utilde{\theta_0}) = \int \bigg[log\;p(\utilde{x},\utilde{y}|\utilde{\theta})q(\utilde{x}|\utilde{y}, \utilde{\theta_0}) \bigg]d\nu(\utilde{x}) = \int \bigg[\big(log\;f(\utilde{y}|\utilde{\theta}) + log\;q(\utilde{x}|\utilde{y},\utilde{\theta}) \big) q(\utilde{x}|\utilde{y}, \utilde{\theta_0}) \bigg]d\nu(\utilde{x})
$$
$$
= log\;f(\utilde{y}|\utilde{\theta}) + \int log\;q(\utilde{x}|\utilde{y}, \utilde{\theta})q(\utilde{x}|\utilde{y}, \utilde{\theta_0})d\nu(\utilde{x})
$$
Therefore, we can write the hypothesis of the theorem using these expressions 
$$
\ell_{EM}(\utilde{\theta_1}|\utilde{\theta_0}) \geq \ell_{EM}(\utilde{\theta_0}|\utilde{\theta_0})
$$
$$
log\;f(\utilde{y}|\utilde{\theta_1}) + \int log\;q(\utilde{x}|\utilde{y}, \utilde{\theta_1})q(\utilde{x}|\utilde{y}, \utilde{\theta_0})d\nu(\utilde{x}) \geq log\;f(\utilde{y}|\utilde{\theta_0}) + \int log\;q(\utilde{x}|\utilde{y}, \utilde{\theta_0})q(\utilde{x}|\utilde{y}, \utilde{\theta_0})d\nu(\utilde{x})
$$

$$
log\;f(\utilde{y}|\utilde{\theta_1}) - log\;f(\utilde{y}|\utilde{\theta_0}) \geq \int log\;\bigg\{ \frac{q(\utilde{x}|\utilde{y}, \utilde{\theta_0})}{q(\utilde{x}|\utilde{y}, \utilde{\theta_1})} \bigg\}\cdot q(\utilde{x}|\utilde{y}, \utilde{\theta_0})d\nu(\utilde{x}) \geq 0
$$
where the last inequality arises from the definition of the KL-divergence theorem.
\end{proof}

\begin{remark}What the fundamental EM-algorithm lemma states is that we can increase the observed data likelihood by replacing $\utilde{\theta_0}$ with $\utilde{\theta_1}.$
\end{remark}

\begin{theorem_exam}{EM Algorithm}{}
The EM-algorithm starts at a starting value $\utilde{\theta_0}$. Then, the update rule for the parameter $\utilde{\theta}$ is given by 
$$
\utilde{\theta_{j+1}} = \max_{\utilde{\theta}}\ell_{EM}(\utilde{\theta}|\utilde{\theta_j}) = \max_{\utilde{\theta}}\bigg\{ \int log\;p(\utilde{x},\utilde{y}|\utilde{\theta})q(\utilde{x}|\utilde{y}, \utilde{\theta_j})d\nu(\utilde{x})\bigg\}
$$
Then, the resultant sequence $\utilde{\theta_0},\utilde{\theta_1},\utilde{\theta_2},...$ is guaranteed to not decrease the observed data likelihood
$$
f(\utilde{y}|\utilde{\theta_0}) \leq f(\utilde{y}|\utilde{\theta_1}) \leq f(\utilde{y}|\utilde{\theta_2}) \leq ...
$$
\end{theorem_exam}
\begin{corollary}
If a global maximum likelihood estimator exists $\theta^*$, then $\theta^*$ is a fixed point of the algorithm.
\end{corollary}

\begin{remark}
It is not true in general that the algorithm converges to the global MLE. Furthermore, the rate of convergence may be very slow.
\end{remark}

\lecture{32}{Expectation-Maximization Algorithm Examples}
\section{Optimality of Bayesian Methods}
\subsection{Normal Location Contamination Mixture Model}

Let $X_i \sim B(1,\eta)$ and $Y_i = X_i \theta + Z_i$ where $Z_i \sim \mathcal{N}(0, 1).$

\begin{lemma} The conditional distribution of Y is 
$$
f_{Y|X}(y|x) = \Phi(y)^{1 - x}\Phi(y - \theta)^x
$$
\end{lemma}
\begin{proof} Recall that $X$ is either 0 or 1. Therefore, we have that 
$$
Y_i|X_i = 0 \sim \mathcal{N}(0, 1) \quad \text{and} \quad Y_i|X_i = 1 \sim \mathcal{N}(\theta, 1)
$$
That means 
$$
\prob(Y \leq y|X = 0) = \Phi(y) \quad \text{and} \quad \prob(Y \leq y|X = 1) = \Phi(y - \theta)
$$
Therefore, we can conclude for the conditional distribution 
$$
f_{Y|X}(y|x) - 1\{x = 0\}\Phi(y) + 1\{x = 1\}\Phi(y - \theta)
$$
$$
= \Phi(y)^{1-x} \cdot \Phi(y - \theta)^x
$$
\end{proof}

\begin{proposition} The joint density of $\utilde{X} = (x_1, ..., x_n)^T$ and $\utilde{Y} = (y_1, ..., y_n)^T$ is given by 
$$
p(\utilde{x}, \utilde{y}| \theta, \eta) = \prod_{i=1}^{n}\bigg[(1 - \eta)\Phi(y_i) \bigg]^{1 - x_i}\bigg[\eta\Phi(y_i - \theta) \bigg]^{x_i}
$$
\end{proposition}

\begin{proof} Recall that $\prob(X = 0) = 1 - \eta$ and $\prob(X = 1) = \eta.$ Therefore, using the expression for the conditional distribution of Y, we have that
$$
p(\utilde{x}, \utilde{y}| \theta, \eta) = p(\utilde{x}| \theta, \eta)p(\utilde{y}| \utilde{x}, \theta, \eta) = \prod_{i=1}^{n}\bigg[(1 - \eta)\Phi(y_i) \bigg]^{1 - x_i}\bigg[\eta\Phi(y_i - \theta) \bigg]^{x_i}
$$
\end{proof}

First, derive the log-likelihood of the complete data joint density 
$$
log\; p(\utilde{x},\utilde{y}|\theta, \eta) = \sum_{i=1}^{n}(1 - X_i)log\;\eta + \sum_{i=1}^{n}X_i\;log\;\eta + \theta \sum_{i=1}^{n}x_i\cdot y_i - \frac{\theta^2}{2}\sum_{i=1}^{n}x_i + nlog\frac{1}{\sqrt{2\pi}} - \frac{\sum_{i=1}^{n}y_i^2}{2}
$$

Then, we can compute the estimators of the parameters by maximizing this log-likelihood
$$
\hat{\eta} = \frac{1}{n}\sum_{i=1}^{n}x_i \quad \hat{\theta} = \frac{\sum_{i=1}^{n}x_i \cdot y_i}{\sum_{i=1}^{n}x_i}
$$
We can then compute the marginal density of the observed data $\utilde{y}$ as 
$$
f(\utilde{y}|\eta, \theta) = \int p(\utilde{x}, \utilde{y}| \eta, \theta)d\nu(\utilde{x}) = \prod_{i=1}^{n}\bigg\{(1 - \eta)\Phi(y_i) + \eta \Phi(y_i - \theta) \bigg\}
$$


We now remark that the observed data log likelihood is extremely difficult to maximize
$$
log\;f(\utilde{y}|\eta, \theta) = \sum_{i=1}^{n}log\;\bigg\{(1 - \eta)\Phi(y_i) - \eta \Phi(y_i - \theta) \bigg\}
$$
Therefore, we require the EM algorithm.

(1) First, we need initial estimates of the parameters $\theta, \eta.$ We can use the Method-Of-Moment estimators as our initial guess 
$$
\hat{\theta} = \frac{\overline{Y}}{\eta}  \quad \hat{\eta} = \frac{\overline{Y}^2}{\overline{Y}^2 + V - 1}
$$
where V is the sample variance of the observed data $\utilde{Y}.$

(2) We now compute the conditional density of the latent variable $\utilde{X}$ given the observed data $\utilde{Y} = \utilde{y}$
$$
q(\utilde{x}|\utilde{y}, \theta, \eta) = \frac{p(\utilde{x}, \utilde{y}| \theta, \eta)}{f(\utilde{y}| \theta, \eta)} = \prod_{i=1}^{n}\bigg\{ \bigg(\frac{(1 - \eta)\Phi(y_i)}{(1 - \eta)\Phi(y_i) + \eta \Phi(y_i - \theta)} \bigg)^{1 - x_{i}} \bigg(\frac{\eta \Phi(y_i - \theta)}{(1 - \eta)\Phi(y_i) + \eta \Phi(y_i - \theta)} \bigg)^{x_{i}} \bigg\}
$$
where we can see that 
$$
X_i|Y_i = y_i \sim B(1, \gamma_i)
$$
where 
$$
\gamma_i = \frac{\eta \Phi(y_i - \theta)}{(1 - \eta)\Phi(y_i) + \eta \Phi(y_i - \theta)}
$$

Now, we note that the complete data log likelihood $p(\utilde{x}, \utilde{y}| \theta, \eta)$ is linear in $X_i.$ Therefore, we have that
$$
\mathbb{E}[g(\utilde{X})|\utilde{Y} = \utilde{y}]
$$
but $g(\utilde{X})$ is of the form $\sum_{i=1}^{n}h(X_i)$ as the data is i.i.d and $X_i|Y_i$ are independent 
$$
= \sum_{i=1}^{n}\mathbb{E}[h(X_i)| Y_i = y_i]
$$
and as $h(x_i) = a + bX_i$ as seen in the complete data log likelihood, we have that 
$$
= a + b\sum_{i=1}^{n}\mathbb{E}[X_i| Y_i = y_i] = a + b\sum_{i=1}^{n}\gamma(y_i)
$$
as $X_i|Y_i = y_i \sim B(1, \gamma(y_i))$. Therefore, going back to our log likelihood of the complete data, 
$$
log\; p(\utilde{x},\utilde{y}|\theta, \eta) = \sum_{i=1}^{n}(1 - X_i)log\;\eta + \sum_{i=1}^{n}X_i\;log\;\eta + \theta \sum_{i=1}^{n}x_i\cdot y_i - \frac{\theta^2}{2}\sum_{i=1}^{n}x_i + nlog\frac{1}{\sqrt{2\pi}} - \frac{\sum_{i=1}^{n}y_i^2}{2}
$$
we replace $x_i$ by the expression 
$$
\gamma_i^{\circ} = \mathbb{E}_{\theta_{0}, \eta_{0}}[X_i|Y_i = y_i] \frac{\eta_0 \Phi(y_i - \theta_0)}{(1 - \eta_0)\Phi(y_i) + \eta_0 \Phi(y_i - \theta_0)}
$$
to arrive at 
$$
log_{\theta ,\eta}(\theta, \eta|\theta_0, \eta_0) = log\eta\sum_{i=1}^{n}\gamma_i^{\circ} + log(1 - \eta)(n - \sum_{i=1}^{n}\gamma_i^{\circ}) + n\;log\frac{1}{\sqrt{2 \pi}} - \frac{n \sum_{i=1}^{n}y_i^2}{2} + \theta \sum_{i=1}^{n}\gamma_i^{\circ}y_i - \frac{\theta^2}{2}\sum_{i=1}^{n}\gamma_i^{\circ}
$$
Maximizing this gives us 
$$
\eta_1 = \frac{1}{n}\sum_{i=1}^{n}\gamma_i^{\circ} \quad \theta_1 = \frac{\sum_{i=1}^{n}\gamma_i^{\circ}y_i}{\sum_{i=1}^{n}\gamma_i^{\circ}}
$$


We summarise the steps taken.


Let $\utilde{x}$ be the latent variable and let $\utilde{y}$ be the observed variable.
\begin{enumerate}
\item Derive the complete data log-likelihood $log\;p(\utilde{x}, \utilde{y}|\theta, \eta)$
\item Derive the estimators of the parameters $\hat{\theta}, \hat{\eta}$
\item Derive the marginal density of the observed variable $f(\utilde{y}|\theta, \eta)$
\item Determine your starting values of your parameters $\theta_0, \eta_0$ (e.g. using M.O.M estimators)
\item Determine the conditional distribution of the latent variable given the observed variable $$
q(\utilde{x}|\utilde{y}, \theta, \eta) = \frac{p(\utilde{x}, \utilde{y}|\theta, \eta)}{f(\utilde{y}|\theta, \eta)}
$$
\item Carry out the "expectation step" 
$$
\gamma_i^{\circ} = \mathbb{E}_{\theta_{0}, \eta_{0}}\bigg[\utilde{X_i}|\utilde{Y_i} = \utilde{y_i} \bigg]
$$
\item Maximize the complete data log-likelihood by replacing the latent variable with $\gamma_i^{\circ}$ to get 
$$
log_{\theta \eta}p(\theta, \eta| \theta_0, \eta_0)
$$
to find the estimates of the parameters $\hat{\theta}, \hat{\eta}$
\end{enumerate}


\lecture{0}{Prerequisite}
\section{Measure Theory Recap}
\section{Measure Theory Recap}
\subsection{Classes of subsets}
For this whole chapter, we denote $\Omega$ as the space. 

\begin{definition}(Powerset).
We define as the set of all subsets of $\Omega$ as the \textbf{powerset} $\mathcal{P} = 2^{\Omega}.$
\end{definition}

\begin{definition}(Semi-algebra). The class $\mathcal{S} \subseteq \mathcal{P}$ is a \textbf{semi-algebra} if 
\begin{enumerate}
\item $\Omega \in \mathcal{P}$
\item If $A, B \in \mathcal{S}$, then $A \cap B \in \mathcal{S}$
\item If $A \in \mathcal{S}$, then there exists a finite disjoint union of sets $E_1,...E_n$ where $E_i \in \mathcal{S}$ for $1 \leq i \leq n$ such that $A^c = \bigcupdot_{i=1}^{n}E_i$
\end{enumerate}
\end{definition}

\begin{remark}In some text, a semi-algebra is also known as a \textbf{semi-ring}.
\end{remark}

\begin{example}(Intervals on $\mathbb{R}$ is a semi-algebra). Let $\Omega = \mathbb{R}$. We then define the class of sets to include 
\begin{enumerate}
\item $\{(a,b]: a < b; a,b \in \mathbb{R} \} \in \mathcal{S}$
\item $\{(-\infty,b]: b \in \mathbb{R} \} \in \mathcal{S}$
\item $\{(a,\infty]: a \in \mathbb{R} \} \in \mathcal{S}$
\item $\emptyset, \mathbb{R} \in \mathcal{S}$
\end{enumerate}
Then, $\mathcal{S}$ is a semi-algebra.
\end{example}

\begin{definition}(Algebra). The class $\mathcal{A} \subseteq \mathcal{P}$ is an \textbf{algebra} if 
\begin{enumerate}
\item $\Omega \in \mathcal{A}$
\item If $A,B \in \mathcal{A}$ then $A \cap B \in \mathcal{A}$
\item If $A \in \mathcal{A}$ then $A^c \in \mathcal{A}.$
\end{enumerate}
\end{definition}

\begin{remark}In some text, an algebra is also known as a \textbf{ring}.
\end{remark}

\begin{claim}If $\mathcal{A}$ is an algebra, then $\mathcal{A}$ is a semi-algebra.
\end{claim}

\begin{proposition}If $E,F \in \mathcal{A}$ then $E \cup F \in \mathcal{A}.$
\end{proposition}

We now move on to our main interest in measure theory.

\begin{definition}($\sigma$-algebra). Let $\mathcal{F} \subseteq \mathcal{P}.$ $\mathcal{F}$ is a $\sigma-$algebra if 
\begin{enumerate}
\item $\Omega \in \mathcal{F}$
\item If $A \in \mathcal{F}$ then $A^c \in \mathcal{F}$
\item If $A_j \in \mathcal{F}$ then $\cup_{j \geq 1}A_j \in \mathcal{F}.$
\end{enumerate}
\end{definition}


\begin{claim}If $\mathcal{F}$ is a $\sigma$-algebra, then $\mathcal{F}$ is an algebra.
\end{claim}

\begin{proposition}Let $\mathcal{A}_i \subseteq \mathcal{P}$ where $i \in I$ is an index set and $\mathcal{A}_i$ is an algebra. Then 
$$
\mathcal{A} = \bigcap_{i \in I}\mathcal{A}_i
$$
is an algebra.
\end{proposition}

\begin{remark}This proposition also holds for the intersection of $\sigma-$algebras $\mathcal{F}_i$ is a $\sigma-$algebra.
\end{remark}

\begin{definition}(The algebra generated by a set). Let $\mathcal{C} \subseteq \powerset$ be a collection of sets. Then, the algebra generated by $\mathcal{C}$ is defined as 
$$
\algebra (\mathcal{C}) = \bigcap_{i \in I}\algebra_i
$$
where $\algebra_i$ are algebras which contains $\mathcal{C}.$ 
\end{definition}

\begin{proposition}(Properties of algebras generated by a set). Let $\mathcal{C} \subset \powerset$ be a collection of sets. Let $\algebra$ be the algebra generated by $\mathcal{C}.$ Then 
\begin{enumerate}
\item $\algebra$ contains $\mathcal{C}$
\item For any other algebra $\beta \supseteq \mathcal{C}$, then $\beta \supseteq \algebra$. That is, $\algebra$ is the smallest algebra that contains $\mathcal{C}.$ 
\end{enumerate}
\end{proposition}

\begin{remark}These ideas also apply to the $\sa$ $\sigmalgebra$ generated by a set $\mathcal{C} \subseteq \powerset.$
\end{remark}

We now see that the algebra $\algebra (\semialgebra)$ generated by a semi-algebra $\semialgebra$ is \textbf{simple} in the sense that any set $E \subset \algebra (\semialgebra)$ can be expressed as a finite union of sets in the semi-algebra $\semialgebra.$ However, this property does not hold for the $\sa$ generated by the semi algebra $\sigmalgebra (\semialgebra)$.

\begin{proposition}(The Algebra generated by semi-algebra is simple). Let $\semialgebra \subseteq \powerset$ be a semi-algebra. Let $\algebra (\semialgebra)$ be the algebra generated by $\semialgebra.$ Then, a set $A \in \algebra (\semialgebra)$ if and only if there exists a finite disjoint collection of sets $E_1, ..., E_n$ where $E_i \in \semialgebra$ for $1 \leq i \leq n$ where 
$$
A = \bigcupdot_{i=1}^{n}E_i.
$$
\end{proposition}

\begin{proof}(Sketch). We can take the set 
$$
\beta = \{\bigcupdot_{j=1}^{n}F_j: F_j \in \semialgebra\}
$$
where $\beta \subseteq \powerset.$ We can show that 
\begin{enumerate}
\item $\beta$ is an algebra;
\item $\beta \supset \semialgebra$.
\end{enumerate}
Hence, this implies that 
$$
\beta \supset \algebra (\semialgebra).
$$
Hence, we can take any set $E \in \algebra (\semialgebra)$ and the above implies that $E \in \beta$ and hence can be written as disjoint union of sets in $\semialgebra.$
\end{proof}

This is significant as any element in $\algebra (\semialgebra)$ can be written as a finite disjoint union of elements in the semi-algebra $\semialgebra.$

\subsection{Functions on Sets}

\begin{definition}(Additive set function). Let $\mathcal{C} \subseteq \powerset$ be a class of sets. Furthermore, assume that $\emptyset \in \mathcal{C}.$ Define the set function 
$$
\mu: \mathcal{C} \rightarrow \positiveextendedreal.
$$

$mu$ is \textbf{additive} if 
\begin{enumerate}
\item $\mu(\emptyset) = 0;$
\item Let $E_1,...,E_n \in \mathcal{C}$ be disjoint sets where $E = \bigcupdot_{j=1}^{n}E_j$ and $E \in \mathcal{C}.$ Then 
$$
\mu(E) = \sum_{j=1}^nE_j.
$$
\end{enumerate}
\end{definition}


\begin{definition}($\sigma$-additive set function). Let $\mathcal{C} \subseteq \powerset$ be a class of sets. Furthermore, assume that $\emptyset \in \mathcal{C}.$ Define the set function 
$$
\mu: \mathcal{C} \rightarrow \positiveextendedreal.
$$

$mu$ is \textbf{$\sigma$-additive} if 
\begin{enumerate}
\item $\mu(\emptyset) = 0;$
\item Let $\{E_i\}_{i \geq 1} \in \mathcal{C}$ be disjoint sets where $E = \bigcupdot_{j \geq 1}E_j$ and $E \in \mathcal{C}.$ Then 
$$
\mu(E) = \sum_{j=1}^{\infty}E_j.
$$
\end{enumerate}
\end{definition}

The second property is what is referred to as $\sigma-$additivity.

\begin{remark}$\sigma-$additivivty is the same as additivity except that the second condition holds for a \textbf{countably infinite} number of disjoint sets. Some text calls additivity, \textbf{finite-additivity} and $\sigma-$additivity, \textbf{countably additive}. 
\end{remark}

\begin{observation}We can relax the first condition required for addivity. If there exists $A \in \mathcal{C}$ such that $\mu(A) < \infty$, then we can express $A = A \cup \emptyset.$ Then 
$$
\mu(A \cup \emptyset) = \mu(A) + \mu(\emptyset)
$$
by addivity. Then, as $\mu(A) < \infty$ by assumption, we have that $\mu(\emptyset) = 0.$ Hence, as long as we have a set A such that $\mu(A) < \infty$, then condition 1 follows from condition 2 for a $(\sigma)$ additive set function.
\end{observation}

\begin{lemma}Let $\mu$ be a $\sigma-$additive set function. If $E \subseteq F$, then 
$$
\mu(E) \leq \mu(F).
$$
\end{lemma}

\begin{proposition}If $\mu$ is a $\sigma-$additive set function, then $\mu$ is an additive set function.
\end{proposition}

\begin{example}(An additive set function that is not $\sigma$-additive). Let $\Omega = (0,1).$ Let $\mathcal{C} = \{(a,b]: 0 \leq a < b < 1\}$. Define the set function $\mu: \mathcal{C} \rightarrow \positiveextendedreal$ as 
$$
\mu((a,b]) = \begin{cases}
+\infty \quad \text{if a = 0}\\
b - a \quad \text{if a}>0\\
\end{cases}
$$
\end{example}

Let $\{E_n\}_{n geq 1}$ be a sequence of sets. We will write $E_n \uparrow E$ if $E_n \subseteq E_{n+1}$ and $\bigcup_{n \geq 1}E_n = E.$ 

We will write $E_n \downarrow E$ if $E_n \supseteq E_{n+1}$ and $\bigcap_{n \geq 1}E_n = E.$ 

\begin{definition}(Continuous from above). Let $\mathcal{C} \subseteq \powerset$ and $\mu: \mathcal{C} \rightarrow \positiveextendedreal$. Take $E \in \mathcal{C}.$ Then, $\mu$ is \textbf{continuous from below} at E if for all sequences $\{E_j\}_{j \geq 1}$ such that $E_j \in \mathcal{C}$ and $E_n \uparrow E$, we have that 
$$
\mu(E_n) \rightarrow \mu(E)
$$
as $n \rightarrow \infty.$
\end{definition}

\begin{definition}(Continuous from below). Let $\mathcal{C} \subseteq \powerset$ and $\mu: \mathcal{C} \rightarrow \positiveextendedreal$. Take $E \in \mathcal{C}.$ Then, $\mu$ is \textbf{continuous from below} at E if for all sequences $\{E_j\}_{j \geq 1}$ such that $E_j \in \mathcal{C}$, $E_n \downarrow E$, and $\mu(E_0) < \infty$, we have that 
$$
\mu(E_n) \rightarrow \mu(E)
$$
as $n \rightarrow \infty.$
\end{definition}

The set function $\mu$ is continuous if it is continuous from above and below. 

We now state a proposition to help us determine if a function is $\sigma-$additive.

\begin{proposition}(Tests for a function being $\sigma-$additive). Let $\algebra \subseteq \powerset$ be an algebra. Define the \textbf{additive} set function $\mu: \algebra \rightarrow \positiveextendedreal$. Then, we have the following:
\begin{enumerate}
\item $\mu$ is $\sigma-$additive if $\mu$ is continuous at E for all $E \in \algebra;$
\item If $\mu$ is continuous from below, then $\mu$ is $\sigma-$additive;
\item If $\mu$ is continuous from above at $\emptyset$ and $\mu$ is finite, then $\mu$ is $\sigma-$additive.
\end{enumerate}
\end{proposition}

\begin{remark}We generally use (2) and (3) to show an additive set function is $\sigma-$additive.
\end{remark}

\subsection{Extension Theorems}

We now look at extending an additive set function on a semi-algebra to an algebra with this extension being unique.
\begin{theorem}(Simple extension theorem). Let $\semialgebra \subseteq \powerset$ be a semi-algebra. Define $\mu: \semialgebra \rightarrow \positiveextendedreal$ to be an additive set function. Let $\algebra (\semialgebra)$ be the algebra generated by the semi-algebra. Then, there exists a set function $\nu: \algebra (\semialgebra) \rightarrow \positiveextendedreal$ such that 
\begin{enumerate}
\item $\nu$ is additive;
\item $\nu(A) = \mu(A)$ for all $A \in \semialgebra$ ($\nu$ is an extension of $\mu$)
\item $\nu$ is an \textbf{unique} extension of $\mu$ onto $\algebra (\semialgebra).$
\end{enumerate}
\end{theorem}

\begin{observation}To define the extension, recall that the collection $\algebra (\semialgebra)$ is simple, that is, for every set $E \in \algebra (\semialgebra)$, there exists a finite number of disjoint sets $E_j \in \semialgebra$ such that $E = \bigcupdot_{j=1}^{n}E_j.$ Hence, we can define our extension as 
$$
\nu(E) = \sum_{j=1}^{n}\mu(E_j).
$$
for every set $E \in \algebra(\semialgebra).$
\end{observation}

\begin{corollary}If $\mu: \semialgebra \rightarrow \positiveextendedreal$ is \textbf{$\sigma-$additive}, then there exists a unique $\sigma-$additive extension $\nu: \algebra (\semialgebra) \rightarrow \positiveextendedreal$.
\end{corollary}


\subsection{Caratheodory Theorem}
Now, we are interested in taking a $\sigma-$additive set function $\nu: \algebra(\semialgebra) \rightarrow \positiveextendedreal$ and extending it to a $\sigma-$additive function $\pi: \sigmalgebra(\algebra) \rightarrow \positiveextendedreal$ where $\sigmalgebra(\algebra)$ is the $\sa$ generated by the algebra $\algebra.$ However, it is not as straight forward as what we did when we extended it onto the algebra $\algebra (\semialgebra)$ as we cannot express every set $E \in \sigmalgebra(\algebra)$ as a finite disjoint union of sets in $\algebra$ or $\semialgebra$. Hence, we require a more elaborate construction.

We outline the steps of what we will need to do.

\begin{enumerate}
\item Define an outer-measure $\pi^*: \powerset \rightarrow \positiveextendedreal$.
\item Define the collection $\mathcal{M} \subseteq \powerset$ where $\mathcal{M}$ is a $\sigmalgebra$ and that $\mathcal{M} \supseteq \sigmalgebra(\algebra).$
\item Show that $\pi^*|_{\mathcal{M}}$ is $\sigma-$additive.
\item Show that $\pi^*|_{\algebra} = \nu$
\item Show that $\pi^*|_{\mathcal{M}}$ is an unique extension (under certain conditions).
\end{enumerate}


Note that the $\sa$ generated by semi-algebras and algebras are the same, hence the difference does not matter and we can repeat all of the above with $\sa$ generated by semi-algebras $\semialgebra$, which actually gives us a more general definition.

Before we proceed, we tie up some definitions.

\begin{definition}(Pre-measure). Let $\algebra$ be an algebra (ring). Let $\mu_0: \algebra \rightarrow \positiveextendedreal$. The function $\mu_0$ is called a \textbf{pre-measure} if 
\begin{enumerate}
\item $\mu_0(\emptyset) = 0$
\item For every countable sequence $\{E_i\}_{i \in \mathbb{N}}$ of pairwise disjoint sets whose union lies in $\algebra$, then 
$$
\mu_0\bigg(\bigcup_{i=1}^{\infty}E_i \bigg) = \sum_{i=1}^{\infty}\mu_0(E_i).
$$
\end{enumerate}
\end{definition}

\begin{remark}This is what we have called a $\sigma-$additive function this whole time! Additionally, we can drop the first condition and only require $\sigma-$addivity if there exists a set $A \in \algebra$ such that $\mu_0(A) < \infty.$ This is known as a pre-measure as it is defined on an algebra $\algebra$ rather than a $\sa$ $\sigmalgebra.$
\end{remark}

Pre-measures will be extremely useful in helping us define outer-measures.

\begin{definition}(Outer-measure). Let $\Omega$ be the set and $\powerset$ be the powerset of $\Omega$. Let $\mu: \powerset \rightarrow \positiveextendedreal$ be a set function. $\mu$ is an \textbf{outer-measure} if 
\begin{enumerate}
\item $\mu(\emptyset) = 0;$
\item (Monotonicity) For any two sets $E, F \in \Omega$, if $E \subseteq F$ then $\mu(E) \leq \mu(F);$
\item ($\sigma$-subaddivitiy) For \textbf{any} sequence $\{E_j\}_{j \geq 1}$ of subsets of $\Omega$, then 
$$
\mu\bigg(\bigcup_{j=1}^{\infty}E_j \bigg) \leq \sum_{j=1}^{\infty}\mu\bigg(E_j \bigg).
$$
\end{enumerate}
\end{definition}

\begin{remark}Note that condition (3) require $\sigma-$subaddivitiy and not $\sigma-$additivity.
\end{remark}


\begin{proposition}Let $\Omega$ be the set and let $\algebra$ be an algebra of the space $\Omega$. Let $\nu$ be the pre-measure we defined on $\algebra$. Then, we define that for any set $A \subseteq \Omega$, the set function
$$
\pi^*(A) = \inf_{ \{E_i\}_{i \geq 1} } \bigg\{\sum_{i \geq 1}\nu(E_i): A \subseteq \bigcup_{i \geq 1}E_i \text{ and } E_i \in \algebra \bigg\}.
$$
Then, $\pi^*$ is an outer-measure.
\end{proposition}

\begin{remark}Here, we take the infimum over all coverings $\{E_i\}_{i \geq 1}$ of the set A.
\end{remark}

Now,we will define the collection of sets to which we will call measurable.

\begin{definition}($\mu^*$-measurable set). Let $\mu^*: \powerset(\Omega) \rightarrow \positiveextendedreal$ be an outer measure. We call a set $A \subseteq \Omega$ a $\mu^*-$measurable set if 
$$
\mu^*(S) = \mu^*(S \cap A) + \mu^*(S \cap A^c)
$$
for all sets $S \subseteq \Omega.$ 
\end{definition}

\begin{definition}(family of measurable sets). Let $\pi^*: \powerset \rightarrow \positiveextendedreal$ be the outer-measure we defined earlier using the pre-measure $\nu.$ We denote the family of measurable sets $\mathcal{M}$ where $A \in \mathcal{M}$ if
$$
\pi^*(E) = \pi^*(E \cap A) + \pi^*(E \cap A^c)
$$
for all sets $E \subseteq \Omega.$
\end{definition}

\begin{proposition}Let $\Omega$ be our set of interest and $\algebra$ be the algebra on $\Omega$. Let $\pi^*$ be the outer-measure we have defined. $\mathcal{M}$ the family of $\pi^*$-measurable sets. Then, we have that 
\begin{enumerate}
\item $\mathcal{M} \supseteq \mathcal{A}$
\item $\mathcal{M}$ is a $\sa$
\item From (1) and (2), we have that 
$$
\mathcal{M} \supseteq \sigmalgebra (\algebra).
$$
\end{enumerate}
\end{proposition}

\begin{proposition}Let $\pi^*$ be the outer-measure we have defined and $\mathcal{M}$ the family of $\pi^*-$measurable sets. Additionally, let $\nu$ be the pre-measure defined on the algebra $\algebra.$ Then 
$$
\pi^*|_{\mathcal{M}}: \mathcal{M} \rightarrow \positiveextendedreal
$$
is $\sigma-$additive and hence a measure $\pi$. Furthermore, $\pi$ is an extension to $\nu$ as $pi(A) = \nu(A)$ for all sets $A \in \algebra.$
\end{proposition}

We need one more definition before we show uniqueness.
\begin{definition}($\sigma$-finite). Let $(\Omega, \mathcal{F}, \mu)$ be a measure space. Then, $\mu$ is $\sigma-$finite if there are sets $\{E_j\}_{j \geq 1}$ such that $E_j \uparrow \Omega$ such that 
$$
\mu(E_j) < \infty
$$
for all $j \in \mathbb{N}.$
\end{definition}

\begin{claim}Assume that $\pi$ is the extension of the pre-measure $\nu$ on $\algebra.$ If $\nu$ is $\sigma-$finite, then it is the \textbf{unique extension} of $\nu$ onto $\sigmalgebra(\algebra).$
\end{claim}

From all this, we can now concisely state Caratheodory's extension theorem.

\begin{theorem_exam}{Caratheory's Extension Theorem}{}Let $\algebra$ be an algebra on $\Omega$ and let $\nu: \algebra \rightarrow \positiveextendedreal$ be a pre-measure on $\algebra.$ Let $\sigmalgebra(\algebra)$ be the $\sa$ generated by $\algebra.$ Then, there exists a measure $\mu: \sigmalgebra(\algebra) \rightarrow \positiveextendedreal$ such that $\mu|_{\algebra} = \nu.$ Moreover, if $\nu$ is $\sigma-$finite, then the extension $\mu$ is unique and also $\sigma-$finite.
\end{theorem_exam}

We give an application.
\begin{proposition}Any pre-measure on an algebra containing all intervals of $\mathbb{R}$ can be extended to the Borel algebra of $\mathbb{R}.$
\end{proposition}

\subsection{Monotone Classes}
\begin{definition}(Monotone Classes of sets). Let $\Omega$ be our set. Let $g \subseteq \powerset.$ g is a monotone class if 
\begin{enumerate}
\item If $A_j \in g$ for all $j \geq 1$, then $A_j \uparrow A$ implies that $A \in g$;
\item If $B_j \in g$ for all $j \geq 1$, then $B_j \downarrow B$ implies that $B \in g$.
\end{enumerate}
\end{definition}

\begin{claim}Suppose we had a family of monotone classes $g_i$ for $i \in I$ and $g_i \in \powerset.$ Then 
$$
\bigcap_{i \in I}g_i
$$
is a monotone class.
\end{claim}

\begin{proposition}Every $\sa$ $\sigmalgebra$ is a monotone class.
\end{proposition}

\begin{definition}(Smallest monotone class). Let $C \subseteq \powerset.$ Then, the smallest monotone class contaning C is 
$$
g(C) = \bigcap_{i \in I}g_i
$$
where $C \subseteq g_i$ for all $i \in I.$
\end{definition}


We now turn to the theorem of interest.
\begin{theorem_exam}{Monotone class and $\sa$}{}Let us define $\algebra \subseteq \powerset$ as the algebra on $\Omega.$ Denote $\mathcal{M}(\algebra)$ as the monotone class generated by $\algebra.$ Denote $\sigmalgebra(\algebra)$ as the $\sa$ generated by $\algebra.$ Then, we have that 
$$
\mathcal{M}(\algebra) = \sigmalgebra(\algebra).
$$
\end{theorem_exam}


We can use this theorem to show that if a collection of sets is a monotone class, then it is also a $\sa.$

\subsection{Lebesgue Measure}

We can use Caratheory's theorem to construct the Lebesgue measure, which is the extension of the measure defined on the algebra of $\mathbb{R}$ intervals.

\begin{definition}(Lebesgue algebra). Let us define the semi-algebra $\semialgebra = \{\emptyset, \mathbb{R}, \{(a,b]: a,b \in \mathbb{R}\}, \{(a,\infty): a \in \mathbb{R}\}, \{(-\infty,b]: b \in \mathbb{R}\}\}$. The Lebesgue algebra is the algebra generated $\algebra(\semialgebra).$
\end{definition}

We now define a measure on this algebra and then extend it to get the Lebesgue measure.

\begin{claim}Let us define the set function $\mu: \algebra \rightarrow \positiveextendedreal$ where 
$$
\begin{cases}
\mu(\emptyset) = 0\\
\mu(\mathbb{R}) = \infty\\
\mu((a,b]) = b - a\\
\mu((a, \infty)) = \infty\\
\mu((-\infty,b]) = \infty\\
\end{cases}
$$
Then, $\mu$ is a pre-measure.
\end{claim}

\begin{claim}The real line $\mathbb{R}$ is $\sigma-$finite with respect to $\mu.$
\end{claim}

\begin{proof}Let $E_n = (-n,n]$ and $\mathbb{R} = \bigcup_{n \in \mathbb{N}}E_n$. Then, $\mu(E_n) = -2n < \infty.$
\end{proof}

From the fact that $\mu$ is a pre-measure and $\mathbb{R}$ is $\sigma-$finite, then by Caratheodory's theorem, we can find a unique extension $\lambda$ on the $\sa$ $\sigmalgebra(\algebra)$ where restricting $\lambda$ to $\algebra$ gives us back $\mu$. This $\lambda$ is the \textbf{Lebesgue measure}.
 
\subsection{Complete Measures}
Many theorems in measure theory, for instance Fubini or Radon-Nikodym, needs completeness to make full sense. The notion of almost everywhere wouldn't make sense if it holds for a set but not subsets of that set.

\begin{definition}(Complete measure). Let $\sigmalgebra \subseteq \powerset$ be a $\sa$ and let $\mu: \sigmalgebra \rightarrow \positiveextendedreal$ be a measure. Then, $(\sigmalgebra, \mu)$ is \textbf{complete} if for every set $A \in \sigmalgebra$ such that $\mu(A) = 0$, then for all sets $E \subseteq A$, we have that $E \in \sigmalgebra.$ The sets E are known as \textbf{negligible sets}.
\end{definition}

\begin{observation}By monotonicity of the measure, we have that $\mu(E) = 0.$
\end{observation}



\begin{claim}Let $\sigmalgebra \subseteq \powerset$ be a $\sa.$ Define $\mu: \sigmalgebra \rightarrow \positiveextendedreal$ be a measure. Then 
$$
\overline{\sigmalgebra} = \{A \cup N: A \in \sigmalgebra \text{ and } N \subseteq E \in \sigmalgebra \text{ such that } \mu(E) = 0\}.
$$
Then, $\overline{\sigmalgebra}$ is a $\sa.$
\end{claim}

Clearly, $\overline{\sigmalgebra} \supset \sigmalgebra.$ 

\begin{definition}Let $\sigmalgebra \subseteq \powerset$ be a $\sa.$ Define $\mu: \sigmalgebra \rightarrow \positiveextendedreal$ be a measure. Then, we define the measure $\overline{\mu}: \overline{\sigmalgebra} \rightarrow \positiveextendedreal$ to be 
$$
\overline{\mu}(A \cup N) = \mu(A)
$$
for all sets $A \in \overline{\sigmalgebra}.$
\end{definition}

Clearly, $\overline{\mu}|_{\sigmalgebra} = \mu.$

\begin{proposition}Define the measure and $\sa$ pair $(\mu, \sigmalgebra)$. Furthermore, assume that $\Omega$ is $\sigma-$finite with respect to $\mu.$ Then, the completion $(\overline{\mu}, \overline{\sigmalgebra})$ is unique.
\end{proposition}

Hence, it is always possible to complete a measure and $\sa.$

\subsection{Approximation and Regularity}

Let us define $\pi^*$ as the outer-measure and let $A \in \mathcal{M}$ be a measurable set such that $\pi^*(A) < \infty.$ We are interested on whether can we approximate $\pi^*(A)$ with a set $E \in \sigmalgebra(\algebra).$ That is, does there exist a set $E \in \sigmalgebra(\algebra)$ such that $A \subseteq E$ and 
$$
\pi^*(A) = \pi^*(E).
$$
Can we approximate any measurable set from above by a set in $\sigmalgebra(\algebra)?$.

First, we show that we can approximate any set in $\sigmalgebra$ by a set in the $\algebra$, which we can write as the finite disjoint union of sets in the semialgebra $\semialgebra$. However, we pay a price in not having an exact approximation.
\begin{theorem}Let $\algebra \subseteq \powerset$ be an algebra and $\sigmalgebra(\algebra)$ be a $\sa.$ Define the measure $\mu: \sigmalgebra \rightarrow \positiveextendedreal$. Let us define the set $A \in \sigmalgebra$ and assume $\mu(A) < \infty.$ Take $\epsilon > 0.$ Then, there exists a set $E \in \algebra$ such that 
$$
\mu(E \text{\textbackslash} A) + \mu(A \text{\textbackslash} E) < \epsilon.
$$
\end{theorem}

\begin{corollary}If $\Omega$ is $\sigma-$finite with respect to $\mu$, then we can extend $(\sigmalgebra(\algebra), \mu)$ to the completion $(\overline{\sigmalgebra}, \overline{\mu})$. Sp tjem of $A \in \overline{\sigmalgebra}$ amd $\epsilon > 0$, then there exists a set $E \in \algebra$ such that 
$$
\overline{\mu}(E \text{\textbackslash} A) + \overline{\mu}(A \text{\textbackslash} E) < \epsilon.
$$
\end{corollary}

\begin{definition_exam}{Regular Measure}{} Let $\Omega$ be a topological space. Let $\mathcal{B}$ be the Borel $\sa$, which is the smalelst $\sa$ which contains all open sets. Let $\mu: \sigmalgebra \rightarrow \positiveextendedreal$ and $\sigmalgebra \supseteq \mathcal{B}$. 

$\mu$ is \textbf{regular} if for all sets $A \in \sigmalgebra$ and $\epsilon > 0$, there exist sets $F \subseteq A \subseteq G$ where F is closed, G is open such that 
$$
\mu(G \text{\textbackslash} F) \leq \epsilon.
$$
\end{definition_exam}

\begin{remark}We can approximate any set $A \in \sigmalgebra$ from below by a closed set and from above by an open set.
\end{remark}

\begin{lemma}Assume $\borelsigmaalgebra \subseteq \sigmalgebra$. If $\mu$ is regular then $\sigmalgebra \subseteq \overline{\borelsigmaalgebra}_{\overline{\mu}}$ where $\overline{\borelsigmaalgebra}_{\overline{\mu}}$ where $\overline{\borelsigmaalgebra}$ is the completion of $\borelsigmaalgebra$ with respect to $\mu.$ 
\end{lemma}

\begin{theorem}(Regular Lebesgue Measure). The Lebesgue measure is regular. Let $\mu$ be the Lebesgue measure where 
$$
\mu: \mathcal{L} \rightarrow \positiveextendedreal
$$
where $\mathcal{L}$ is the Lebesgue $\sa$ (the extension of semi-algebra of real line intervals).
\end{theorem}

We now denote $F_{\sigma}$ as the countable union of closed sets and $G_{\delta}$ as the countable intersection of open sets.

We can now state that we can approximate any Lebesgue measurable set by a countable collection of closed and open sets.
\begin{theorem}For any Lebesgue measurable set $A \in \mathcal{L}$, there exists $R \in F_{\sigma}$ and $S \in G_{\delta}$ such that $R \subseteq A \subseteq S$ such that 
$$
\mu(S \text{\textbackslash} R) = 0.
$$
\end{theorem}

\subsection{Measurability}
\begin{definition}(Measurable functions). Define a measure space $(\Omega, \sigmalgebra, \mu)$. Let $f: \Omega \rightarrow \positiveextendedreal$. Define $\overline{\borelsigmaalgebra}$ to be the extended Borel $\sa.$ Then, a function f is measurable if $f^{-1}(A) \in \sigmalgebra$ for all $A \in \overline{\borelsigmaalgebra}.$
\end{definition}
\begin{remark}This is important when we integrate as we will need to take the measure $\mu^{-1}(f^{-1}(A))$.
\end{remark}


It is extremely tedious to check that every set in $\overline{\borelsigmaalgebra}$ has a measurable preimage, hence the following theorem helps us narrow the number of sets we need to check.

\begin{theorem}(Measurability of a function). Define a measure space $(\Omega, \sigmalgebra, \mu)$. Let $f: \Omega \rightarrow \positiveextendedreal$. Then, the function f is measurable if and only if one of the following holds 
\begin{enumerate}
\item $f^{-1}((-\infty,x]) \in \sigmalgebra$ for all $x \in \mathbb{R}$;
\item $f^{-1}((-\infty,x)) \in \sigmalgebra$ for all $x \in \mathbb{R}$;
\item $f^{-1}((x,\infty)) \in \sigmalgebra$ for all $x \in \mathbb{R}$;
\item $f^{-1}([x, \infty)) \in \sigmalgebra$ for all $x \in \mathbb{R}$.
\end{enumerate}
\end{theorem}

Hence, we can simply check whether $\{\omega \in \Omega: f(\omega) \leq x\} \in \sigmalgebra$  for all $x \in \mathbb{R}.$

\subsection{Simple Functions}

\begin{lemma}A simple function $1_A$ is measurable if and only if A is measurable.
\end{lemma}

\begin{definition}(Simple function). Define a measure space $(\Omega, \sigmalgebra, \mu)$. Then f is a simple function if we can write it in the form 
$$
f = \sum_{j=1}^{n}c_j1_{E_{j}}
$$
where $c_j \in \mathbb{R}$, $E_j \in \sigmalgebra$, $E_j \cap E_k = \emptyset$ for $j \neq k$ and $\cupdot_{j=1}^{n}E_j = \Omega.$
\end{definition}


\subsection{Integrating Simple Functions}

\begin{definition}(Integral of a simple function).  Define a measure space $(\Omega, \sigmalgebra, \mu)$. Let f be a simple function. Then, we define the integral of f with respect to $\mu$ as 
$$
I(f) = \sum_{j=1}^{n}c_j\mu(E_j).
$$
\end{definition}


We state an important theorem that we can approximate any non-negative function by a sequence of monotonic simple functions.
\begin{theorem}(Simple approximation theorem). Let $f: \Omega \rightarrow \positiveextendedreal$ be a measurable function. Then, there exists a sequence of simple function $\{f_n\}_{n \geq 1}$ such that $f_n \geq 0$ and $f_n \uparrow f.$
\end{theorem}


\subsection{Integrating non-negative Functions}
\begin{definition}(Integral of non-negative function). Let $f: \Omega \rightarrow \positiveextendedreal$ be a measurable function. Then, the integral of f is defined as 
$$
I(f) = \lim_{n \rightarrow \infty}I(f_n).
$$
\end{definition}

\begin{lemma}The integral of a non-negative function $f: \Omega \rightarrow \positiveextendedreal$ does not depend on the sequence of non-negative simple functions chosen to approximate f.
\end{lemma}
\subsection{Integrating measurable functions}

We are now interested in measurable functions $f: \Omega \rightarrow \positiveextendedreal.$ Then, we can decompose f into its positive and negative part. That is, we can define 
$$
\begin{cases}
f^+ = \max(f, 0)\\
f^- = \max(-f, 0).
\end{cases}
$$
We have that $f^+, f^-$ are measurable and we can express $f = f^+ - f^-.$

\begin{remark}Note that if either $f^+$ or $f^-$ is infinity, then the other term has to be zero.
\end{remark}

\begin{definition}(Integrable function). We say that a function f is integrable if  $\min\{f^+, f^-\} < \infty$.
\end{definition}

\begin{definition}(Integrating measurable functions). Define the measurable function  $f: \Omega \rightarrow \positiveextendedreal.$ Then, define $f^+,f^-$ as before. We define the respective integrals $I(f^+)$ and $I(f^-).$ Now, if we have that $\min\{f^+, f^-\} < \infty$, then we define the integral of f as 
$$
I(f) = I(f^+) - I(f^-).
$$
\end{definition}


\subsection{Measurability of functions}

\begin{proposition}(Properties of measurable functions). Let $(\Omega, \sigmalgebra, \mu)$ be a measure space. Then define $f,g: \Omega \rightarrow \positiveextendedreal$ to be measurable functions. Let $\alpha \in \mathbb{R}.$ The following functions are measurable.
\begin{enumerate}
\item $\alpha f \in \sigmalgebra$
\item $\alpha + f \in \sigmalgebra$
\item $f + g \in \sigmalgebra$
\item $f^2 \in \sigmalgebra$
\item $\frac{1}{f} \in \sigmalgebra$
\item $f^+, f^-, |f| \in \sigmalgebra$
\item $fg \in \sigmalgebra$
\end{enumerate}
\end{proposition}

\begin{proposition}Let $\{f_n\}_{n \geq 1}$ be a sequence of functions $f_n: \Omega \rightarrow \positiveextendedreal$ and $f_n \in \sigmalgebra.$
We have that the following functions are measurable.
\begin{enumerate}
\item $\sup_n f_n \in \sigmalgebra$
\item $\inf_n f_n \in \sigmalgebra$
\item $\lim_{n \rightarrow \infty}\sup f_n \in \sigmalgebra$
\item $\lim_{n \rightarrow \infty}\inf f_n \in \sigmalgebra$
\item If $f_n \rightarrow f$, then $f \in \sigmalgebra.$
\end{enumerate}
\end{proposition}


\begin{proposition}Let $\Omega$ be a topological space. Define the measure space $(\Omega, \sigmalgebra, \mu)$ and let $\sigmalgebra \supseteq \borelsigmaalgebra$ where $\borelsigmaalgebra$ is the Borel $\sa.$ Then, define the function $f: \Omega \rightarrow \positiveextendedreal.$ Then, if the function f is continuous, it is also measurable.
\end{proposition}

\subsection{Properties of Integrals}


\begin{proposition}Let $(\Omega, \sigmalgebra, \mu)$ be a measure space and let $f, g$ be integrable with respect to $\sigmalgebra.$ Then, 
$$
\int\bigg(f + g \bigg)d\mu = \int fd\mu + \int gd\mu.
$$
\end{proposition}

\begin{proposition}Let $(\Omega, \sigmalgebra, \mu)$ be a measure space and let $f$ be integrable with respect to $\sigmalgebra.$ Then 
$$
\bigg|\int fd\mu \bigg| \leq \int |f|d\mu.
$$
\end{proposition}

\begin{proposition}Let $(\Omega, \sigmalgebra, \mu)$ be a measure space and $c \in \mathbb{R}.$ Let $f$ be integrable with respect to $\sigmalgebra.$ Then 
$$
\int cfd\mu = c \int fd\mu.
$$
\end{proposition}

\begin{proposition}(Monotonicty of integral). If $f \geq 0$ then $\int fd\mu \geq 0.$ If $f \geq g$, then $\int fd\mu \geq \int gd\mu .$
\end{proposition}

\begin{proposition}If $f = g$ a.e., then we have that 
$$
\int fd\mu = \int gd\mu.
$$
\end{proposition}

\begin{proposition}If $h: \Omega \rightarrow \positiveextendedreal$ and $h \in \sigmalgebra.$ Let $|h| \leq f.$ If f is integrable, then h is integrable.
\end{proposition}

\subsection{Convergence Theorems for non-negative functions}

\begin{theorem}(Monotone Convergence Theorem). Let $(\Omega, \sigmalgebra, \mu)$ be a measure space. Let $f_n \geq 0$ be a sequence of non-negative functions where $f_n \in \mathcal{F}$ for all $n \geq 1.$ Suppose that $f_n \uparrow f$ pointwise. Then 
$$
\int f_nd\mu \uparrow \int fd\mu.
$$
\end{theorem}

\begin{remark}The MCT still holds if we replace $f_n \geq 0$ by $f_n \geq g$ where g is integrable as we can then define $g_n = f_n - g \geq 0.$
\end{remark}
\begin{definition}(Uniform integrability). Let $f \geq 0$ on a measure space $(\Omega, \sigmalgebra, \mu).$ Define $\mu_f(A) = \int_Afd\mu.$ Then, the set A is uniformly integrable if for all $\epsilon > 0$, there exists a $\delta > 0$ such that $\mu(A) < \delta$ implies that $\mu_f(A) < \epsilon.$
\end{definition}

\begin{definition}(Fatou's Lemma). Let $f_n \geq 0$. Then 
$$
\int \underline{lim}f_nd\mu \leq \underline{\lim}\int f_nd\mu.
$$
\end{definition}
\begin{remark}We can repalce $f_n \geq 0$ by $f_n \geq g$ where g is integrable.
\end{remark}

\begin{definition}(Reversed Fatou's Lemma). Let $f_n \geq 0$. Then 
$$
\int \overline{lim}f_nd\mu \geq \overline{\lim}\int f_nd\mu.
$$
\end{definition}

\begin{remark}We can repalce $f_n \geq 0$ by $f_n \leq g$ where g is integrable.
\end{remark}

Using the two Fatou's lemma, we define the dominated convergence theorem.
\begin{theorem}(Dominated Convergence Theorem). Let $f_n \rightarrow f$ where $|f_n| \leq g$ where g is integrable. 
Then f is integrable and 
$$
\int f_nd\mu \rightarrow \int fd\mu.
$$
\end{theorem}

\subsection{Lebesgue-Stieltjes Integral}



There is a relationship between right continuous increasing functions $F$ on $\mathbb{R}$ and Borel measure $\mu_F$. 

If we start off with a regular Borel measure $\mu$ on $\mathbb{R}$, we can define a right continuous increasing function by 
$$
F_0(t) = \begin{cases}
\mu((0,t]) \quad t > 0\\
-\mu((t,0]) \quad t < 0
\end{cases}.
$$
Then, we derive the \textbf{distribution function} by $F(t) = F_0(t) + \mu((-\infty]).$


Now, let us start off with a right continuous increasing function F. First, define the \textbf{Lebesgue-Stieltjes outer measure} by 
$$
\mu_{F}^{*}(A) = inf \{\sum_{k=0}^{\infty}(F(b_k) - F(a_k)): A \subseteq \bigcup_{k=0}^{\infty}(a_k,b_k] \}.
$$
Then, create a $\sa$ by collecting all sets $E \in X$ such that $\mu_{F}^{*}(E) = \mu_{F}^{*}(E \cap A) + \mu_{F}^{*}(E \cap A^c)$ for all $A \in X$. Then, if we restrict $\mu_{F}^{*},$ we get the \textbf{Lebesgue-Stieltjes measure induced by F} denoted by $\mu_F.$ We have that $\mu_F$ is a Borel measure (every Borel set is inside the $\sa$).


\begin{theorem}Every regular Borel measure $\mu$ on $\mathbb{R}$ is associated to an increasing right continuous function $F: \mathbb{R} \rightarrow \mathbb{R}.$
\end{theorem}

\begin{definition}(Lebesgue-Stieltjes Integral). Let $f$ be $\mu_F$-measurable. Then, the Lebesgue-Stieltjes integral is defined as 
$$
\int_{\mathbb{R}}fd\mu_F.
$$
\end{definition}

\begin{remark}If we set $F(x) = x$, then we will recover the Lebesgue measure and resultingly, the Lebesgue integral.
\end{remark}

\subsection{Measure on finite product of spaces}

We define the set up on the measure spaces $(\Omega_j, \sigmalgebra_j, \mu_j)$ for j=1,2. We can define $\Omega = \Omega_1 \times \Omega_2 = \{(x,y): x \in \Omega_1, y \in \Omega_2\}$. Our aim is to now define a $\sa$ on $\Omega$ and a measure $\mu$ on $\Omega$.

\begin{definition}(Rectangle). Define the measure spaces $(\Omega_j, \sigmalgebra_j, \mu_j)$ for j=1,2. Then, consider the sets $E_j \in \sigmalgebra_j$. Define the set 
$$
E_1 \times E_2 = \{(x,y): x \in E_1, y \in E_2\}.
$$
The set $E_1 \times E_2$ is called a rectangle.
\end{definition}


\begin{definition}(Class of rectangles). Define the measure spaces $(\Omega_j, \sigmalgebra_j, \mu_j)$ for j=1,2. We define the \textbf{class of rectangles} $\sigmalgebra_1 \times \sigmalgebra_2$ as 
$$
\sigmalgebra_1 \times \sigmalgebra_2 = \{E_1 \times E_2: E_1 \in \sigmalgebra_1, E_2 \in \sigmalgebra_2\}.
$$
\end{definition}

\begin{proposition}The family of rectangles $\sigmalgebra_1 \times \sigmalgebra_2$ is a semi-algebra.
\end{proposition}

\begin{definition}($\sa$ of rectangles). Let $\sigmalgebra_1 \times \sigmalgebra_2$ be the family of rectangles. We define the $\sa$ of rectangles as 
$$
\sigmalgebra = \sigmalgebra_1 * \sigmalgebra_2 = \sigma(\sigmalgebra_1 \times \sigmalgebra_2).
$$
\end{definition}

We now want to define a pre-measure on the semi-algebra $\sigmalgebra_1 \times \sigmalgebra_2$ and then by Caratheodory's theorem, uniquely extend this to a measure on $\sigmalgebra.$

\begin{proposition}Define $\sigmalgebra_1 \times \sigmalgebra_2$ as the semi-algebra of rectangles. Then, define the set function $\mu: \sigmalgebra_1 \times \sigmalgebra_2 \rightarrow \positiveextendedreal$ as 
$$
\mu(E_1 \times E_2) = \mu_1(E_1)\mu_2(E_2)
$$
where we define $0.\infty = 0.$
\end{proposition}

\begin{proposition}The set function $\mu: \sigmalgebra_1 \times \sigmalgebra_2 \rightarrow \positiveextendedreal$ is a pre-measure. That is, it is $\sigma$-additive.
\end{proposition}

\begin{lemma}Take the set $A \in \sigmalgebra.$ For any set $A \subseteq \Omega$, we define for $x \in \Omega_1$ and for $y \in \Omega_2$, we define
$$
\begin{cases}
A_x = \{y \in \Omega_2: (x,y) \in A\}\\
A^y = \{x \in \Omega_1: (x,y) \in A\}. 
\end{cases}
$$
Clearly, $A_x \subseteq \Omega_2$ and $A^y \subseteq \Omega_1.$ Then, for all $x \in \Omega_1$, we have that $A_x \in \sigmalgebra_2$ and for all $y \in \Omega_2$, we have that $A^y \in \sigmalgebra_1.$
\end{lemma}

\begin{claim}Assume that $\Omega_1, \Omega_2$ is $\sigma-$finite with respect to $\mu_1, \mu_2$ respectively. Then, $\Omega$ is $\sigma-$finite with respect to $\mu.$ 
\end{claim}

\begin{proposition}Let $\mu$ be the pre-measure defined on the semi-algebra $\sigmalgebra_1 \times \sigmalgebra_2$. Let $\sigmalgebra$ be the $\sa$ generated by the semi-algebra $\sigmalgebra_1 \times \sigmalgebra_2$. Let $\Omega$ be $\sigma$-finite with respect to $\mu.$ Then, by Caratheodory's theorem, we can \textbf{uniquely} extend the pre-measure $\mu$ onto the $\sa$ $\sigmalgebra$. This extended measure is known as the \textbf{product measure}.
\end{proposition}


\subsection{Countable Product Space}

\subsection{Fubini's Theorem}
Fubini's theorem is a theorem which gives us the sufficient conditions for when we can exchange the order of integrals.

We describe the setup. Let $(\Omega_i, \sigmalgebra_i, \mu_i)$ for i=1,2. We also have $\Omega_i$ to be $\sigma$-finite with respect to $\mu_i.$ Then, we define the product measure $\mu = \mu_1*\mu_2$ and the product $\sa$ as $\sigmalgebra = \sigma(\sigmalgebra_1 \times \sigmalgebra_2).$ We now have a function $f: \Omega_1 \times \Omega_2 \rightarrow \overline{\real}.$ We are interested for when does the following hold:
$$
\int_{\Omega_{1}} \bigg[\int_{\Omega_{2}}f_x(y)d\mu_2(y) \bigg]d\mu_1(x) = \int fd\mu.
$$

This equation has 2 implicit things we need to show. First, $f_x(y)$ is $\sigmalgebra_2-$measurable so that we are able to integrate it with respect to $\mu_2$. Then, we need to show $\int_{\Omega_{2}}f_x(y)d\mu_2(y)$ is measurable with respect to $\sigmalgebra_1$ for any fixed x so that we can integrate it with respect to $\mu_1.$

\begin{claim}Let $f: \Omega \rightarrow \overline{\real}$ be a function that is measurable with respect to $\sigmalgebra = \sigma(\sigmalgebra_1 \times \sigmalgebra_2).$ Then, for all $x \in \Omega$, we define $f_x: \Omega_2 \rightarrow \overline{\real}$ as 
$$
y \rightarrow (x,y).
$$
Then, we have that $f_x$ is measurable with respect to $\sigmalgebra_2.$
\end{claim}

Recall that if a set $E \in \sigmalgebra = \sigma(\sigmalgebra_1 \times \sigmalgebra_2)$, we defined the x-section of E and the y-section of E as: 

$$
\begin{cases}
E_x = \{y \in \Omega_2: (x,y) \in E\}\\
E^y = \{x \in \Omega_1: (x,y) \in E\}. 
\end{cases}
$$

We first state a lemma to help us prove an important theorem for Fubini's theorem.
\begin{lemma}Let $(\Omega_j, \sigmalgebra_j, \mu_j)$ be measure spaces for j=1,2 where $\Omega_j$ is $\sigma-$finite with respect to $\mu_j.$ Take a set $E \in \sigmalgebra = \sigma(\sigmalgebra_1 \times \sigmalgebra_2)$. Then, we have the following 
\begin{enumerate}
\item $E_x \in \sigmalgebra_2$;
\item $\mu_2(E_x)$ is well-defined;
\item $E^y \in \sigmalgebra_1$;
\item $\mu_1(E^y)$ is well-defined.
\end{enumerate}
\end{lemma}

\begin{theorem}Let $(\Omega_j, \sigmalgebra_j, \mu_j)$ be measure spaces for j=1,2 where $\Omega_j$ is $\sigma-$finite with respect to $\mu_j.$ Take a set $E \in \sigmalgebra = \sigma(\sigmalgebra_1 \times \sigmalgebra_2)$. Then, we have the following.
\begin{enumerate}
\item $x \rightarrow \mu_2(E_x)$ is $\sigmalgebra_1-$measurable;
\item $y \rightarrow \mu_1(E^y)$ is $\sigmalgebra_2-$measurable;
\item $\int_{\Omega_{1}} \mu_2(E_x)d\mu_1(x) = \mu(E) = \int_{\Omega_{2}} \mu_1(E^y)d\mu_2(y).$
\end{enumerate}
\end{theorem}


\begin{theorem}(Tonelli's Theorem). Let $(\Omega_j, \sigmalgebra_j, \mu_j)$ be measure spaces for j=1,2 where $\Omega_j$ is $\sigma-$finite with respect to $\mu_j.$ Take a function $f: \Omega_1 \times \Omega_2 \rightarrow \positiveextendedreal$. Then 
$$
\int_{\Omega_{1}}\bigg[\int_{\Omega_{2}}f_x(y)d\mu_2 \bigg]d\mu_1 = \int fd\mu = \int_{\Omega_{2}}\bigg[\int_{\Omega_{1}}f^y(x)d\mu_1 \bigg]d\mu_2
$$
\end{theorem}

\begin{remark}Here, we are saying that $\int_{\Omega_{2}}f_x(y)d\mu_2$ is measurable with respect to $\sigmalgebra_1$ and hence we can integrate it with $\mu_1.$
\end{remark}


\begin{theorem}(Fubini's Theorem). Let $(\Omega_j, \sigmalgebra_j, \mu_j)$ be measure spaces for j=1,2 where $\Omega_j$ is $\sigma-$finite with respect to $\mu_j.$ Take a function that is measurable with respect to $\sigmalgebra$. Furthermore, assume that $\textbf{f is integrable}$. Then 
\begin{enumerate}
\item $\int_{\Omega_{2}}f_x(y)d\mu_2$ is measurable with respect to $\sigmalgebra_1$;
\item $\int_{\Omega_{1}}f^y(x)d\mu_1$ is measurable with respect to $\sigmalgebra_2$;
\item $$
\int_{\Omega_{1}}\bigg[\int_{\Omega_{2}}f_x(y)d\mu_2 \bigg]d\mu_1 = \int fd\mu = \int_{\Omega_{2}}\bigg[\int_{\Omega_{1}}f^y(x)d\mu_1 \bigg]d\mu_2
$$
\end{enumerate}
\end{theorem}

\subsection{Radon-Nikodym Theorem}

\begin{definition}(Absolute continuity). Let $\mu, \nu$ be measures on the space $(\Omega, \sigmalgebra)$. $\mu$ is absolutely continuous with respect to $\nu$ if $\nu(A) = 0$ implies that $\mu(A) = 0$. We denote this by $\mu << \nu.$
\end{definition}

\begin{claim}(Measure with a density).
Let $f \geq 0$ be a function on $(\Omega, \sigmalgebra, \mu).$ Then, we can define set function 
$$
\mu_f(A) = \int_Afd\mu = \int_{\Omega}1_{A}fd\mu.
$$
where $A \in \sigmalgebra$. Then, $\mu_f$ is a measure.
\end{claim}


The following gives us the converse, that is, if 2 measures are absolutely continuous, then there exists a non-negative function relating the two measures.

\begin{theorem}(Radon-Nikodym Theorem). Let $\mu, \nu$ be measures on the space $(\Omega, \sigmalgebra)$. Let $\mu << \nu$. Then, there exists a non-negative function $g ( = \frac{d\mu}{d\nu})$ such that 
$$
\mu(B) = \int_Bgd\nu
$$
for all $B \in \sigmalgebra.$
\end{theorem}


\subsection{Convergence of functions}

\begin{lemma}Let $(\Omega, \sigmalgebra, \mu)$ is a measure space. Let $\Omega$ be $\sigma-$finite with respect to $\mu.$ Assume that $\sigmalgebra$ is $\sigma-$complete. Let $f: \Omega \rightarrow \extendedreal$ and $g: \Omega \rightarrow \extendedreal$. If $f$ is $\sigmalgebra$-measurable and $g = f$ almost surely, then g is $\sigmalgebra-$measurable.
\end{lemma}

\begin{definition}(Pointwise Convergence). Let $f, f_n: E \rightarrow \extendedreal.$ Then $f_n$ converges to f pointwise if for all $x \in E$, $f_n(x) \rightarrow f(x)$. We write this as $f_n \xrightarrow{p} f.$
\end{definition}

\begin{definition}(Almost Sure Convergence). Let $f, f_n: \Omega \rightarrow \extendedreal.$  Then, $f_n$ converges to f almost surely (or almost everywhere) if there exists a set $E \in \sigmalgebra$ such that $\mu(E^c) = 0$ and $f_n$ converges to f pointwise on E, that is, for all $x \in E$, $f_n(x) \rightarrow f(x)$.
\end{definition}

We can think of a.s. convergence as pointwise convergence except for a null set E.

\begin{proposition}(Properties of a.s. convergence). Let $f_n \rightarrow f$ almost surely. Then if $f_n \sim g_n$ and $f \sim g$ then $g_n \rightarrow g$ almost surely.
\end{proposition}

\begin{proposition}(Further properties of a.s. convergence). Let $f_n \rightarrow f$ almost surely and $f_n \rightarrow g$ almost surely. Then $f = g$ almost surely.
\end{proposition}

We recall another form of convergence from analysis.
\begin{definition}(Uniform Convergence). Let $f, f_n: E \rightarrow \extendedreal.$ Then $f_n$ converges to f uniformly if for all $\epsilon > 0$ there exists $n_0 \in \mathbb{N}$ such that 
$$
\sup_{x \in E}|f_n(x) - f(x)| \leq \epsilon
$$
for all $x \in E$ and $n \geq n_0.$
\end{definition}

\begin{definition}(Uniform Convergence Almost Everywhere). Let $f, f_n: \Omega \rightarrow \extendedreal$. Then $f_n$ converges to f \textbf{uniformly almost everywhere} if there exists a set $E \in \sigmalgebra$ such that $\mu (E^c) = 0$ and $f_n$ converges to f uniformly on E.
\end{definition}

\begin{definition}(Almost Uniform Convergence). Let $f, f_n: \Omega \rightarrow \extendedreal.$ Then $f_n$ converges to f \textbf{almost uniformly} if for all $\epsilon > 0$, there exists a set $E_{\epsilon} \in \sigmalgebra$ such that $\mu(E_{\epsilon}^c) \leq \epsilon$ and $f_n$ converges to f uniformly on $E_{\epsilon}$.
\end{definition}



\begin{proposition}(Relationships between forms of convergence). Let $f, f_n: \Omega \rightarrow \extendedreal.$ Then, if $f_n \rightarrow f$ uniformly almost everywhere, then $f_n$ converges to f almost everywhere \textbf{AND} also converges almost uniformly.
\end{proposition}

\begin{theorem}(Ergoroff). Let $\mu(\Omega) < \infty.$ Then $f_n \rightarrow f$ almost surely if and only if $f_n \rightarrow f$ almost uniformly.
\end{theorem}
\begin{remark}In a probability space, this always holds!
\end{remark}


\begin{definition}(Convergence in measure). Let $f_n, f: \Omega \rightarrow \extendedreal.$ Then, $f_n$ converges to f in measure if for all $\epsilon > 0$, we have that 
$$
\mu \bigg(\{x: |f_n(x) - f(x)| > \epsilon\} \bigg) \rightarrow 0
$$
as $n \rightarrow \infty.$
\end{definition}

\begin{proposition}Assume that $f_n$ converges to f in measure and $f_n$ converges to g in measure. Then $f = g$ almost surely.
\end{proposition}

\begin{proposition}If $f_n \rightarrow f$ in measure and $g_n \sim f_n$ and $g \sim f$, then $g_n \rightarrow g$ in measure.
\end{proposition}


\begin{lemma}Assume that $f_n$ converges to f in measure. Then, there exists a subsequence $\{n_k\}$ such that $f_{n_{k}} \rightarrow f$ almost surely.
\end{lemma}

\begin{remark}Note that this only holds for a subsequence, not for the whole sequence.
\end{remark}

\begin{theorem}Assume that $\mu(\Omega) < \infty$. Then if $f_n \rightarrow f$ almost surely, then $f_n \rightarrow f$ in measure.
\end{theorem}

\begin{remark}In probability theory, this means that if a sequence of random variables converges almost surely, then the sequence of random variables converges in probability.
\end{remark}

\subsection{Hlder and Minkowski Inequalities}

\begin{definition}($L^p$-norm). Let $1 \leq p < \infty$. We define the $L^p-$norm as 
$$
||f||_p = \bigg(\int |f(x)|^p\mu (dx) \bigg)^{\frac{1}{p}}.
$$
\end{definition}

\begin{theorem}(Hlder's Inequality). Let $1 < p < \infty$. Define q to be such that $\frac{1}{p} + \frac{1}{q} = 1.$ Assume that $||f||_p < \infty$ and $||g||_q < \infty.$ Then, we have that 
$$
\int |fg|d\mu \leq ||f||_p||g||_q.
$$
\end{theorem}


\begin{theorem}(Minkowski Inequality). Let $1 \leq p < \infty.$ Let f,g be functions such that $||f||_p < \infty$ and $||g||_p < \infty.$ Then, we have that 
$$
||f + g||_p \leq ||f||_p + ||g||_p.
$$
\end{theorem}

\begin{lemma}The Minkowski inequality is a \textbf{pseudonorm}.
\end{lemma}

\subsection{$L^p$-Spaces}


\begin{definition}($\mathcal{L}^p-$space). We define the Lebesgue space as
$$
\mathcal{L}^p = \{f: \Omega \rightarrow \overline{\mathbb{R}}: ||f||_p < \infty\}.
$$
\end{definition}

\begin{theorem}($\mathcal{L}_p$ is a linear space). Let $f,g \in \mathcal{L}_p.$ Then 
$$
f + g \in \mathcal{L}_p.
$$
\end{theorem}

\begin{definition}(Metric in $\mathcal{L}^p$). We can define a metric on the $\mathcal{L}^p-$space as 
$$
d(f,g) = ||f - g||_p.
$$
\end{definition}

\begin{definition}(Convergence in $L^p$). Define a sequence of functions $\{f_n\}_{n \geq 1}$ where $f_n \in \mathcal{L}^p.$ Then, $f_n$ converges to f in $\mathcal{L}^p$ if and only if 
$$
||f_n - f||_p \rightarrow 0.
$$
\end{definition}

\begin{definition}(Cauchy Sequence). Let $\{f_n\}_{n \geq 1}$ be a sequence of functions where $f_n \in \mathcal{L}^p.$ Then, $f_n$ is a Cauchy sequence if for all $\epsilon > 0$, there exists a $M_0 \in \mathbb{N}$ such that $||f_n - f_m||_p \leq \epsilon$ for all $n,m \geq M_0.$
\end{definition}

\begin{theorem}The space $\mathcal{L}^p$ is complete. That is, suppose there exists a Cauchy sequence of functions $\{f_n\}_{n \geq 1}$ in $\mathcal{L}^p$, then there exists a function $f \in \mathcal{L}^p$ such that $f_n \rightarrow f$ in $\mathcal{L}^p.$
\end{theorem}


\begin{definition}(Uniformly Integrable). A sequence of functions $\{f_n\}_{n \geq 1}$ is uniformly integrable if 
$$
\sup_{n}\int_{|f_n| > A}|f_n|^pd\mu \rightarrow 0
$$
as $A \rightarrow \infty.$
\end{definition}



\end{document}


}
}

